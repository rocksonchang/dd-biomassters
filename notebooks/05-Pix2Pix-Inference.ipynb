{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 05 - Pix2Pix Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:90% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from botocore.exceptions import ClientError\n",
    "import boto3\n",
    "# import calendar\n",
    "import io\n",
    "from itertools import product\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "# import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tifffile as tif\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "# from torch.utils.data import Dataset, DataLoader\n",
    "# from torchvision import transforms\n",
    "\n",
    "# from models.pix2pix_model import Pix2PixModel\n",
    "\n",
    "from IPython.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:90% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_STATE=42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create train, validation, test splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/loaner/projects/dd-biomassters\n"
     ]
    }
   ],
   "source": [
    "%cd ~/projects/dd-biomassters\n",
    "df_metadata = pd.read_csv(\"data/metadata/features_metadata.csv\",index_col=0)\n",
    "all_chips = list(df_metadata.chip_id.unique())\n",
    "train_chips = list(df_metadata[df_metadata.split=='train'].chip_id.unique())\n",
    "test_chips = list(df_metadata[df_metadata.split=='test'].chip_id.unique())\n",
    "\n",
    "df_metadata_train = df_metadata[df_metadata.split=='train'].chip_id \\\n",
    "    .drop_duplicates().reset_index(drop=True).to_frame()\n",
    "\n",
    "X_train, X_validation = train_test_split(df_metadata_train, test_size=0.33, random_state=RANDOM_STATE)\n",
    "df_metadata.loc[df_metadata.chip_id.isin(X_validation.chip_id), 'split'] = 'validation'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check for data completeness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>chip_id</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split</th>\n",
       "      <th>is_complete</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">test</th>\n",
       "      <th>False</th>\n",
       "      <td>2566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <td>207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">train</th>\n",
       "      <th>False</th>\n",
       "      <td>5482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <td>339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">validation</th>\n",
       "      <th>False</th>\n",
       "      <td>2699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <td>169</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        chip_id\n",
       "split      is_complete         \n",
       "test       False           2566\n",
       "           True             207\n",
       "train      False           5482\n",
       "           True             339\n",
       "validation False           2699\n",
       "           True             169"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chips = all_chips\n",
    "satellites = ['S1', 'S2']\n",
    "months = range(1,13)\n",
    "df_metadata_complete = pd.DataFrame(list(product(chips, satellites, months)), columns=['chip_id', 'satellite', 'month'])\n",
    "df_metadata_complete = df_metadata_complete.merge(df_metadata, on=['chip_id', 'satellite', 'month'], how='left')\n",
    "\n",
    "# chip aggregates\n",
    "df_metadata_complete['file_exists'] = df_metadata_complete.apply(lambda row: type(row.filename) == str, axis=1)\n",
    "df_agg = df_metadata_complete.groupby('chip_id').agg(\n",
    "    {\n",
    "        'file_exists': pd.Series.all,\n",
    "        'num_s1_missing': sum, \n",
    "        'num_s2_obscured': sum\n",
    "    }\n",
    ").reset_index()\n",
    "df_agg_s1 = df_metadata_complete[df_metadata_complete.satellite=='S1'].groupby('chip_id').agg(\n",
    "    {\n",
    "        'file_exists': pd.Series.all,\n",
    "        'num_s1_missing': sum\n",
    "    }\n",
    ").reset_index()\n",
    "df_agg_s2 = df_metadata_complete[df_metadata_complete.satellite=='S2'].groupby('chip_id').agg(\n",
    "    {\n",
    "        'file_exists': pd.Series.all,\n",
    "        'num_s2_obscured': sum\n",
    "    }\n",
    ").reset_index()\n",
    "\n",
    "# completeness criteria\n",
    "complete_chips = df_agg[(df_agg.file_exists)&(df_agg.num_s1_missing==0)&(df_agg.num_s2_obscured==0)].chip_id.to_list()\n",
    "complete_s1_chips = df_agg_s1[(df_agg_s1.file_exists)&(df_agg_s1.num_s1_missing==0)].chip_id.to_list()\n",
    "complete_s2_chips = df_agg_s2[(df_agg_s2.file_exists)&(df_agg_s2.num_s2_obscured==0)].chip_id.to_list()\n",
    "\n",
    "# add to original\n",
    "df_metadata['is_complete'] = df_metadata.chip_id.isin(complete_chips)\n",
    "df_metadata['is_complete_s1'] = df_metadata.chip_id.isin(complete_s1_chips)\n",
    "df_metadata['is_complete_s2'] = df_metadata.chip_id.isin(complete_s2_chips)\n",
    "\n",
    "# summary stats\n",
    "df_metadata[['chip_id', 'split', 'is_complete']].drop_duplicates().groupby(['split', 'is_complete']).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_metadata.to_csv(f\"data/metadata/features_metadata_split_{RANDOM_STATE}.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download train data to local"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataDownloader():\n",
    "    S3_BUCKET_NAME = 'drivendata-competition-biomassters-public-us'\n",
    "    IMG_SIZE = 256, 256\n",
    "    RANDOM_STATE = 42\n",
    "\n",
    "    def __init__(self, phase, dataroot, dataset_size, chip_is_complete):\n",
    "        \n",
    "        self.phase = phase\n",
    "        self.dataroot = dataroot\n",
    "        self.dataset_size = dataset_size\n",
    "\n",
    "        # prepare metadata\n",
    "        self.metadata = pd.read_csv(f\"{self.dataroot}/metadata/features_metadata_split_42.csv\",index_col=0)\n",
    "        if chip_is_complete:\n",
    "            self.metadata = self.metadata[self.metadata.is_complete]\n",
    "        self.data = self.metadata[self.metadata.split == self.phase] \\\n",
    "            .chip_id.drop_duplicates().reset_index(drop=True).to_frame()\n",
    "        if self.dataset_size < len(self.data):\n",
    "            self.data = self.data.sample(self.dataset_size, random_state=self.RANDOM_STATE).reset_index(drop=True)\n",
    "\n",
    "        self.images = []\n",
    "        self.__initialize_s3()\n",
    "    \n",
    "    def __initialize_s3(self):\n",
    "        \"\"\"Initalize AWS s3 bucket for \n",
    "        \"\"\"\n",
    "        s3_resource = boto3.resource(\n",
    "            's3',\n",
    "            aws_access_key_id=os.environ['AWS_ACCESS_KEY_ID'],\n",
    "            aws_secret_access_key=os.environ['AWS_SECRET_ACCESS_KEY']\n",
    "        )\n",
    "        self.s3_bucket = s3_resource.Bucket(self.S3_BUCKET_NAME)\n",
    "\n",
    "    def run(self):\n",
    "        for i, row in self.data.iterrows():\n",
    "            print(i, row.chip_id)\n",
    "            X = self.__load_chip_feature_data(row['chip_id'])\n",
    "            y = self.__load_chip_target_data(row['chip_id'])\n",
    "            self.images.append({'chip_id': row['chip_id'], 'X': X, 'y': y})\n",
    "\n",
    "    def __get_chip_metadata(self, chip_id):\n",
    "        return self.metadata[self.metadata.chip_id==chip_id]\n",
    "            \n",
    "    def __load_chip_feature_data(self, chip_id):\n",
    "        img_channels = []\n",
    "        for _, row in self.__get_chip_metadata(chip_id).iterrows():\n",
    "            \n",
    "            if type(row.filename) != str:\n",
    "                print(row)\n",
    "                if row.satellite=='S1':\n",
    "                    print('Missing S1')\n",
    "                    img = self.dummy_s1_missing_img\n",
    "                elif row.satellite=='S2':\n",
    "                    print('Missing S2')\n",
    "                    img = self.dummy_s2_missing_img\n",
    "                else:\n",
    "                    raise ValueError(\"Unknown satellite value\")\n",
    "            else:\n",
    "                s3_key = f\"{'test' if self.phase=='test' else 'train'}_features/{row.filename}\"\n",
    "                img = self.__load_tif(self.s3_bucket, s3_key, out_path=f'{self.dataroot}/{s3_key}')\n",
    "            img_channels.append(img)\n",
    "        return np.concatenate(img_channels, axis=2)\n",
    "\n",
    "    def __load_chip_target_data(self, chip_id):\n",
    "        filename = self.__get_chip_metadata(chip_id).corresponding_agbm.iloc[0]\n",
    "        s3_key = f'train_agbm/{filename}'\n",
    "        img = self.__load_tif(self.s3_bucket, s3_key, out_path=f'{self.dataroot}/{s3_key}')\n",
    "        return img\n",
    "    \n",
    "    def __load_tif(self, s3_bucket, key, out_path):\n",
    "        if not os.path.exists(out_path):\n",
    "            self.download_obj_from_s3(s3_bucket, key, out_path)\n",
    "        img = tif.imread(out_path)\n",
    "        return img\n",
    "\n",
    "    def download_obj_from_s3(self, s3_bucket, key, out_path):\n",
    "        try:\n",
    "            s3_bucket.download_file(key, out_path)\n",
    "        except ClientError as e:\n",
    "            if e.response['Error']['Code'] == \"404\":\n",
    "                print(\"The object does not exist.\")\n",
    "            else:\n",
    "                raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/loaner/projects/dd-biomassters\n",
      "0 dbe9a663\n",
      "1 584e3e68\n",
      "2 55a14920\n",
      "3 25fd4e5d\n",
      "4 63d80a6c\n",
      "5 baacf334\n",
      "6 91f65529\n",
      "7 d7a3a181\n",
      "8 fec09d0b\n",
      "9 14d3b92b\n",
      "10 5fe2bef0\n",
      "11 b2c401d0\n",
      "12 cd588d96\n",
      "13 7af9ab75\n",
      "14 51e245a8\n",
      "15 874dde20\n",
      "16 5957a5cc\n",
      "17 f5279346\n",
      "18 d10d20b5\n",
      "19 0636b264\n",
      "20 d8ae34f2\n",
      "21 30617afb\n",
      "22 819bfa10\n",
      "23 5a1bc9dd\n",
      "24 75e80cb9\n",
      "25 4618c2da\n",
      "26 51d93376\n",
      "27 a9ee85c3\n",
      "28 7164a926\n",
      "29 ef683082\n",
      "30 8dbdd885\n",
      "31 23159416\n",
      "32 4f349d09\n",
      "33 ef957a4d\n",
      "34 3f56d3a1\n",
      "35 04b380c7\n",
      "36 e8ab54e7\n",
      "37 f707aaad\n",
      "38 5209306d\n",
      "39 3e398cfe\n",
      "40 42b5ac06\n",
      "41 02c460be\n",
      "42 7c768708\n",
      "43 b958c3fb\n",
      "44 28e70767\n",
      "45 ef699037\n",
      "46 dcfb6072\n",
      "47 e23ad4d7\n",
      "48 3abcf82c\n",
      "49 1d98f768\n",
      "50 f11ecfea\n",
      "51 9353eb6d\n",
      "52 a5289942\n",
      "53 42252aa2\n",
      "54 35e67e33\n",
      "55 a01646fd\n",
      "56 30fcd658\n",
      "57 f822769e\n",
      "58 fb48851a\n",
      "59 27c33457\n",
      "60 eb4f944d\n",
      "61 ebac9596\n",
      "62 f016331a\n",
      "63 893c3cd5\n",
      "64 a759e918\n",
      "65 3abc0182\n",
      "66 3d92ead9\n",
      "67 0ad475a1\n",
      "68 36bb6861\n",
      "69 572306c5\n",
      "70 04debe47\n",
      "71 70dbbfd2\n",
      "72 f5d934ef\n",
      "73 e98df0c5\n",
      "74 e3a3dba4\n",
      "75 3e4eba43\n",
      "76 76e4ec0c\n",
      "77 a072b45b\n",
      "78 cafffd1d\n",
      "79 3411cc89\n",
      "80 4c268cf7\n",
      "81 d56a14ed\n",
      "82 479938e1\n",
      "83 a259bbd9\n",
      "84 782c53ff\n",
      "85 0baa5577\n",
      "86 14888ef2\n",
      "87 d63f63c2\n",
      "88 74cbb1e1\n",
      "89 b3b09e5f\n",
      "90 c850f570\n",
      "91 d34d78e6\n",
      "92 ab8aca7a\n",
      "93 c6a1a0d1\n",
      "94 799941cb\n",
      "95 a92f468a\n",
      "96 0d820bc7\n",
      "97 9dfc6558\n",
      "98 3f639fed\n",
      "99 f151753a\n",
      "100 0d29f58c\n",
      "101 718a93b8\n",
      "102 f2c4e032\n",
      "103 1c9623a5\n",
      "104 c453546b\n",
      "105 bd6855bb\n",
      "106 80201e73\n",
      "107 c690365e\n",
      "108 7845c46d\n",
      "109 8e1d1870\n",
      "110 33c704f0\n",
      "111 52fc4b30\n",
      "112 6df753f4\n",
      "113 0980ecf3\n",
      "114 04d55e6a\n",
      "115 e27f28be\n",
      "116 b0b6749d\n",
      "117 477c3997\n",
      "118 1b9a4249\n",
      "119 13a24a0e\n",
      "120 deb2e257\n",
      "121 e8554baf\n",
      "122 307fd254\n",
      "123 97240310\n",
      "124 0823f904\n",
      "125 ba3e1964\n",
      "126 c39baeb8\n",
      "127 41ccaa73\n",
      "128 f41af028\n",
      "129 a4934fa1\n",
      "130 bb199b7e\n",
      "131 82ba0f12\n",
      "132 b17132cf\n",
      "133 8f1b1d05\n",
      "134 4710730c\n",
      "135 3965ad40\n",
      "136 c24587f1\n",
      "137 4883fda1\n",
      "138 dcd798ec\n",
      "139 49c61083\n",
      "140 919d0968\n",
      "141 38e926b9\n",
      "142 146c7d5c\n",
      "143 214f24fa\n",
      "144 5db0fdc9\n",
      "145 36ea0203\n",
      "146 d5634f79\n",
      "147 7a9d2ab7\n",
      "148 61dc34a5\n",
      "149 7773df35\n",
      "150 9e5fe349\n",
      "151 42d10eb5\n",
      "152 ddc53aab\n",
      "153 c71306e1\n",
      "154 de9a47fe\n",
      "155 7b96cdd6\n",
      "156 cc536e91\n",
      "157 840ef2ee\n",
      "158 bc1ff2be\n",
      "159 e907db32\n",
      "160 cb8174a4\n",
      "161 6935bde1\n",
      "162 22624011\n",
      "163 cb7f3f9d\n",
      "164 c3771d47\n",
      "165 8c44fb34\n",
      "166 541d6d32\n",
      "167 d5d216a7\n",
      "168 b90fa769\n",
      "169 58fd9072\n",
      "170 f03ca9d2\n",
      "171 f5caa467\n",
      "172 c3a9dce0\n",
      "173 ebfa8b82\n",
      "174 8072c55d\n",
      "175 9f154a38\n",
      "176 b5b7a982\n",
      "177 7ac5bd16\n",
      "178 b87247c0\n",
      "179 017f206b\n",
      "180 576b40f2\n",
      "181 9388f561\n",
      "182 b6c1b022\n",
      "183 5aa60f00\n",
      "184 cd81157c\n",
      "185 e1da530d\n",
      "186 67267a49\n",
      "187 3d83c7cf\n",
      "188 19ea29be\n",
      "189 4236bb10\n",
      "190 d99e5081\n",
      "191 51d234ae\n",
      "192 9cfe9617\n",
      "193 d8520030\n",
      "194 6e62271a\n",
      "195 9512f5f3\n",
      "196 c5111b82\n",
      "197 26ea6cd0\n",
      "198 eee3ce3a\n",
      "199 369b577d\n"
     ]
    }
   ],
   "source": [
    "%cd /Users/loaner/projects/dd-biomassters/\n",
    "dd = DataDownloader(phase='train', dataroot='data/', dataset_size=200, chip_is_complete=True)\n",
    "dd.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12800, 256) -12.469111 3.4001684\n",
      "0.5000004 0.4999999\n",
      "-12.469111 3.4001684\n"
     ]
    }
   ],
   "source": [
    "yy = np.concatenate([data['y'] for data in dd.images])\n",
    "mean = yy.mean()\n",
    "std = yy.std()\n",
    "print(yy.shape, mean, std)\n",
    "yy_scaled = (yy-mean)/std * .5 + .5\n",
    "print(yy_scaled.mean(), yy_scaled.std())\n",
    "\n",
    "yy_scaled_invert = ((yy_scaled - .5) / .5 * std) + mean\n",
    "print(yy_scaled_invert.mean(), yy_scaled_invert.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0, 0.574639, 0.0068725203, 0.008914556)"
      ]
     },
     "execution_count": 367,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_list = [data['y'] for data in dd.images]\n",
    "y_flat = np.concatenate(y_list).flatten()\n",
    "y_max=1e4\n",
    "y_flat = y_flat/y_max\n",
    "df = pd.DataFrame(y_flat)\n",
    "df.hist(bins=60)\n",
    "min(y_flat), max(y_flat), np.mean(y_flat), np.std(y_flat)\n",
    "# y_t = (y_flat-.5) / .5\n",
    "# min(y_t), max(y_t), np.mean(y_t), np.std(y_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50, 256, 256, 4) mean: [-12.47562  -19.737421 -12.25755  -19.234262] std: [3.3957279 4.483836  4.1778703 5.884509 ]\n"
     ]
    }
   ],
   "source": [
    "yy = np.stack([data['X'][:,:,:4] for data in dd.images])\n",
    "mean = np.mean(yy, axis=(0,1,2))\n",
    "std = np.std(yy, axis=(0,1,2))\n",
    "print(yy.shape, 'mean:', mean, 'std:', std)\n",
    "# yy_scaled = (yy-mean)/std * .5 + .5\n",
    "# print(yy_scaled.mean(), yy_scaled.std())\n",
    "\n",
    "# yy_scaled_invert = ((yy_scaled - .5) / .5 * std) + mean\n",
    "# print(yy_scaled_invert.mean(), yy_scaled_invert.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-12.47562 3.3957279\n",
      "-19.737421 4.483836\n",
      "-12.25755 4.1778703\n",
      "-19.234262 5.884509\n"
     ]
    }
   ],
   "source": [
    "X_mean = [-12.47562, -19.737421, -12.25755, -19.234262]\n",
    "X_std = [3.3957279, 4.483836, 4.1778703, 5.884509 ]\n",
    "X = data['X'][:,:,:4]\n",
    "for d, (m, s) in enumerate(zip(X_mean, X_std)):\n",
    "    print(m,s)\n",
    "    X[:,:,d] = (X[:,:,d] - m) / s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.21489711"
      ]
     },
     "execution_count": 316,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# data['X'][:,:,:4].shape\n",
    "X.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[<AxesSubplot: title={'center': '0'}>]], dtype=object)"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_list = [data['y'] for data in dd.images]\n",
    "y_flat = np.concatenate(y_list[:1]).flatten()\n",
    "y_flat = (y_flat - mean) / std\n",
    "y_flat = np.log(y_flat+1)\n",
    "df = pd.DataFrame(y_flat)\n",
    "# df[df>0].hist(bins=100)\n",
    "df.hist(bins=60)\n",
    "# df.hist(bins=np.arange(-1,15,.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/loaner/projects/dd-biomassters\n"
     ]
    }
   ],
   "source": [
    "%cd /Users/loaner/projects/dd-biomassters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test via command line interface"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "!python ./pix2pix/test.py --dataroot ./data --name biomassters --model pix2pix --direction AtoB --input_nc 180 \\\n",
    "    --dataset_mode biomassters --gpu_ids -1 --results_dir ./results/ --phase validation \\\n",
    "    --max_dataset_size 10 --preprocess \"\" --no_dropout\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/loaner/projects/dd-biomassters\n",
      "----------------- Options ---------------\n",
      "               batch_size: 10                            \t[default: 1]\n",
      "                    beta1: 0.5                           \n",
      "          checkpoints_dir: ./checkpoints                 \n",
      "           continue_train: False                         \n",
      "                crop_size: 256                           \n",
      "                 dataroot: ./data                        \t[default: data]\n",
      "             dataset_mode: biomassters                   \t[default: aligned]\n",
      "                direction: AtoB                          \n",
      "              display_env: main                          \n",
      "             display_freq: 100                           \t[default: 400]\n",
      "               display_id: 1                             \n",
      "            display_ncols: 4                             \n",
      "             display_port: 8097                          \n",
      "           display_server: http://localhost              \n",
      "          display_winsize: 256                           \n",
      "                    epoch: latest                        \n",
      "              epoch_count: 1                             \n",
      "                 gan_mode: vanilla                       \n",
      "                  gpu_ids: -1                            \t[default: 0]\n",
      "                init_gain: 0.02                          \n",
      "                init_type: normal                        \n",
      "                 input_nc: 4                             \t[default: 3]\n",
      "                  isTrain: True                          \t[default: None]\n",
      "                lambda_L1: 100.0                         \n",
      "                load_iter: 0                             \t[default: 0]\n",
      "                load_size: 286                           \n",
      "                       lr: 0.0002                        \n",
      "           lr_decay_iters: 50                            \n",
      "                lr_policy: linear                        \n",
      "         max_dataset_size: 100                           \t[default: inf]\n",
      "                    model: pix2pix                       \t[default: cycle_gan]\n",
      "                 n_epochs: 100                           \n",
      "           n_epochs_decay: 100                           \n",
      "               n_layers_D: 3                             \n",
      "                     name: biomassters_softplus_b3p0     \t[default: experiment_name]\n",
      "                      ndf: 64                            \n",
      "                     netD: basic                         \n",
      "                     netG: unet_256                      \n",
      "                      ngf: 64                            \n",
      "               no_dropout: False                         \n",
      "                  no_flip: True                          \t[default: False]\n",
      "                  no_html: False                         \n",
      "                     norm: batch                         \n",
      "              num_threads: 4                             \n",
      "                output_nc: 1                             \t[default: 3]\n",
      "                    phase: train                         \n",
      "                pool_size: 0                             \n",
      "               preprocess:                               \t[default: resize_and_crop]\n",
      "               print_freq: 100                           \n",
      "             save_by_iter: False                         \n",
      "          save_epoch_freq: 5                             \n",
      "         save_latest_freq: 5000                          \n",
      "           serial_batches: False                         \n",
      "                   suffix:                               \n",
      "         update_html_freq: 100                           \t[default: 1000]\n",
      "                use_wandb: False                         \n",
      "                  verbose: False                         \n",
      "       wandb_project_name: CycleGAN-and-pix2pix          \n",
      "----------------- End -------------------\n",
      "dataset [BioMasstersDataset] was created\n",
      "The number of training images = 100\n",
      "initialize network with normal\n",
      "initialize network with normal\n",
      "model [Pix2PixModel] was created\n",
      "---------- Networks initialized -------------\n",
      "[Network G] Total number of parameters : 54.411 M\n",
      "[Network D] Total number of parameters : 2.768 M\n",
      "-----------------------------------------------\n",
      "Setting up a new session...\n",
      "create web directory ./checkpoints/biomassters_softplus_b3p0/web...\n",
      "/Users/loaner/.pyenv/versions/3.8.15/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:138: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  warnings.warn(\"Detected call of `lr_scheduler.step()` before `optimizer.step()`. \"\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "real_A shape: torch.Size([10, 4, 256, 256]) max: 8.600046 mean: -0.026949953 min: -3.6275392\n",
      "fake_B shape: torch.Size([10, 1, 256, 256]) max: 1.7985626 mean: 0.42338172 min: 0.0021262474\n",
      "real_B shape: torch.Size([10, 1, 256, 256]) max: 35.554623 mean: 1.0828012 min: 0.0\n",
      "fake_B_inverted shape: torch.Size([10, 1, 256, 256]) max: 114.05704 mean: 26.84903 min: 0.13483739\n",
      "real_B_inverted shape: torch.Size([10, 1, 256, 256]) max: 2254.72 mean: 68.66655 min: 0.0\n",
      "RMSE: 95.922516\n",
      "saving html\n",
      "(epoch: 1, iters: 100, time: 1.290, data: 9.728) G_GAN: 0.825 G_L1: 82.473 D_real: 0.690 D_fake: 0.847 \n",
      "End of epoch 1 / 200 \t Time Taken: 154 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "real_A shape: torch.Size([10, 4, 256, 256]) max: 7.587265 mean: 0.21098666 min: -3.38226\n",
      "fake_B shape: torch.Size([10, 1, 256, 256]) max: 2.2173035 mean: 0.6186556 min: 0.0012262702\n",
      "real_B shape: torch.Size([10, 1, 256, 256]) max: 73.918175 mean: 1.0486528 min: 0.0\n",
      "fake_B_inverted shape: torch.Size([10, 1, 256, 256]) max: 140.61177 mean: 39.232452 min: 0.077764735\n",
      "real_B_inverted shape: torch.Size([10, 1, 256, 256]) max: 4687.57 mean: 66.501 min: 0.0\n",
      "RMSE: 78.37484\n",
      "saving html\n",
      "(epoch: 2, iters: 100, time: 1.218, data: 13.847) G_GAN: 0.841 G_L1: 67.638 D_real: 0.717 D_fake: 0.687 \n",
      "End of epoch 2 / 200 \t Time Taken: 159 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "real_A shape: torch.Size([10, 4, 256, 256]) max: 8.6378 mean: -0.016915549 min: -3.683715\n",
      "fake_B shape: torch.Size([10, 1, 256, 256]) max: 4.805387 mean: 0.73930484 min: 0.0009443222\n",
      "real_B shape: torch.Size([10, 1, 256, 256]) max: 37.956238 mean: 1.0379331 min: 0.0\n",
      "fake_B_inverted shape: torch.Size([10, 1, 256, 256]) max: 304.7368 mean: 46.883507 min: 0.059884816\n",
      "real_B_inverted shape: torch.Size([10, 1, 256, 256]) max: 2407.02 mean: 65.82121 min: 0.0\n",
      "RMSE: 77.94412\n",
      "saving html\n",
      "(epoch: 3, iters: 100, time: 1.257, data: 10.227) G_GAN: 0.819 G_L1: 66.143 D_real: 0.704 D_fake: 0.715 \n",
      "End of epoch 3 / 200 \t Time Taken: 153 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "real_A shape: torch.Size([10, 4, 256, 256]) max: 9.242048 mean: 0.39888182 min: -3.865085\n",
      "fake_B shape: torch.Size([10, 1, 256, 256]) max: 4.6979213 mean: 0.78221905 min: 0.00052420807\n",
      "real_B shape: torch.Size([10, 1, 256, 256]) max: 55.61008 mean: 1.0574144 min: 0.0\n",
      "fake_B_inverted shape: torch.Size([10, 1, 256, 256]) max: 297.92178 mean: 49.604942 min: 0.033243\n",
      "real_B_inverted shape: torch.Size([10, 1, 256, 256]) max: 3526.55 mean: 67.05664 min: 0.0\n",
      "RMSE: 72.50668\n",
      "saving html\n",
      "(epoch: 4, iters: 100, time: 1.237, data: 18.665) G_GAN: 1.018 G_L1: 65.623 D_real: 0.628 D_fake: 0.528 \n",
      "End of epoch 4 / 200 \t Time Taken: 166 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "real_A shape: torch.Size([10, 4, 256, 256]) max: 7.994336 mean: 0.25077787 min: -3.683715\n",
      "fake_B shape: torch.Size([10, 1, 256, 256]) max: 5.482075 mean: 0.83030736 min: 0.0001349392\n",
      "real_B shape: torch.Size([10, 1, 256, 256]) max: 67.54041 mean: 1.132449 min: 0.0\n",
      "fake_B_inverted shape: torch.Size([10, 1, 256, 256]) max: 347.6494 mean: 52.65449 min: 0.008557258\n",
      "real_B_inverted shape: torch.Size([10, 1, 256, 256]) max: 4283.12 mean: 71.81501 min: 0.0\n",
      "RMSE: 74.231346\n",
      "saving html\n",
      "(epoch: 5, iters: 100, time: 1.223, data: 13.229) G_GAN: 0.952 G_L1: 64.192 D_real: 0.524 D_fake: 0.656 \n",
      "saving the model at the end of epoch 5, iters 500\n",
      "End of epoch 5 / 200 \t Time Taken: 158 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "real_A shape: torch.Size([10, 4, 256, 256]) max: 7.8842535 mean: 0.45701584 min: -6.2594895\n",
      "fake_B shape: torch.Size([10, 1, 256, 256]) max: 4.073519 mean: 0.87168294 min: 3.007041e-05\n",
      "real_B shape: torch.Size([10, 1, 256, 256]) max: 50.913292 mean: 1.2124332 min: 0.0\n",
      "fake_B_inverted shape: torch.Size([10, 1, 256, 256]) max: 258.32492 mean: 55.278343 min: 0.001906935\n",
      "real_B_inverted shape: torch.Size([10, 1, 256, 256]) max: 3228.7 mean: 76.88727 min: 0.0\n",
      "RMSE: 71.717094\n",
      "saving html\n",
      "(epoch: 6, iters: 100, time: 1.221, data: 11.741) G_GAN: 1.195 G_L1: 63.565 D_real: 0.549 D_fake: 0.454 \n",
      "End of epoch 6 / 200 \t Time Taken: 154 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "real_A shape: torch.Size([10, 4, 256, 256]) max: 5.9119744 mean: 0.18037257 min: -3.6275392\n",
      "fake_B shape: torch.Size([10, 1, 256, 256]) max: 3.6207848 mean: 0.8982588 min: 0.00022215101\n",
      "real_B shape: torch.Size([10, 1, 256, 256]) max: 73.918175 mean: 0.9775276 min: 0.0\n",
      "fake_B_inverted shape: torch.Size([10, 1, 256, 256]) max: 229.61446 mean: 56.963684 min: 0.014087853\n",
      "real_B_inverted shape: torch.Size([10, 1, 256, 256]) max: 4687.57 mean: 61.99055 min: 0.0\n",
      "RMSE: 63.935005\n",
      "saving html\n",
      "(epoch: 7, iters: 100, time: 1.216, data: 13.560) G_GAN: 1.062 G_L1: 55.283 D_real: 0.425 D_fake: 0.562 \n",
      "End of epoch 7 / 200 \t Time Taken: 156 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "real_A shape: torch.Size([10, 4, 256, 256]) max: 7.8317804 mean: 0.16554713 min: -4.2943535\n",
      "fake_B shape: torch.Size([10, 1, 256, 256]) max: 4.6306577 mean: 0.88470376 min: 2.764839e-05\n",
      "real_B shape: torch.Size([10, 1, 256, 256]) max: 74.41238 mean: 0.970216 min: 0.0\n",
      "fake_B_inverted shape: torch.Size([10, 1, 256, 256]) max: 293.65622 mean: 56.104076 min: 0.0017533409\n",
      "real_B_inverted shape: torch.Size([10, 1, 256, 256]) max: 4718.91 mean: 61.526894 min: 0.0\n",
      "RMSE: 64.63516\n",
      "saving html\n",
      "(epoch: 8, iters: 100, time: 1.201, data: 12.673) G_GAN: 0.959 G_L1: 55.256 D_real: 0.436 D_fake: 0.778 \n",
      "End of epoch 8 / 200 \t Time Taken: 157 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "real_A shape: torch.Size([10, 4, 256, 256]) max: 7.8317804 mean: 0.21800487 min: -3.8647614\n",
      "fake_B shape: torch.Size([10, 1, 256, 256]) max: 4.5683417 mean: 0.8993273 min: 4.7613194e-06\n",
      "real_B shape: torch.Size([10, 1, 256, 256]) max: 55.61008 mean: 0.99257505 min: 0.0\n",
      "fake_B_inverted shape: torch.Size([10, 1, 256, 256]) max: 289.7044 mean: 57.031433 min: 0.0003019422\n",
      "real_B_inverted shape: torch.Size([10, 1, 256, 256]) max: 3526.55 mean: 62.944813 min: 0.0\n",
      "RMSE: 55.333763\n",
      "saving html\n",
      "(epoch: 9, iters: 100, time: 1.250, data: 11.839) G_GAN: 0.975 G_L1: 49.417 D_real: 0.864 D_fake: 0.448 \n",
      "End of epoch 9 / 200 \t Time Taken: 154 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "real_A shape: torch.Size([10, 4, 256, 256]) max: 8.6378 mean: 0.13195829 min: -6.2594895\n",
      "fake_B shape: torch.Size([10, 1, 256, 256]) max: 5.641951 mean: 0.7480537 min: 5.738941e-06\n",
      "real_B shape: torch.Size([10, 1, 256, 256]) max: 50.913292 mean: 0.96384394 min: 0.0\n",
      "fake_B_inverted shape: torch.Size([10, 1, 256, 256]) max: 357.78806 mean: 47.438316 min: 0.00036393874\n",
      "real_B_inverted shape: torch.Size([10, 1, 256, 256]) max: 3228.7 mean: 61.12279 min: 0.0\n",
      "RMSE: 70.90286\n",
      "saving html\n",
      "(epoch: 10, iters: 100, time: 1.204, data: 13.105) G_GAN: 0.921 G_L1: 62.293 D_real: 0.288 D_fake: 0.780 \n",
      "saving the model at the end of epoch 10, iters 1000\n",
      "End of epoch 10 / 200 \t Time Taken: 156 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "real_A shape: torch.Size([10, 4, 256, 256]) max: 7.026938 mean: 0.1059404 min: -3.6275392\n",
      "fake_B shape: torch.Size([10, 1, 256, 256]) max: 4.5052676 mean: 0.83676165 min: 9.9674915e-05\n",
      "real_B shape: torch.Size([10, 1, 256, 256]) max: 55.61008 mean: 0.87733155 min: 0.0\n",
      "fake_B_inverted shape: torch.Size([10, 1, 256, 256]) max: 285.70453 mean: 53.063793 min: 0.0063209506\n",
      "real_B_inverted shape: torch.Size([10, 1, 256, 256]) max: 3526.55 mean: 55.63656 min: 0.0\n",
      "RMSE: 58.013462\n",
      "saving html\n",
      "(epoch: 11, iters: 100, time: 1.214, data: 12.592) G_GAN: 0.863 G_L1: 49.506 D_real: 0.668 D_fake: 0.388 \n",
      "End of epoch 11 / 200 \t Time Taken: 153 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "real_A shape: torch.Size([10, 4, 256, 256]) max: 9.767428 mean: 0.47145978 min: -3.2025332\n",
      "fake_B shape: torch.Size([10, 1, 256, 256]) max: 6.106706 mean: 0.88386554 min: 1.2298715e-05\n",
      "real_B shape: torch.Size([10, 1, 256, 256]) max: 46.684208 mean: 1.1174988 min: 0.0\n",
      "fake_B_inverted shape: torch.Size([10, 1, 256, 256]) max: 387.2608 mean: 56.050915 min: 0.00077993114\n",
      "real_B_inverted shape: torch.Size([10, 1, 256, 256]) max: 2960.51 mean: 70.86692 min: 0.0\n",
      "RMSE: 67.12378\n",
      "saving html\n",
      "(epoch: 12, iters: 100, time: 1.208, data: 10.253) G_GAN: 1.095 G_L1: 57.263 D_real: 0.533 D_fake: 0.675 \n",
      "End of epoch 12 / 200 \t Time Taken: 152 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "real_A shape: torch.Size([10, 4, 256, 256]) max: 9.767428 mean: 0.0326034 min: -3.6275392\n",
      "fake_B shape: torch.Size([10, 1, 256, 256]) max: 5.3893447 mean: 0.8734066 min: 1.1827884e-06\n",
      "real_B shape: torch.Size([10, 1, 256, 256]) max: 37.745407 mean: 1.209869 min: 0.0\n",
      "fake_B_inverted shape: torch.Size([10, 1, 256, 256]) max: 341.76886 mean: 55.387657 min: 7.500731e-05\n",
      "real_B_inverted shape: torch.Size([10, 1, 256, 256]) max: 2393.65 mean: 76.72465 min: 0.0\n",
      "RMSE: 71.5676\n",
      "saving html\n",
      "(epoch: 13, iters: 100, time: 1.211, data: 10.133) G_GAN: 1.206 G_L1: 58.700 D_real: 0.550 D_fake: 0.455 \n",
      "End of epoch 13 / 200 \t Time Taken: 156 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "real_A shape: torch.Size([10, 4, 256, 256]) max: 9.242048 mean: 0.29796085 min: -3.477169\n",
      "fake_B shape: torch.Size([10, 1, 256, 256]) max: 6.8563 mean: 0.9099642 min: 6.1601e-06\n",
      "real_B shape: torch.Size([10, 1, 256, 256]) max: 44.738163 mean: 1.1367204 min: 0.0\n",
      "fake_B_inverted shape: torch.Size([10, 1, 256, 256]) max: 434.79678 mean: 57.705982 min: 0.0003906468\n",
      "real_B_inverted shape: torch.Size([10, 1, 256, 256]) max: 2837.1 mean: 72.08586 min: 0.0\n",
      "RMSE: 69.23655\n",
      "saving html\n",
      "(epoch: 14, iters: 100, time: 1.224, data: 13.139) G_GAN: 1.225 G_L1: 58.286 D_real: 0.406 D_fake: 0.558 \n",
      "End of epoch 14 / 200 \t Time Taken: 155 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "real_A shape: torch.Size([10, 4, 256, 256]) max: 8.600046 mean: 0.26863962 min: -4.051862\n",
      "fake_B shape: torch.Size([10, 1, 256, 256]) max: 8.549351 mean: 0.9919488 min: 7.2573766e-06\n",
      "real_B shape: torch.Size([10, 1, 256, 256]) max: 36.607517 mean: 1.113653 min: 0.0\n",
      "fake_B_inverted shape: torch.Size([10, 1, 256, 256]) max: 542.1627 mean: 62.90509 min: 0.00046023133\n",
      "real_B_inverted shape: torch.Size([10, 1, 256, 256]) max: 2321.49 mean: 70.62305 min: 0.0\n",
      "RMSE: 58.60248\n",
      "saving html\n",
      "(epoch: 15, iters: 100, time: 1.215, data: 10.086) G_GAN: 0.761 G_L1: 50.840 D_real: 0.937 D_fake: 0.963 \n",
      "saving the model at the end of epoch 15, iters 1500\n",
      "End of epoch 15 / 200 \t Time Taken: 158 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "real_A shape: torch.Size([10, 4, 256, 256]) max: 9.767428 mean: -0.047317374 min: -3.6275392\n",
      "fake_B shape: torch.Size([10, 1, 256, 256]) max: 7.4201217 mean: 0.8935214 min: 2.2333354e-05\n",
      "real_B shape: torch.Size([10, 1, 256, 256]) max: 32.6432 mean: 1.027794 min: 0.0\n",
      "fake_B_inverted shape: torch.Size([10, 1, 256, 256]) max: 470.5519 mean: 56.663246 min: 0.0014162844\n",
      "real_B_inverted shape: torch.Size([10, 1, 256, 256]) max: 2070.09 mean: 65.17824 min: 0.0\n",
      "RMSE: 60.83164\n",
      "saving html\n",
      "(epoch: 16, iters: 100, time: 1.235, data: 12.449) G_GAN: 1.114 G_L1: 49.186 D_real: 0.361 D_fake: 0.981 \n",
      "End of epoch 16 / 200 \t Time Taken: 155 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "real_A shape: torch.Size([10, 4, 256, 256]) max: 7.33078 mean: 0.44311816 min: -3.4478276\n",
      "fake_B shape: torch.Size([10, 1, 256, 256]) max: 5.667744 mean: 0.9754488 min: 1.4750514e-06\n",
      "real_B shape: torch.Size([10, 1, 256, 256]) max: 74.41238 mean: 1.2474549 min: 0.0\n",
      "fake_B_inverted shape: torch.Size([10, 1, 256, 256]) max: 359.42374 mean: 61.858727 min: 9.3541355e-05\n",
      "real_B_inverted shape: torch.Size([10, 1, 256, 256]) max: 4718.91 mean: 79.10817 min: 0.0\n",
      "RMSE: 59.606697\n",
      "saving html\n",
      "(epoch: 17, iters: 100, time: 1.217, data: 10.514) G_GAN: 1.376 G_L1: 52.874 D_real: 0.419 D_fake: 0.439 \n",
      "End of epoch 17 / 200 \t Time Taken: 154 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "real_A shape: torch.Size([10, 4, 256, 256]) max: 9.242048 mean: 0.6126998 min: -6.2594895\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fake_B shape: torch.Size([10, 1, 256, 256]) max: 7.0631714 mean: 0.9600035 min: 1.1021207e-06\n",
      "real_B shape: torch.Size([10, 1, 256, 256]) max: 50.913292 mean: 1.260802 min: 0.0\n",
      "fake_B_inverted shape: torch.Size([10, 1, 256, 256]) max: 447.91568 mean: 60.87925 min: 6.9891714e-05\n",
      "real_B_inverted shape: torch.Size([10, 1, 256, 256]) max: 3228.7 mean: 79.95459 min: 0.0\n",
      "RMSE: 64.43398\n",
      "saving html\n",
      "(epoch: 18, iters: 100, time: 1.210, data: 9.757) G_GAN: 1.169 G_L1: 58.067 D_real: 0.519 D_fake: 0.433 \n",
      "End of epoch 18 / 200 \t Time Taken: 151 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "real_A shape: torch.Size([10, 4, 256, 256]) max: 7.994336 mean: 0.49832186 min: -3.865085\n",
      "fake_B shape: torch.Size([10, 1, 256, 256]) max: 6.647507 mean: 0.9407457 min: 5.192513e-06\n",
      "real_B shape: torch.Size([10, 1, 256, 256]) max: 73.918175 mean: 1.0174105 min: 0.0\n",
      "fake_B_inverted shape: torch.Size([10, 1, 256, 256]) max: 421.55606 mean: 59.658012 min: 0.00032928665\n",
      "real_B_inverted shape: torch.Size([10, 1, 256, 256]) max: 4687.57 mean: 64.51975 min: 0.0\n",
      "RMSE: 59.458405\n",
      "saving html\n",
      "(epoch: 19, iters: 100, time: 1.216, data: 13.012) G_GAN: 1.178 G_L1: 49.793 D_real: 0.450 D_fake: 0.596 \n",
      "End of epoch 19 / 200 \t Time Taken: 155 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "real_A shape: torch.Size([10, 4, 256, 256]) max: 6.8651295 mean: 0.42977524 min: -4.2943535\n",
      "fake_B shape: torch.Size([10, 1, 256, 256]) max: 6.293779 mean: 1.0029663 min: 1.2380406e-06\n",
      "real_B shape: torch.Size([10, 1, 256, 256]) max: 74.41238 mean: 1.2082717 min: 0.0\n",
      "fake_B_inverted shape: torch.Size([10, 1, 256, 256]) max: 399.12415 mean: 63.60377 min: 7.851116e-05\n",
      "real_B_inverted shape: torch.Size([10, 1, 256, 256]) max: 4718.91 mean: 76.62335 min: 0.0\n",
      "RMSE: 57.10714\n",
      "saving html\n",
      "(epoch: 20, iters: 100, time: 1.211, data: 10.638) G_GAN: 0.479 G_L1: 50.578 D_real: 0.767 D_fake: 0.316 \n",
      "saving the model at the end of epoch 20, iters 2000\n",
      "End of epoch 20 / 200 \t Time Taken: 154 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "real_A shape: torch.Size([10, 4, 256, 256]) max: 9.233964 mean: 0.47395912 min: -6.2594895\n",
      "fake_B shape: torch.Size([10, 1, 256, 256]) max: 6.688969 mean: 0.96293366 min: 4.7194485e-06\n",
      "real_B shape: torch.Size([10, 1, 256, 256]) max: 50.913292 mean: 1.1248248 min: 0.0\n",
      "fake_B_inverted shape: torch.Size([10, 1, 256, 256]) max: 424.1854 mean: 61.06507 min: 0.00029928694\n",
      "real_B_inverted shape: torch.Size([10, 1, 256, 256]) max: 3228.7 mean: 71.331505 min: 0.0\n",
      "RMSE: 62.73158\n",
      "saving html\n",
      "(epoch: 21, iters: 100, time: 1.234, data: 13.717) G_GAN: 0.947 G_L1: 53.094 D_real: 0.454 D_fake: 0.383 \n",
      "End of epoch 21 / 200 \t Time Taken: 156 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "real_A shape: torch.Size([10, 4, 256, 256]) max: 8.561171 mean: 0.19003832 min: -3.5459752\n",
      "fake_B shape: torch.Size([10, 1, 256, 256]) max: 6.8848214 mean: 0.88273704 min: 7.3346787e-06\n",
      "real_B shape: torch.Size([10, 1, 256, 256]) max: 34.115547 mean: 1.0226905 min: 0.0\n",
      "fake_B_inverted shape: torch.Size([10, 1, 256, 256]) max: 436.6055 mean: 55.97936 min: 0.0004651335\n",
      "real_B_inverted shape: torch.Size([10, 1, 256, 256]) max: 2163.46 mean: 64.8546 min: 0.0\n",
      "RMSE: 53.115826\n",
      "saving html\n",
      "(epoch: 22, iters: 100, time: 1.206, data: 13.397) G_GAN: 0.737 G_L1: 44.381 D_real: 0.623 D_fake: 0.746 \n",
      "End of epoch 22 / 200 \t Time Taken: 155 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "real_A shape: torch.Size([10, 4, 256, 256]) max: 7.8317804 mean: 0.4146924 min: -3.8210413\n",
      "fake_B shape: torch.Size([10, 1, 256, 256]) max: 7.035553 mean: 0.9612315 min: 5.1201937e-06\n",
      "real_B shape: torch.Size([10, 1, 256, 256]) max: 67.54041 mean: 1.0426505 min: 0.0\n",
      "fake_B_inverted shape: torch.Size([10, 1, 256, 256]) max: 446.16425 mean: 60.95713 min: 0.00032470046\n",
      "real_B_inverted shape: torch.Size([10, 1, 256, 256]) max: 4283.12 mean: 66.12036 min: 0.0\n",
      "RMSE: 55.275963\n",
      "saving html\n",
      "(epoch: 23, iters: 100, time: 1.213, data: 9.374) G_GAN: 1.606 G_L1: 45.781 D_real: 0.264 D_fake: 0.980 \n",
      "End of epoch 23 / 200 \t Time Taken: 151 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "real_A shape: torch.Size([10, 4, 256, 256]) max: 7.7945876 mean: 0.16407049 min: -3.365688\n",
      "fake_B shape: torch.Size([10, 1, 256, 256]) max: 7.663511 mean: 0.9243313 min: 1.5252425e-06\n",
      "real_B shape: torch.Size([10, 1, 256, 256]) max: 46.684208 mean: 0.9975912 min: 0.0\n",
      "fake_B_inverted shape: torch.Size([10, 1, 256, 256]) max: 485.9866 mean: 58.617077 min: 9.672426e-05\n",
      "real_B_inverted shape: torch.Size([10, 1, 256, 256]) max: 2960.51 mean: 63.2629 min: 0.0\n",
      "RMSE: 50.645744\n",
      "saving html\n",
      "(epoch: 24, iters: 100, time: 1.213, data: 10.767) G_GAN: 1.180 G_L1: 40.481 D_real: 0.780 D_fake: 0.512 \n",
      "End of epoch 24 / 200 \t Time Taken: 152 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "real_A shape: torch.Size([10, 4, 256, 256]) max: 10.11356 mean: 0.25243416 min: -3.5837924\n",
      "fake_B shape: torch.Size([10, 1, 256, 256]) max: 7.431572 mean: 0.98000634 min: 7.000465e-06\n",
      "real_B shape: torch.Size([10, 1, 256, 256]) max: 58.405605 mean: 1.1264138 min: 0.0\n",
      "fake_B_inverted shape: torch.Size([10, 1, 256, 256]) max: 471.27805 mean: 62.147743 min: 0.0004439391\n",
      "real_B_inverted shape: torch.Size([10, 1, 256, 256]) max: 3703.83 mean: 71.432274 min: 0.0\n",
      "RMSE: 61.58496\n",
      "saving html\n",
      "(epoch: 25, iters: 100, time: 1.210, data: 11.545) G_GAN: 1.007 G_L1: 48.902 D_real: 0.523 D_fake: 0.388 \n",
      "saving the model at the end of epoch 25, iters 2500\n",
      "End of epoch 25 / 200 \t Time Taken: 156 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "real_A shape: torch.Size([10, 4, 256, 256]) max: 7.587265 mean: 0.2112331 min: -3.5837924\n",
      "fake_B shape: torch.Size([10, 1, 256, 256]) max: 7.0922875 mean: 0.85415137 min: 2.9539463e-06\n",
      "real_B shape: torch.Size([10, 1, 256, 256]) max: 55.61008 mean: 1.0833875 min: 0.0\n",
      "fake_B_inverted shape: torch.Size([10, 1, 256, 256]) max: 449.76212 mean: 54.166576 min: 0.00018732646\n",
      "real_B_inverted shape: torch.Size([10, 1, 256, 256]) max: 3526.55 mean: 68.70372 min: 0.0\n",
      "RMSE: 56.387512\n",
      "saving html\n",
      "(epoch: 26, iters: 100, time: 1.218, data: 13.254) G_GAN: 1.319 G_L1: 44.708 D_real: 0.239 D_fake: 0.477 \n",
      "End of epoch 26 / 200 \t Time Taken: 157 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "real_A shape: torch.Size([10, 4, 256, 256]) max: 6.084272 mean: 0.09585929 min: -3.5837924\n",
      "fake_B shape: torch.Size([10, 1, 256, 256]) max: 7.152831 mean: 0.99562913 min: 2.359621e-06\n",
      "real_B shape: torch.Size([10, 1, 256, 256]) max: 37.078068 mean: 0.9459313 min: 0.0\n",
      "fake_B_inverted shape: torch.Size([10, 1, 256, 256]) max: 453.6015 mean: 63.13848 min: 0.00014963692\n",
      "real_B_inverted shape: torch.Size([10, 1, 256, 256]) max: 2351.33 mean: 59.986866 min: 0.0\n",
      "RMSE: 40.321575\n",
      "saving html\n",
      "(epoch: 27, iters: 100, time: 1.251, data: 13.718) G_GAN: 0.675 G_L1: 34.687 D_real: 0.780 D_fake: 0.451 \n",
      "End of epoch 27 / 200 \t Time Taken: 156 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "real_A shape: torch.Size([10, 4, 256, 256]) max: 8.561171 mean: 0.5271862 min: -3.3241448\n",
      "fake_B shape: torch.Size([10, 1, 256, 256]) max: 7.421277 mean: 1.002206 min: 2.313238e-07\n",
      "real_B shape: torch.Size([10, 1, 256, 256]) max: 73.918175 mean: 1.2616765 min: 0.0\n",
      "fake_B_inverted shape: torch.Size([10, 1, 256, 256]) max: 470.62518 mean: 63.555553 min: 1.4669551e-05\n",
      "real_B_inverted shape: torch.Size([10, 1, 256, 256]) max: 4687.57 mean: 80.010056 min: 0.0\n",
      "RMSE: 58.876945\n",
      "saving html\n",
      "(epoch: 28, iters: 100, time: 1.401, data: 13.875) G_GAN: 1.076 G_L1: 51.172 D_real: 0.414 D_fake: 0.413 \n",
      "End of epoch 28 / 200 \t Time Taken: 165 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "real_A shape: torch.Size([10, 4, 256, 256]) max: 7.33078 mean: 0.37054887 min: -3.4133644\n",
      "fake_B shape: torch.Size([10, 1, 256, 256]) max: 8.097964 mean: 0.96690714 min: 6.486818e-08\n",
      "real_B shape: torch.Size([10, 1, 256, 256]) max: 67.54041 mean: 1.2214295 min: 0.0\n",
      "fake_B_inverted shape: torch.Size([10, 1, 256, 256]) max: 513.5378 mean: 61.317055 min: 4.1136586e-06\n",
      "real_B_inverted shape: torch.Size([10, 1, 256, 256]) max: 4283.12 mean: 77.457756 min: 0.0\n",
      "RMSE: 55.66461\n",
      "saving html\n",
      "(epoch: 29, iters: 100, time: 1.477, data: 15.192) G_GAN: 2.113 G_L1: 47.120 D_real: 0.173 D_fake: 0.250 \n",
      "End of epoch 29 / 200 \t Time Taken: 176 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "real_A shape: torch.Size([10, 4, 256, 256]) max: 9.242048 mean: 0.079923674 min: -3.578535\n",
      "fake_B shape: torch.Size([10, 1, 256, 256]) max: 9.720937 mean: 0.9843032 min: 3.4142265e-06\n",
      "real_B shape: torch.Size([10, 1, 256, 256]) max: 74.41238 mean: 0.9771158 min: 0.0\n",
      "fake_B_inverted shape: torch.Size([10, 1, 256, 256]) max: 616.45966 mean: 62.420235 min: 0.00021651543\n",
      "real_B_inverted shape: torch.Size([10, 1, 256, 256]) max: 4718.91 mean: 61.96444 min: 0.0\n",
      "RMSE: 50.641655\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving html\n",
      "(epoch: 30, iters: 100, time: 1.375, data: 14.399) G_GAN: 1.277 G_L1: 41.025 D_real: 0.522 D_fake: 0.185 \n",
      "saving the model at the end of epoch 30, iters 3000\n",
      "End of epoch 30 / 200 \t Time Taken: 172 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "real_A shape: torch.Size([10, 4, 256, 256]) max: 5.5547905 mean: 0.67459327 min: -3.8647614\n",
      "fake_B shape: torch.Size([10, 1, 256, 256]) max: 7.1307707 mean: 1.0577368 min: 2.218003e-08\n",
      "real_B shape: torch.Size([10, 1, 256, 256]) max: 58.405605 mean: 1.2365239 min: 0.0\n",
      "fake_B_inverted shape: torch.Size([10, 1, 256, 256]) max: 452.20255 mean: 67.07707 min: 1.4065613e-06\n",
      "real_B_inverted shape: torch.Size([10, 1, 256, 256]) max: 3703.83 mean: 78.41498 min: 0.0\n",
      "RMSE: 54.01496\n",
      "saving html\n",
      "(epoch: 31, iters: 100, time: 1.457, data: 15.192) G_GAN: 2.004 G_L1: 47.616 D_real: 0.188 D_fake: 0.456 \n",
      "End of epoch 31 / 200 \t Time Taken: 176 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "real_A shape: torch.Size([10, 4, 256, 256]) max: 7.587265 mean: 0.34680003 min: -3.4478276\n",
      "fake_B shape: torch.Size([10, 1, 256, 256]) max: 7.096055 mean: 0.9492413 min: 4.5615266e-07\n",
      "real_B shape: torch.Size([10, 1, 256, 256]) max: 37.078068 mean: 0.94578534 min: 0.0\n",
      "fake_B_inverted shape: torch.Size([10, 1, 256, 256]) max: 450.001 mean: 60.19676 min: 2.8927223e-05\n",
      "real_B_inverted shape: torch.Size([10, 1, 256, 256]) max: 2351.33 mean: 59.9776 min: 0.0\n",
      "RMSE: 43.73274\n",
      "saving html\n",
      "(epoch: 32, iters: 100, time: 1.397, data: 13.575) G_GAN: 1.914 G_L1: 36.163 D_real: 0.182 D_fake: 0.426 \n",
      "End of epoch 32 / 200 \t Time Taken: 169 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "real_A shape: torch.Size([10, 4, 256, 256]) max: 6.4212174 mean: -0.35424158 min: -3.683715\n",
      "fake_B shape: torch.Size([10, 1, 256, 256]) max: 8.976613 mean: 0.923776 min: 8.340226e-07\n",
      "real_B shape: torch.Size([10, 1, 256, 256]) max: 43.180817 mean: 0.88199884 min: 0.0\n",
      "fake_B_inverted shape: torch.Size([10, 1, 256, 256]) max: 569.2579 mean: 58.58186 min: 5.2890096e-05\n",
      "real_B_inverted shape: torch.Size([10, 1, 256, 256]) max: 2738.34 mean: 55.932545 min: 0.0\n",
      "RMSE: 46.329655\n",
      "saving html\n",
      "(epoch: 33, iters: 100, time: 1.339, data: 17.291) G_GAN: 2.103 G_L1: 35.882 D_real: 0.160 D_fake: 0.428 \n",
      "End of epoch 33 / 200 \t Time Taken: 184 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "real_A shape: torch.Size([10, 4, 256, 256]) max: 7.5661025 mean: 0.3833798 min: -3.8210413\n",
      "fake_B shape: torch.Size([10, 1, 256, 256]) max: 7.9860377 mean: 1.0115906 min: 6.311034e-08\n",
      "real_B shape: torch.Size([10, 1, 256, 256]) max: 58.405605 mean: 1.1434679 min: 0.0\n",
      "fake_B_inverted shape: torch.Size([10, 1, 256, 256]) max: 506.43985 mean: 64.15068 min: 4.002184e-06\n",
      "real_B_inverted shape: torch.Size([10, 1, 256, 256]) max: 3703.83 mean: 72.51378 min: 0.0\n",
      "RMSE: 51.574085\n",
      "saving html\n",
      "(epoch: 34, iters: 100, time: 1.374, data: 14.206) G_GAN: 1.779 G_L1: 42.427 D_real: 0.512 D_fake: 0.381 \n",
      "End of epoch 34 / 200 \t Time Taken: 171 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "real_A shape: torch.Size([10, 4, 256, 256]) max: 10.11356 mean: 0.30463848 min: -3.4478276\n",
      "fake_B shape: torch.Size([10, 1, 256, 256]) max: 7.7812047 mean: 0.90294963 min: 4.6558395e-07\n",
      "real_B shape: torch.Size([10, 1, 256, 256]) max: 37.078068 mean: 1.235279 min: 0.0\n",
      "fake_B_inverted shape: torch.Size([10, 1, 256, 256]) max: 493.45023 mean: 57.261147 min: 2.9525314e-05\n",
      "real_B_inverted shape: torch.Size([10, 1, 256, 256]) max: 2351.33 mean: 78.33602 min: 0.0\n",
      "RMSE: 66.37719\n",
      "saving html\n",
      "(epoch: 35, iters: 100, time: 1.360, data: 16.258) G_GAN: 1.759 G_L1: 52.559 D_real: 0.390 D_fake: 0.151 \n",
      "saving the model at the end of epoch 35, iters 3500\n",
      "End of epoch 35 / 200 \t Time Taken: 179 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "real_A shape: torch.Size([10, 4, 256, 256]) max: 8.600046 mean: 0.2659345 min: -3.5837924\n",
      "fake_B shape: torch.Size([10, 1, 256, 256]) max: 10.450084 mean: 0.9678365 min: 1.2246527e-07\n",
      "real_B shape: torch.Size([10, 1, 256, 256]) max: 44.700787 mean: 0.93603975 min: 0.0\n",
      "fake_B_inverted shape: torch.Size([10, 1, 256, 256]) max: 662.699 mean: 61.375988 min: 7.766216e-06\n",
      "real_B_inverted shape: torch.Size([10, 1, 256, 256]) max: 2834.73 mean: 59.359577 min: 0.0\n",
      "RMSE: 49.510303\n",
      "saving html\n",
      "(epoch: 36, iters: 100, time: 1.919, data: 16.903) G_GAN: 1.826 G_L1: 39.438 D_real: 0.356 D_fake: 0.116 \n",
      "End of epoch 36 / 200 \t Time Taken: 179 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "real_A shape: torch.Size([10, 4, 256, 256]) max: 7.33078 mean: 0.21427207 min: -3.5837924\n",
      "fake_B shape: torch.Size([10, 1, 256, 256]) max: 7.9227166 mean: 0.9704894 min: 6.4255e-08\n",
      "real_B shape: torch.Size([10, 1, 256, 256]) max: 37.745407 mean: 1.1908836 min: 0.0\n",
      "fake_B_inverted shape: torch.Size([10, 1, 256, 256]) max: 502.42432 mean: 61.544228 min: 4.074773e-06\n",
      "real_B_inverted shape: torch.Size([10, 1, 256, 256]) max: 2393.65 mean: 75.520676 min: 0.0\n",
      "RMSE: 53.24459\n",
      "saving html\n",
      "(epoch: 37, iters: 100, time: 1.211, data: 14.435) G_GAN: 2.051 G_L1: 43.531 D_real: 0.171 D_fake: 0.860 \n",
      "End of epoch 37 / 200 \t Time Taken: 164 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "real_A shape: torch.Size([10, 4, 256, 256]) max: 9.767428 mean: 0.31545785 min: -3.8210413\n",
      "fake_B shape: torch.Size([10, 1, 256, 256]) max: 8.894043 mean: 0.9718655 min: 1.155914e-07\n",
      "real_B shape: torch.Size([10, 1, 256, 256]) max: 46.684208 mean: 1.2064346 min: 0.0\n",
      "fake_B_inverted shape: torch.Size([10, 1, 256, 256]) max: 564.0216 mean: 61.63149 min: 7.330305e-06\n",
      "real_B_inverted shape: torch.Size([10, 1, 256, 256]) max: 2960.51 mean: 76.50686 min: 0.0\n",
      "RMSE: 60.036404\n",
      "saving html\n",
      "(epoch: 38, iters: 100, time: 1.300, data: 13.534) G_GAN: 2.738 G_L1: 48.139 D_real: 0.062 D_fake: 0.990 \n",
      "End of epoch 38 / 200 \t Time Taken: 163 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "real_A shape: torch.Size([10, 4, 256, 256]) max: 7.994336 mean: 0.50387406 min: -3.38226\n",
      "fake_B shape: torch.Size([10, 1, 256, 256]) max: 8.022141 mean: 1.0496271 min: 1.0910519e-08\n",
      "real_B shape: torch.Size([10, 1, 256, 256]) max: 54.255207 mean: 1.2767617 min: 0.0\n",
      "fake_B_inverted shape: torch.Size([10, 1, 256, 256]) max: 508.7294 mean: 66.56279 min: 6.9189775e-07\n",
      "real_B_inverted shape: torch.Size([10, 1, 256, 256]) max: 3440.63 mean: 80.96669 min: 0.0\n",
      "RMSE: 54.90589\n",
      "saving html\n",
      "(epoch: 39, iters: 100, time: 1.261, data: 12.448) G_GAN: 2.883 G_L1: 46.827 D_real: 0.136 D_fake: 0.110 \n",
      "End of epoch 39 / 200 \t Time Taken: 158 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "real_A shape: torch.Size([10, 4, 256, 256]) max: 8.113412 mean: 0.21599765 min: -3.38226\n",
      "fake_B shape: torch.Size([10, 1, 256, 256]) max: 10.580939 mean: 1.060694 min: 6.081876e-08\n",
      "real_B shape: torch.Size([10, 1, 256, 256]) max: 30.833078 mean: 1.1670948 min: 0.0\n",
      "fake_B_inverted shape: torch.Size([10, 1, 256, 256]) max: 670.99725 mean: 67.26461 min: 3.856862e-06\n",
      "real_B_inverted shape: torch.Size([10, 1, 256, 256]) max: 1955.3 mean: 74.012085 min: 0.0\n",
      "RMSE: 47.08784\n",
      "saving html\n",
      "(epoch: 40, iters: 100, time: 1.235, data: 12.768) G_GAN: 2.573 G_L1: 40.769 D_real: 0.247 D_fake: 0.045 \n",
      "saving the model at the end of epoch 40, iters 4000\n",
      "End of epoch 40 / 200 \t Time Taken: 168 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "real_A shape: torch.Size([10, 4, 256, 256]) max: 7.587265 mean: 0.31981295 min: -3.8210413\n",
      "fake_B shape: torch.Size([10, 1, 256, 256]) max: 9.288635 mean: 1.0247327 min: 8.607146e-08\n",
      "real_B shape: torch.Size([10, 1, 256, 256]) max: 54.255207 mean: 1.0657974 min: 0.0\n",
      "fake_B_inverted shape: torch.Size([10, 1, 256, 256]) max: 589.0449 mean: 64.9841 min: 5.4582783e-06\n",
      "real_B_inverted shape: torch.Size([10, 1, 256, 256]) max: 3440.63 mean: 67.58824 min: 0.0\n",
      "RMSE: 46.061558\n",
      "saving html\n",
      "(epoch: 41, iters: 100, time: 1.214, data: 11.393) G_GAN: 2.111 G_L1: 38.651 D_real: 0.246 D_fake: 0.831 \n",
      "End of epoch 41 / 200 \t Time Taken: 152 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "real_A shape: torch.Size([10, 4, 256, 256]) max: 10.11356 mean: 0.5788235 min: -3.5837924\n",
      "fake_B shape: torch.Size([10, 1, 256, 256]) max: 9.140143 mean: 1.0560467 min: 2.0681043e-08\n",
      "real_B shape: torch.Size([10, 1, 256, 256]) max: 43.701035 mean: 1.1709645 min: 0.0\n",
      "fake_B_inverted shape: torch.Size([10, 1, 256, 256]) max: 579.62823 mean: 66.969894 min: 1.3115019e-06\n",
      "real_B_inverted shape: torch.Size([10, 1, 256, 256]) max: 2771.33 mean: 74.257484 min: 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 63.889614\n",
      "saving html\n",
      "(epoch: 42, iters: 100, time: 1.314, data: 12.241) G_GAN: 2.715 G_L1: 52.799 D_real: 0.142 D_fake: 0.069 \n",
      "End of epoch 42 / 200 \t Time Taken: 159 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "real_A shape: torch.Size([10, 4, 256, 256]) max: 7.587265 mean: 0.2131106 min: -4.051862\n",
      "fake_B shape: torch.Size([10, 1, 256, 256]) max: 10.844383 mean: 1.0451527 min: 4.3528928e-10\n",
      "real_B shape: torch.Size([10, 1, 256, 256]) max: 44.738163 mean: 1.1198515 min: 0.0\n",
      "fake_B_inverted shape: torch.Size([10, 1, 256, 256]) max: 687.70374 mean: 66.279045 min: 2.7604157e-08\n",
      "real_B_inverted shape: torch.Size([10, 1, 256, 256]) max: 2837.1 mean: 71.01613 min: 0.0\n",
      "RMSE: 46.414864\n",
      "saving html\n",
      "(epoch: 43, iters: 100, time: 1.250, data: 12.769) G_GAN: 1.830 G_L1: 38.368 D_real: 0.208 D_fake: 0.261 \n",
      "End of epoch 43 / 200 \t Time Taken: 153 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "real_A shape: torch.Size([10, 4, 256, 256]) max: 10.11356 mean: 0.29713455 min: -3.6275392\n",
      "fake_B shape: torch.Size([10, 1, 256, 256]) max: 11.819483 mean: 0.95748216 min: 8.440859e-09\n",
      "real_B shape: torch.Size([10, 1, 256, 256]) max: 67.54041 mean: 1.265866 min: 0.0\n",
      "fake_B_inverted shape: torch.Size([10, 1, 256, 256]) max: 749.5403 mean: 60.719368 min: 5.3528265e-07\n",
      "real_B_inverted shape: torch.Size([10, 1, 256, 256]) max: 4283.12 mean: 80.27574 min: 0.0\n",
      "RMSE: 65.56812\n",
      "saving html\n",
      "(epoch: 44, iters: 100, time: 1.298, data: 14.502) G_GAN: 2.801 G_L1: 52.080 D_real: 0.104 D_fake: 0.195 \n",
      "End of epoch 44 / 200 \t Time Taken: 163 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "real_A shape: torch.Size([10, 4, 256, 256]) max: 7.8842535 mean: -0.0270089 min: -3.8210413\n",
      "fake_B shape: torch.Size([10, 1, 256, 256]) max: 10.507562 mean: 0.95457774 min: 6.880036e-09\n",
      "real_B shape: torch.Size([10, 1, 256, 256]) max: 57.138252 mean: 0.92276 min: 0.0\n",
      "fake_B_inverted shape: torch.Size([10, 1, 256, 256]) max: 666.344 mean: 60.53518 min: 4.3630203e-07\n",
      "real_B_inverted shape: torch.Size([10, 1, 256, 256]) max: 3623.46 mean: 58.517445 min: 0.0\n",
      "RMSE: 44.563145\n",
      "saving html\n",
      "(epoch: 45, iters: 100, time: 1.211, data: 12.262) G_GAN: 2.632 G_L1: 35.052 D_real: 0.092 D_fake: 0.134 \n",
      "saving the model at the end of epoch 45, iters 4500\n",
      "End of epoch 45 / 200 \t Time Taken: 155 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "real_A shape: torch.Size([10, 4, 256, 256]) max: 7.8025866 mean: 0.5051654 min: -6.2594895\n",
      "fake_B shape: torch.Size([10, 1, 256, 256]) max: 10.222312 mean: 1.004945 min: 3.013785e-11\n",
      "real_B shape: torch.Size([10, 1, 256, 256]) max: 50.913292 mean: 1.1341184 min: 0.0\n",
      "fake_B_inverted shape: torch.Size([10, 1, 256, 256]) max: 648.2547 mean: 63.72926 min: 1.9112116e-09\n",
      "real_B_inverted shape: torch.Size([10, 1, 256, 256]) max: 3228.7 mean: 71.92087 min: 0.0\n",
      "RMSE: 50.608574\n",
      "saving html\n",
      "(epoch: 46, iters: 100, time: 1.224, data: 12.783) G_GAN: 2.999 G_L1: 43.128 D_real: 0.123 D_fake: 0.173 \n",
      "End of epoch 46 / 200 \t Time Taken: 159 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "real_A shape: torch.Size([10, 4, 256, 256]) max: 9.233964 mean: 0.4054795 min: -3.8647614\n",
      "fake_B shape: torch.Size([10, 1, 256, 256]) max: 9.371466 mean: 0.98093605 min: 2.8149145e-09\n",
      "real_B shape: torch.Size([10, 1, 256, 256]) max: 58.405605 mean: 1.0922581 min: 0.0\n",
      "fake_B_inverted shape: torch.Size([10, 1, 256, 256]) max: 594.29767 mean: 62.206703 min: 1.7850967e-07\n",
      "real_B_inverted shape: torch.Size([10, 1, 256, 256]) max: 3703.83 mean: 69.26627 min: 0.0\n",
      "RMSE: 52.834404\n",
      "saving html\n",
      "(epoch: 47, iters: 100, time: 1.244, data: 12.770) G_GAN: 3.674 G_L1: 42.152 D_real: 0.135 D_fake: 0.032 \n",
      "End of epoch 47 / 200 \t Time Taken: 153 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "real_A shape: torch.Size([10, 4, 256, 256]) max: 9.767428 mean: 0.1940035 min: -6.2594895\n",
      "fake_B shape: torch.Size([10, 1, 256, 256]) max: 15.554169 mean: 0.93678457 min: 9.971614e-09\n",
      "real_B shape: torch.Size([10, 1, 256, 256]) max: 57.138252 mean: 1.0404297 min: 0.0\n",
      "fake_B_inverted shape: torch.Size([10, 1, 256, 256]) max: 986.37787 mean: 59.40681 min: 6.323565e-07\n",
      "real_B_inverted shape: torch.Size([10, 1, 256, 256]) max: 3623.46 mean: 65.97953 min: 0.0\n",
      "RMSE: 51.912003\n",
      "saving html\n",
      "(epoch: 48, iters: 100, time: 1.260, data: 9.525) G_GAN: 2.786 G_L1: 40.596 D_real: 0.082 D_fake: 0.161 \n",
      "End of epoch 48 / 200 \t Time Taken: 155 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "real_A shape: torch.Size([10, 4, 256, 256]) max: 7.8317804 mean: 0.33543327 min: -3.38226\n",
      "fake_B shape: torch.Size([10, 1, 256, 256]) max: 13.087816 mean: 1.0646719 min: 1.0681113e-09\n",
      "real_B shape: torch.Size([10, 1, 256, 256]) max: 74.41238 mean: 1.1439087 min: 0.0\n",
      "fake_B_inverted shape: torch.Size([10, 1, 256, 256]) max: 829.97253 mean: 67.51687 min: 6.773498e-08\n",
      "real_B_inverted shape: torch.Size([10, 1, 256, 256]) max: 4718.91 mean: 72.541725 min: 0.0\n",
      "RMSE: 49.1025\n",
      "saving html\n",
      "(epoch: 49, iters: 100, time: 1.236, data: 13.202) G_GAN: 2.316 G_L1: 40.620 D_real: 0.043 D_fake: 0.457 \n",
      "End of epoch 49 / 200 \t Time Taken: 159 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "real_A shape: torch.Size([10, 4, 256, 256]) max: 7.994336 mean: 0.061627485 min: -3.683715\n",
      "fake_B shape: torch.Size([10, 1, 256, 256]) max: 10.889368 mean: 0.948043 min: 1.7384775e-09\n",
      "real_B shape: torch.Size([10, 1, 256, 256]) max: 73.918175 mean: 0.9384721 min: 0.0\n",
      "fake_B_inverted shape: torch.Size([10, 1, 256, 256]) max: 690.55646 mean: 60.120777 min: 1.10246695e-07\n",
      "real_B_inverted shape: torch.Size([10, 1, 256, 256]) max: 4687.57 mean: 59.513824 min: 0.0\n",
      "RMSE: 46.790653\n",
      "saving html\n",
      "(epoch: 50, iters: 100, time: 1.216, data: 11.401) G_GAN: 3.083 G_L1: 35.558 D_real: 0.042 D_fake: 0.082 \n",
      "saving the latest model (epoch 50, total_iters 5000)\n",
      "saving the model at the end of epoch 50, iters 5000\n",
      "End of epoch 50 / 200 \t Time Taken: 163 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "real_A shape: torch.Size([10, 4, 256, 256]) max: 8.600046 mean: 0.3749223 min: -3.865085\n",
      "fake_B shape: torch.Size([10, 1, 256, 256]) max: 12.170156 mean: 0.9800266 min: 7.731615e-12\n",
      "real_B shape: torch.Size([10, 1, 256, 256]) max: 55.61008 mean: 1.0428822 min: 0.0\n",
      "fake_B_inverted shape: torch.Size([10, 1, 256, 256]) max: 771.77844 mean: 62.149036 min: 4.9030546e-10\n",
      "real_B_inverted shape: torch.Size([10, 1, 256, 256]) max: 3526.55 mean: 66.13507 min: 0.0\n",
      "RMSE: 46.419018\n",
      "saving html\n",
      "(epoch: 51, iters: 100, time: 1.266, data: 12.864) G_GAN: 2.681 G_L1: 37.135 D_real: 0.071 D_fake: 0.096 \n",
      "End of epoch 51 / 200 \t Time Taken: 154 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "real_A shape: torch.Size([10, 4, 256, 256]) max: 6.3803477 mean: 0.47714862 min: -3.8647614\n",
      "fake_B shape: torch.Size([10, 1, 256, 256]) max: 9.6804695 mean: 1.1015322 min: 1.2110888e-12\n",
      "real_B shape: torch.Size([10, 1, 256, 256]) max: 43.180817 mean: 1.2296622 min: 0.0\n",
      "fake_B_inverted shape: torch.Size([10, 1, 256, 256]) max: 613.8934 mean: 69.85439 min: 7.6802e-11\n",
      "real_B_inverted shape: torch.Size([10, 1, 256, 256]) max: 2738.34 mean: 77.97984 min: 0.0\n",
      "RMSE: 48.063915\n",
      "saving html\n",
      "(epoch: 52, iters: 100, time: 1.216, data: 11.137) G_GAN: 3.141 G_L1: 41.428 D_real: 0.174 D_fake: 0.033 \n",
      "End of epoch 52 / 200 \t Time Taken: 156 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "real_A shape: torch.Size([10, 4, 256, 256]) max: 8.6378 mean: 0.06366502 min: -3.5459752\n",
      "fake_B shape: torch.Size([10, 1, 256, 256]) max: 19.962156 mean: 0.96473885 min: 2.6305656e-15\n",
      "real_B shape: torch.Size([10, 1, 256, 256]) max: 35.554623 mean: 1.1311971 min: 0.0\n",
      "fake_B_inverted shape: torch.Size([10, 1, 256, 256]) max: 1265.9133 mean: 61.179554 min: 1.6681906e-13\n",
      "real_B_inverted shape: torch.Size([10, 1, 256, 256]) max: 2254.72 mean: 71.73561 min: 0.0\n",
      "RMSE: 48.210194\n",
      "saving html\n",
      "(epoch: 53, iters: 100, time: 1.252, data: 9.864) G_GAN: 3.641 G_L1: 37.746 D_real: 0.023 D_fake: 0.880 \n",
      "End of epoch 53 / 200 \t Time Taken: 151 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "real_A shape: torch.Size([10, 4, 256, 256]) max: 8.600046 mean: 0.06845043 min: -3.865085\n",
      "fake_B shape: torch.Size([10, 1, 256, 256]) max: 15.597193 mean: 0.94083613 min: 9.681697e-10\n",
      "real_B shape: torch.Size([10, 1, 256, 256]) max: 37.078068 mean: 0.85465205 min: 0.0\n",
      "fake_B_inverted shape: torch.Size([10, 1, 256, 256]) max: 989.10626 mean: 59.663746 min: 6.139712e-08\n",
      "real_B_inverted shape: torch.Size([10, 1, 256, 256]) max: 2351.33 mean: 54.198326 min: 0.0\n",
      "RMSE: 44.731106\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving html\n",
      "(epoch: 54, iters: 100, time: 1.242, data: 10.080) G_GAN: 1.999 G_L1: 34.516 D_real: 0.281 D_fake: 0.040 \n",
      "End of epoch 54 / 200 \t Time Taken: 156 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "real_A shape: torch.Size([10, 4, 256, 256]) max: 8.600046 mean: 0.33450952 min: -3.2836716\n",
      "fake_B shape: torch.Size([10, 1, 256, 256]) max: 19.423702 mean: 1.0514146 min: 6.4152984e-16\n",
      "real_B shape: torch.Size([10, 1, 256, 256]) max: 74.41238 mean: 1.0076424 min: 0.0\n",
      "fake_B_inverted shape: torch.Size([10, 1, 256, 256]) max: 1231.767 mean: 66.67616 min: 4.068304e-14\n",
      "real_B_inverted shape: torch.Size([10, 1, 256, 256]) max: 4718.91 mean: 63.900307 min: 0.0\n",
      "RMSE: 47.873756\n",
      "saving html\n",
      "(epoch: 55, iters: 100, time: 1.261, data: 13.016) G_GAN: 3.670 G_L1: 37.679 D_real: 0.083 D_fake: 0.025 \n",
      "saving the model at the end of epoch 55, iters 5500\n",
      "End of epoch 55 / 200 \t Time Taken: 157 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "real_A shape: torch.Size([10, 4, 256, 256]) max: 10.11356 mean: 0.28374332 min: -3.683715\n",
      "fake_B shape: torch.Size([10, 1, 256, 256]) max: 14.575982 mean: 0.9672491 min: 5.6040117e-13\n",
      "real_B shape: torch.Size([10, 1, 256, 256]) max: 57.138252 mean: 1.0519193 min: 0.0\n",
      "fake_B_inverted shape: torch.Size([10, 1, 256, 256]) max: 924.3455 mean: 61.338745 min: 3.553821e-11\n",
      "real_B_inverted shape: torch.Size([10, 1, 256, 256]) max: 3623.46 mean: 66.70816 min: 0.0\n",
      "RMSE: 52.724068\n",
      "saving html\n",
      "(epoch: 56, iters: 100, time: 1.233, data: 11.489) G_GAN: 2.209 G_L1: 40.636 D_real: 0.198 D_fake: 0.304 \n",
      "End of epoch 56 / 200 \t Time Taken: 158 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "real_A shape: torch.Size([10, 4, 256, 256]) max: 7.994336 mean: 0.31871372 min: -3.8647614\n",
      "fake_B shape: torch.Size([10, 1, 256, 256]) max: 18.104465 mean: 1.0439832 min: 1.4035977e-18\n",
      "real_B shape: torch.Size([10, 1, 256, 256]) max: 74.41238 mean: 1.2059612 min: 0.0\n",
      "fake_B_inverted shape: torch.Size([10, 1, 256, 256]) max: 1148.1067 mean: 66.20488 min: 8.9010073e-17\n",
      "real_B_inverted shape: torch.Size([10, 1, 256, 256]) max: 4718.91 mean: 76.47682 min: 0.0\n",
      "RMSE: 52.9957\n",
      "saving html\n",
      "(epoch: 57, iters: 100, time: 1.243, data: 10.187) G_GAN: 2.799 G_L1: 42.022 D_real: 0.099 D_fake: 0.218 \n",
      "End of epoch 57 / 200 \t Time Taken: 152 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "real_A shape: torch.Size([10, 4, 256, 256]) max: 7.8317804 mean: 0.068745844 min: -4.051862\n",
      "fake_B shape: torch.Size([10, 1, 256, 256]) max: 12.306003 mean: 0.98519343 min: 8.7578556e-13\n",
      "real_B shape: torch.Size([10, 1, 256, 256]) max: 33.503395 mean: 1.1005872 min: 0.0\n",
      "fake_B_inverted shape: torch.Size([10, 1, 256, 256]) max: 780.3933 mean: 62.476696 min: 5.5538518e-11\n",
      "real_B_inverted shape: torch.Size([10, 1, 256, 256]) max: 2124.64 mean: 69.79447 min: 0.0\n",
      "RMSE: 48.496475\n",
      "saving html\n",
      "(epoch: 58, iters: 100, time: 1.211, data: 9.495) G_GAN: 1.758 G_L1: 39.251 D_real: 0.461 D_fake: 0.055 \n",
      "End of epoch 58 / 200 \t Time Taken: 154 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "real_A shape: torch.Size([10, 4, 256, 256]) max: 8.6378 mean: 0.020962197 min: -4.2943535\n",
      "fake_B shape: torch.Size([10, 1, 256, 256]) max: 36.1536 mean: 1.0236238 min: 1.6964593e-22\n",
      "real_B shape: torch.Size([10, 1, 256, 256]) max: 43.180817 mean: 0.96031606 min: 0.0\n",
      "fake_B_inverted shape: torch.Size([10, 1, 256, 256]) max: 2292.7043 mean: 64.91378 min: 1.07582085e-20\n",
      "real_B_inverted shape: torch.Size([10, 1, 256, 256]) max: 2738.34 mean: 60.89908 min: 0.0\n",
      "RMSE: 43.21242\n",
      "saving html\n",
      "(epoch: 59, iters: 100, time: 1.263, data: 9.844) G_GAN: 2.460 G_L1: 33.784 D_real: 0.385 D_fake: 0.208 \n",
      "End of epoch 59 / 200 \t Time Taken: 150 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "real_A shape: torch.Size([10, 4, 256, 256]) max: 7.7945876 mean: 0.02989607 min: -3.578535\n",
      "fake_B shape: torch.Size([10, 1, 256, 256]) max: 12.375748 mean: 0.7684881 min: 1.0013979e-09\n",
      "real_B shape: torch.Size([10, 1, 256, 256]) max: 46.684208 mean: 0.7777871 min: 0.0\n",
      "fake_B_inverted shape: torch.Size([10, 1, 256, 256]) max: 784.8162 mean: 48.734184 min: 6.350431e-08\n",
      "real_B_inverted shape: torch.Size([10, 1, 256, 256]) max: 2960.51 mean: 49.32388 min: 0.0\n",
      "RMSE: 41.678486\n",
      "saving html\n",
      "(epoch: 60, iters: 100, time: 1.210, data: 13.800) G_GAN: 2.909 G_L1: 30.085 D_real: 0.068 D_fake: 0.316 \n",
      "saving the model at the end of epoch 60, iters 6000\n",
      "End of epoch 60 / 200 \t Time Taken: 161 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "real_A shape: torch.Size([10, 4, 256, 256]) max: 6.4212174 mean: 0.3495286 min: -3.865085\n",
      "fake_B shape: torch.Size([10, 1, 256, 256]) max: 33.373024 mean: 1.0168808 min: 6.688241e-21\n",
      "real_B shape: torch.Size([10, 1, 256, 256]) max: 58.405605 mean: 1.1175463 min: 0.0\n",
      "fake_B_inverted shape: torch.Size([10, 1, 256, 256]) max: 2116.3723 mean: 64.48617 min: 4.2413924e-19\n",
      "real_B_inverted shape: torch.Size([10, 1, 256, 256]) max: 3703.83 mean: 70.869934 min: 0.0\n",
      "RMSE: 46.869972\n",
      "saving html\n",
      "(epoch: 61, iters: 100, time: 1.235, data: 11.526) G_GAN: 1.728 G_L1: 37.209 D_real: 0.321 D_fake: 0.040 \n",
      "End of epoch 61 / 200 \t Time Taken: 154 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "real_A shape: torch.Size([10, 4, 256, 256]) max: 8.6378 mean: 0.21245268 min: -4.051862\n",
      "fake_B shape: torch.Size([10, 1, 256, 256]) max: 49.830624 mean: 1.0029633 min: 3.277366e-37\n",
      "real_B shape: torch.Size([10, 1, 256, 256]) max: 74.41238 mean: 1.1304595 min: 0.0\n",
      "fake_B_inverted shape: torch.Size([10, 1, 256, 256]) max: 3160.042 mean: 63.603577 min: 2.0783633e-35\n",
      "real_B_inverted shape: torch.Size([10, 1, 256, 256]) max: 4718.91 mean: 71.68884 min: 0.0\n",
      "RMSE: 50.322094\n",
      "saving html\n",
      "(epoch: 62, iters: 100, time: 1.245, data: 10.911) G_GAN: 2.884 G_L1: 37.823 D_real: 0.080 D_fake: 0.133 \n",
      "End of epoch 62 / 200 \t Time Taken: 156 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "real_A shape: torch.Size([10, 4, 256, 256]) max: 7.587265 mean: -0.25871366 min: -4.2943535\n",
      "fake_B shape: torch.Size([10, 1, 256, 256]) max: 11.324647 mean: 0.82909787 min: 7.6489987e-10\n",
      "real_B shape: torch.Size([10, 1, 256, 256]) max: 37.745407 mean: 0.8368371 min: 0.0\n",
      "fake_B_inverted shape: torch.Size([10, 1, 256, 256]) max: 718.16 mean: 52.57778 min: 4.850663e-08\n",
      "real_B_inverted shape: torch.Size([10, 1, 256, 256]) max: 2393.65 mean: 53.06858 min: 0.0\n",
      "RMSE: 37.007015\n",
      "saving html\n",
      "(epoch: 63, iters: 100, time: 1.275, data: 9.290) G_GAN: 3.615 G_L1: 27.085 D_real: 0.115 D_fake: 0.391 \n",
      "End of epoch 63 / 200 \t Time Taken: 150 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "real_A shape: torch.Size([10, 4, 256, 256]) max: 5.4866724 mean: 0.21316643 min: -4.2943535\n",
      "fake_B shape: torch.Size([10, 1, 256, 256]) max: 89.792114 mean: 0.8590226 min: 0.0\n",
      "real_B shape: torch.Size([10, 1, 256, 256]) max: 54.255207 mean: 0.9759289 min: 0.0\n",
      "fake_B_inverted shape: torch.Size([10, 1, 256, 256]) max: 5694.226 mean: 54.475487 min: 0.0\n",
      "real_B_inverted shape: torch.Size([10, 1, 256, 256]) max: 3440.63 mean: 61.88917 min: 0.0\n",
      "RMSE: 47.68852\n",
      "saving html\n",
      "(epoch: 64, iters: 100, time: 1.213, data: 9.698) G_GAN: 0.197 G_L1: 31.819 D_real: 1.432 D_fake: 0.078 \n",
      "End of epoch 64 / 200 \t Time Taken: 155 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "real_A shape: torch.Size([10, 4, 256, 256]) max: 9.242048 mean: 0.27229774 min: -3.8647614\n",
      "fake_B shape: torch.Size([10, 1, 256, 256]) max: 137.33049 mean: 0.99094695 min: 0.0\n",
      "real_B shape: torch.Size([10, 1, 256, 256]) max: 73.918175 mean: 0.9495322 min: 0.0\n",
      "fake_B_inverted shape: torch.Size([10, 1, 256, 256]) max: 8708.903 mean: 62.841553 min: 0.0\n",
      "real_B_inverted shape: torch.Size([10, 1, 256, 256]) max: 4687.57 mean: 60.21521 min: 0.0\n",
      "RMSE: 49.426125\n",
      "saving html\n",
      "(epoch: 65, iters: 100, time: 1.281, data: 13.021) G_GAN: 2.044 G_L1: 33.672 D_real: 0.246 D_fake: 0.062 \n",
      "saving the model at the end of epoch 65, iters 6500\n",
      "End of epoch 65 / 200 \t Time Taken: 159 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "real_A shape: torch.Size([10, 4, 256, 256]) max: 8.600046 mean: 0.48356742 min: -6.2594895\n",
      "fake_B shape: torch.Size([10, 1, 256, 256]) max: 67.0758 mean: 1.0054369 min: 1.048872e-38\n",
      "real_B shape: torch.Size([10, 1, 256, 256]) max: 50.913292 mean: 1.0861489 min: 0.0\n",
      "fake_B_inverted shape: torch.Size([10, 1, 256, 256]) max: 4253.6562 mean: 63.76045 min: 6.651491e-37\n",
      "real_B_inverted shape: torch.Size([10, 1, 256, 256]) max: 3228.7 mean: 68.878845 min: 0.0\n",
      "RMSE: 53.311535\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving html\n",
      "(epoch: 66, iters: 100, time: 1.295, data: 12.764) G_GAN: 3.036 G_L1: 38.367 D_real: 0.087 D_fake: 0.081 \n",
      "End of epoch 66 / 200 \t Time Taken: 158 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "real_A shape: torch.Size([10, 4, 256, 256]) max: 9.233964 mean: 0.24639389 min: -3.3638265\n",
      "fake_B shape: torch.Size([10, 1, 256, 256]) max: 17.646992 mean: 0.96936166 min: 2.643666e-13\n",
      "real_B shape: torch.Size([10, 1, 256, 256]) max: 55.61008 mean: 0.9339577 min: 0.0\n",
      "fake_B_inverted shape: torch.Size([10, 1, 256, 256]) max: 1119.0957 mean: 61.472717 min: 1.6764982e-11\n",
      "real_B_inverted shape: torch.Size([10, 1, 256, 256]) max: 3526.55 mean: 59.22754 min: 0.0\n",
      "RMSE: 45.876633\n",
      "saving html\n",
      "(epoch: 67, iters: 100, time: 1.245, data: 9.699) G_GAN: 3.162 G_L1: 35.000 D_real: 0.098 D_fake: 0.126 \n",
      "End of epoch 67 / 200 \t Time Taken: 151 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "real_A shape: torch.Size([10, 4, 256, 256]) max: 9.233964 mean: 0.5361334 min: -3.8647614\n",
      "fake_B shape: torch.Size([10, 1, 256, 256]) max: 14.669832 mean: 1.1377318 min: 4.179155e-14\n",
      "real_B shape: torch.Size([10, 1, 256, 256]) max: 46.684208 mean: 1.2317253 min: 0.0\n",
      "fake_B_inverted shape: torch.Size([10, 1, 256, 256]) max: 930.2971 mean: 72.15 min: 2.6502388e-12\n",
      "real_B_inverted shape: torch.Size([10, 1, 256, 256]) max: 2960.51 mean: 78.11068 min: 0.0\n",
      "RMSE: 51.46124\n",
      "saving html\n",
      "(epoch: 68, iters: 100, time: 1.256, data: 9.617) G_GAN: 2.868 G_L1: 42.439 D_real: 0.150 D_fake: 0.091 \n",
      "End of epoch 68 / 200 \t Time Taken: 156 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "real_A shape: torch.Size([10, 4, 256, 256]) max: 7.8317804 mean: 0.36515078 min: -4.2943535\n",
      "fake_B shape: torch.Size([10, 1, 256, 256]) max: 11.813118 mean: 1.1085379 min: 1.5801656e-13\n",
      "real_B shape: torch.Size([10, 1, 256, 256]) max: 38.414013 mean: 1.323279 min: 0.0\n",
      "fake_B_inverted shape: torch.Size([10, 1, 256, 256]) max: 749.13666 mean: 70.29866 min: 1.0020725e-11\n",
      "real_B_inverted shape: torch.Size([10, 1, 256, 256]) max: 2436.05 mean: 83.916626 min: 0.0\n",
      "RMSE: 52.876534\n",
      "saving html\n",
      "(epoch: 69, iters: 100, time: 1.262, data: 11.938) G_GAN: 3.333 G_L1: 45.347 D_real: 0.063 D_fake: 0.042 \n",
      "End of epoch 69 / 200 \t Time Taken: 154 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "real_A shape: torch.Size([10, 4, 256, 256]) max: 7.8025866 mean: -0.087505236 min: -6.2594895\n",
      "fake_B shape: torch.Size([10, 1, 256, 256]) max: 26.82601 mean: 0.9571862 min: 9.8286825e-18\n",
      "real_B shape: torch.Size([10, 1, 256, 256]) max: 74.41238 mean: 0.99442786 min: 0.0\n",
      "fake_B_inverted shape: torch.Size([10, 1, 256, 256]) max: 1701.1891 mean: 60.700603 min: 6.2329237e-16\n",
      "real_B_inverted shape: torch.Size([10, 1, 256, 256]) max: 4718.91 mean: 63.062294 min: 0.0\n",
      "RMSE: 45.52585\n",
      "saving html\n",
      "(epoch: 70, iters: 100, time: 1.214, data: 12.853) G_GAN: 2.429 G_L1: 33.783 D_real: 0.136 D_fake: 0.067 \n",
      "saving the model at the end of epoch 70, iters 7000\n",
      "End of epoch 70 / 200 \t Time Taken: 163 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "real_A shape: torch.Size([10, 4, 256, 256]) max: 7.8025866 mean: 0.36600846 min: -6.2594895\n",
      "fake_B shape: torch.Size([10, 1, 256, 256]) max: 12.746038 mean: 1.0633564 min: 2.7693177e-13\n",
      "real_B shape: torch.Size([10, 1, 256, 256]) max: 50.913292 mean: 1.0503864 min: 0.0\n",
      "fake_B_inverted shape: torch.Size([10, 1, 256, 256]) max: 808.29846 mean: 67.43345 min: 1.7561811e-11\n",
      "real_B_inverted shape: torch.Size([10, 1, 256, 256]) max: 3228.7 mean: 66.61095 min: 0.0\n",
      "RMSE: 45.042976\n",
      "saving html\n",
      "(epoch: 71, iters: 100, time: 1.219, data: 12.938) G_GAN: 1.796 G_L1: 36.616 D_real: 1.284 D_fake: 0.012 \n",
      "End of epoch 71 / 200 \t Time Taken: 154 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "real_A shape: torch.Size([10, 4, 256, 256]) max: 7.8317804 mean: 0.46347848 min: -6.2594895\n",
      "fake_B shape: torch.Size([10, 1, 256, 256]) max: 15.946799 mean: 1.0969591 min: 4.1842137e-13\n",
      "real_B shape: torch.Size([10, 1, 256, 256]) max: 50.913292 mean: 1.0862195 min: 0.0\n",
      "fake_B_inverted shape: torch.Size([10, 1, 256, 256]) max: 1011.2768 mean: 69.56439 min: 2.6534467e-11\n",
      "real_B_inverted shape: torch.Size([10, 1, 256, 256]) max: 3228.7 mean: 68.88334 min: 0.0\n",
      "RMSE: 50.062584\n",
      "saving html\n",
      "(epoch: 72, iters: 100, time: 1.232, data: 9.842) G_GAN: 3.439 G_L1: 41.304 D_real: 0.069 D_fake: 0.041 \n",
      "End of epoch 72 / 200 \t Time Taken: 155 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "real_A shape: torch.Size([10, 4, 256, 256]) max: 8.6378 mean: 0.4328912 min: -3.2622905\n",
      "fake_B shape: torch.Size([10, 1, 256, 256]) max: 127.11057 mean: 0.9672431 min: 0.0\n",
      "real_B shape: torch.Size([10, 1, 256, 256]) max: 36.731464 mean: 1.2218071 min: 0.0\n",
      "fake_B_inverted shape: torch.Size([10, 1, 256, 256]) max: 8060.801 mean: 61.33836 min: 0.0\n",
      "real_B_inverted shape: torch.Size([10, 1, 256, 256]) max: 2329.35 mean: 77.4817 min: 0.0\n",
      "RMSE: 58.62155\n",
      "saving html\n",
      "(epoch: 73, iters: 100, time: 1.341, data: 13.333) G_GAN: 3.511 G_L1: 45.424 D_real: 0.069 D_fake: 0.128 \n",
      "End of epoch 73 / 200 \t Time Taken: 162 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "real_A shape: torch.Size([10, 4, 256, 256]) max: 9.767428 mean: 0.05404966 min: -3.370372\n",
      "fake_B shape: torch.Size([10, 1, 256, 256]) max: 117.36813 mean: 0.80634654 min: 0.0\n",
      "real_B shape: torch.Size([10, 1, 256, 256]) max: 74.41238 mean: 0.9737406 min: 0.0\n",
      "fake_B_inverted shape: torch.Size([10, 1, 256, 256]) max: 7442.9775 mean: 51.135002 min: 0.0\n",
      "real_B_inverted shape: torch.Size([10, 1, 256, 256]) max: 4718.91 mean: 61.750404 min: 0.0\n",
      "RMSE: 52.853848\n",
      "saving html\n",
      "(epoch: 74, iters: 100, time: 1.222, data: 12.552) G_GAN: 2.750 G_L1: 34.954 D_real: 0.111 D_fake: 0.075 \n",
      "End of epoch 74 / 200 \t Time Taken: 158 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "real_A shape: torch.Size([10, 4, 256, 256]) max: 8.6378 mean: 0.14820573 min: -3.4074469\n",
      "fake_B shape: torch.Size([10, 1, 256, 256]) max: 117.31674 mean: 1.0080236 min: 0.0\n",
      "real_B shape: torch.Size([10, 1, 256, 256]) max: 73.918175 mean: 1.0694946 min: 0.0\n",
      "fake_B_inverted shape: torch.Size([10, 1, 256, 256]) max: 7439.7188 mean: 63.92448 min: 0.0\n",
      "real_B_inverted shape: torch.Size([10, 1, 256, 256]) max: 4687.57 mean: 67.82271 min: 0.0\n",
      "RMSE: 52.316753\n",
      "saving html\n",
      "(epoch: 75, iters: 100, time: 1.222, data: 12.721) G_GAN: 2.215 G_L1: 35.241 D_real: 0.026 D_fake: 0.119 \n",
      "saving the model at the end of epoch 75, iters 7500\n",
      "End of epoch 75 / 200 \t Time Taken: 158 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "real_A shape: torch.Size([10, 4, 256, 256]) max: 7.7945876 mean: 0.21452458 min: -3.683715\n",
      "fake_B shape: torch.Size([10, 1, 256, 256]) max: 13.6092 mean: 1.0044291 min: 5.758902e-12\n",
      "real_B shape: torch.Size([10, 1, 256, 256]) max: 73.918175 mean: 0.98782396 min: 0.0\n",
      "fake_B_inverted shape: torch.Size([10, 1, 256, 256]) max: 863.0364 mean: 63.696533 min: 3.652046e-10\n",
      "real_B_inverted shape: torch.Size([10, 1, 256, 256]) max: 4687.57 mean: 62.643505 min: 0.0\n",
      "RMSE: 44.724358\n",
      "saving html\n",
      "(epoch: 76, iters: 100, time: 1.216, data: 9.389) G_GAN: 3.550 G_L1: 34.812 D_real: 0.043 D_fake: 0.147 \n",
      "End of epoch 76 / 200 \t Time Taken: 154 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "real_A shape: torch.Size([10, 4, 256, 256]) max: 10.11356 mean: 0.10361262 min: -4.051862\n",
      "fake_B shape: torch.Size([10, 1, 256, 256]) max: 96.15791 mean: 0.9608995 min: 9.8e-44\n",
      "real_B shape: torch.Size([10, 1, 256, 256]) max: 54.255207 mean: 1.0721998 min: 0.0\n",
      "fake_B_inverted shape: torch.Size([10, 1, 256, 256]) max: 6097.9175 mean: 60.936073 min: 6.22e-42\n",
      "real_B_inverted shape: torch.Size([10, 1, 256, 256]) max: 3440.63 mean: 67.99426 min: 0.0\n",
      "RMSE: 51.55334\n",
      "saving html\n",
      "(epoch: 77, iters: 100, time: 1.250, data: 10.554) G_GAN: 2.232 G_L1: 36.091 D_real: 0.027 D_fake: 0.498 \n",
      "End of epoch 77 / 200 \t Time Taken: 155 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "real_A shape: torch.Size([10, 4, 256, 256]) max: 10.11356 mean: 0.043219496 min: -3.5837924\n",
      "fake_B shape: torch.Size([10, 1, 256, 256]) max: 96.84188 mean: 0.9137243 min: 0.0\n",
      "real_B shape: torch.Size([10, 1, 256, 256]) max: 44.738163 mean: 0.97148323 min: 0.0\n",
      "fake_B_inverted shape: torch.Size([10, 1, 256, 256]) max: 6141.292 mean: 57.944435 min: 0.0\n",
      "real_B_inverted shape: torch.Size([10, 1, 256, 256]) max: 2837.1 mean: 61.60725 min: 0.0\n",
      "RMSE: 53.109524\n",
      "saving html\n",
      "(epoch: 78, iters: 100, time: 1.214, data: 12.183) G_GAN: 3.206 G_L1: 35.790 D_real: 0.061 D_fake: 0.096 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End of epoch 78 / 200 \t Time Taken: 158 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "real_A shape: torch.Size([10, 4, 256, 256]) max: 7.994336 mean: 0.23717706 min: -3.5837924\n",
      "fake_B shape: torch.Size([10, 1, 256, 256]) max: 12.459345 mean: 1.0549517 min: 6.646708e-13\n",
      "real_B shape: torch.Size([10, 1, 256, 256]) max: 67.54041 mean: 1.2440846 min: 0.0\n",
      "fake_B_inverted shape: torch.Size([10, 1, 256, 256]) max: 790.1176 mean: 66.90045 min: 4.2150537e-11\n",
      "real_B_inverted shape: torch.Size([10, 1, 256, 256]) max: 4283.12 mean: 78.894455 min: 0.0\n",
      "RMSE: 51.893665\n",
      "saving html\n",
      "(epoch: 79, iters: 100, time: 1.221, data: 11.171) G_GAN: 3.825 G_L1: 40.905 D_real: 0.128 D_fake: 0.033 \n",
      "End of epoch 79 / 200 \t Time Taken: 159 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "real_A shape: torch.Size([10, 4, 256, 256]) max: 7.994336 mean: 0.5600871 min: -6.2594895\n",
      "fake_B shape: torch.Size([10, 1, 256, 256]) max: 12.492895 mean: 0.9979634 min: 7.881968e-13\n",
      "real_B shape: torch.Size([10, 1, 256, 256]) max: 73.918175 mean: 1.039859 min: 0.0\n",
      "fake_B_inverted shape: torch.Size([10, 1, 256, 256]) max: 792.2452 mean: 63.28652 min: 4.9984024e-11\n",
      "real_B_inverted shape: torch.Size([10, 1, 256, 256]) max: 4687.57 mean: 65.943344 min: 0.0\n",
      "RMSE: 48.333626\n",
      "saving html\n",
      "(epoch: 80, iters: 100, time: 1.220, data: 13.138) G_GAN: 3.036 G_L1: 36.590 D_real: 0.041 D_fake: 0.115 \n",
      "saving the model at the end of epoch 80, iters 8000\n",
      "End of epoch 80 / 200 \t Time Taken: 163 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "real_A shape: torch.Size([10, 4, 256, 256]) max: 9.242048 mean: 0.42168966 min: -3.578535\n",
      "fake_B shape: torch.Size([10, 1, 256, 256]) max: 183.72115 mean: 0.9036995 min: 0.0\n",
      "real_B shape: torch.Size([10, 1, 256, 256]) max: 44.738163 mean: 0.9443514 min: 0.0\n",
      "fake_B_inverted shape: torch.Size([10, 1, 256, 256]) max: 11650.798 mean: 57.308704 min: 0.0\n",
      "real_B_inverted shape: torch.Size([10, 1, 256, 256]) max: 2837.1 mean: 59.88667 min: 0.0\n",
      "RMSE: 47.352844\n",
      "saving html\n",
      "(epoch: 81, iters: 100, time: 1.242, data: 10.812) G_GAN: 2.647 G_L1: 30.969 D_real: 0.339 D_fake: 0.074 \n",
      "End of epoch 81 / 200 \t Time Taken: 152 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "real_A shape: torch.Size([10, 4, 256, 256]) max: 8.600046 mean: 0.31550574 min: -4.2943535\n",
      "fake_B shape: torch.Size([10, 1, 256, 256]) max: 35.19304 mean: 1.0369406 min: 5.740231e-29\n",
      "real_B shape: torch.Size([10, 1, 256, 256]) max: 54.255207 mean: 1.2152666 min: 0.0\n",
      "fake_B_inverted shape: torch.Size([10, 1, 256, 256]) max: 2231.7898 mean: 65.75827 min: 3.6402056e-27\n",
      "real_B_inverted shape: torch.Size([10, 1, 256, 256]) max: 3440.63 mean: 77.06693 min: 0.0\n",
      "RMSE: 49.84982\n",
      "saving html\n",
      "(epoch: 82, iters: 100, time: 1.259, data: 9.751) G_GAN: 4.110 G_L1: 39.623 D_real: 0.007 D_fake: 1.515 \n",
      "End of epoch 82 / 200 \t Time Taken: 155 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "real_A shape: torch.Size([10, 4, 256, 256]) max: 8.561171 mean: -0.22397575 min: -4.2943535\n",
      "fake_B shape: torch.Size([10, 1, 256, 256]) max: 13.521561 mean: 0.8564123 min: 4.2144374e-15\n",
      "real_B shape: torch.Size([10, 1, 256, 256]) max: 55.61008 mean: 0.89145553 min: 0.0\n",
      "fake_B_inverted shape: torch.Size([10, 1, 256, 256]) max: 857.4787 mean: 54.30996 min: 2.6726134e-13\n",
      "real_B_inverted shape: torch.Size([10, 1, 256, 256]) max: 3526.55 mean: 56.532238 min: 0.0\n",
      "RMSE: 41.687\n",
      "saving html\n",
      "(epoch: 83, iters: 100, time: 1.260, data: 13.242) G_GAN: 3.190 G_L1: 29.824 D_real: 0.226 D_fake: 0.203 \n",
      "End of epoch 83 / 200 \t Time Taken: 155 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "real_A shape: torch.Size([10, 4, 256, 256]) max: 5.9119744 mean: 0.23617005 min: -3.8647614\n",
      "fake_B shape: torch.Size([10, 1, 256, 256]) max: 12.503064 mean: 0.9956955 min: 4.0373863e-14\n",
      "real_B shape: torch.Size([10, 1, 256, 256]) max: 57.138252 mean: 0.95284414 min: 0.0\n",
      "fake_B_inverted shape: torch.Size([10, 1, 256, 256]) max: 792.8901 mean: 63.14269 min: 2.5603352e-12\n",
      "real_B_inverted shape: torch.Size([10, 1, 256, 256]) max: 3623.46 mean: 60.425243 min: 0.0\n",
      "RMSE: 40.37742\n",
      "saving html\n",
      "(epoch: 84, iters: 100, time: 1.219, data: 10.511) G_GAN: 1.024 G_L1: 31.199 D_real: 0.897 D_fake: 0.035 \n",
      "End of epoch 84 / 200 \t Time Taken: 156 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "real_A shape: torch.Size([10, 4, 256, 256]) max: 6.8651295 mean: -0.008736074 min: -3.3638265\n",
      "fake_B shape: torch.Size([10, 1, 256, 256]) max: 12.637697 mean: 0.925957 min: 4.3181574e-12\n",
      "real_B shape: torch.Size([10, 1, 256, 256]) max: 44.700787 mean: 0.9803375 min: 0.0\n",
      "fake_B_inverted shape: torch.Size([10, 1, 256, 256]) max: 801.4279 mean: 58.720177 min: 2.738388e-10\n",
      "real_B_inverted shape: torch.Size([10, 1, 256, 256]) max: 2834.73 mean: 62.168762 min: 0.0\n",
      "RMSE: 40.215828\n",
      "saving html\n",
      "(epoch: 85, iters: 100, time: 1.256, data: 11.050) G_GAN: 3.924 G_L1: 29.774 D_real: 0.087 D_fake: 0.565 \n",
      "saving the model at the end of epoch 85, iters 8500\n",
      "End of epoch 85 / 200 \t Time Taken: 156 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "real_A shape: torch.Size([10, 4, 256, 256]) max: 9.767428 mean: 0.2640054 min: -3.5837924\n",
      "fake_B shape: torch.Size([10, 1, 256, 256]) max: 22.561966 mean: 0.97290164 min: 7.9662697e-14\n",
      "real_B shape: torch.Size([10, 1, 256, 256]) max: 32.899445 mean: 1.164098 min: 0.0\n",
      "fake_B_inverted shape: torch.Size([10, 1, 256, 256]) max: 1430.782 mean: 61.697205 min: 5.0518626e-12\n",
      "real_B_inverted shape: torch.Size([10, 1, 256, 256]) max: 2086.34 mean: 73.822044 min: 0.0\n",
      "RMSE: 48.21765\n",
      "saving html\n",
      "(epoch: 86, iters: 100, time: 1.245, data: 9.669) G_GAN: 1.714 G_L1: 38.183 D_real: 0.342 D_fake: 0.067 \n",
      "End of epoch 86 / 200 \t Time Taken: 155 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "real_A shape: torch.Size([10, 4, 256, 256]) max: 8.6378 mean: 0.29315138 min: -6.2594895\n",
      "fake_B shape: torch.Size([10, 1, 256, 256]) max: 94.92512 mean: 0.93833935 min: 0.0\n",
      "real_B shape: torch.Size([10, 1, 256, 256]) max: 50.913292 mean: 0.9773151 min: 0.0\n",
      "fake_B_inverted shape: torch.Size([10, 1, 256, 256]) max: 6019.7393 mean: 59.505413 min: 0.0\n",
      "real_B_inverted shape: torch.Size([10, 1, 256, 256]) max: 3228.7 mean: 61.97708 min: 0.0\n",
      "RMSE: 47.494366\n",
      "saving html\n",
      "(epoch: 87, iters: 100, time: 1.255, data: 10.882) G_GAN: 3.466 G_L1: 33.603 D_real: 0.470 D_fake: 0.018 \n",
      "End of epoch 87 / 200 \t Time Taken: 153 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "real_A shape: torch.Size([10, 4, 256, 256]) max: 9.767428 mean: 0.39094958 min: -6.2594895\n",
      "fake_B shape: torch.Size([10, 1, 256, 256]) max: 22.799332 mean: 1.1105115 min: 5.0141564e-13\n",
      "real_B shape: torch.Size([10, 1, 256, 256]) max: 50.913292 mean: 1.3077408 min: 0.0\n",
      "fake_B_inverted shape: torch.Size([10, 1, 256, 256]) max: 1445.8347 mean: 70.42381 min: 3.1797603e-11\n",
      "real_B_inverted shape: torch.Size([10, 1, 256, 256]) max: 3228.7 mean: 82.93125 min: 0.0\n",
      "RMSE: 52.208824\n",
      "saving html\n",
      "(epoch: 88, iters: 100, time: 1.226, data: 13.539) G_GAN: 2.880 G_L1: 43.733 D_real: 0.017 D_fake: 0.098 \n",
      "End of epoch 88 / 200 \t Time Taken: 160 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "real_A shape: torch.Size([10, 4, 256, 256]) max: 7.33078 mean: 0.6779145 min: -3.8210413\n",
      "fake_B shape: torch.Size([10, 1, 256, 256]) max: 17.073235 mean: 1.1599954 min: 1.406155e-13\n",
      "real_B shape: torch.Size([10, 1, 256, 256]) max: 44.738163 mean: 1.304589 min: 0.0\n",
      "fake_B_inverted shape: torch.Size([10, 1, 256, 256]) max: 1082.7104 mean: 73.561874 min: 8.9172255e-12\n",
      "real_B_inverted shape: torch.Size([10, 1, 256, 256]) max: 2837.1 mean: 82.73138 min: 0.0\n",
      "RMSE: 48.11555\n",
      "saving html\n",
      "(epoch: 89, iters: 100, time: 1.253, data: 12.838) G_GAN: 2.732 G_L1: 41.333 D_real: 0.056 D_fake: 0.039 \n",
      "End of epoch 89 / 200 \t Time Taken: 155 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "real_A shape: torch.Size([10, 4, 256, 256]) max: 9.767428 mean: 0.49648276 min: -3.2025332\n",
      "fake_B shape: torch.Size([10, 1, 256, 256]) max: 16.448883 mean: 1.2132226 min: 5.161205e-15\n",
      "real_B shape: torch.Size([10, 1, 256, 256]) max: 46.684208 mean: 1.3308198 min: 0.0\n",
      "fake_B_inverted shape: torch.Size([10, 1, 256, 256]) max: 1043.1168 mean: 76.93732 min: 3.2730123e-13\n",
      "real_B_inverted shape: torch.Size([10, 1, 256, 256]) max: 2960.51 mean: 84.39482 min: 0.0\n",
      "RMSE: 51.33548\n",
      "saving html\n",
      "(epoch: 90, iters: 100, time: 1.226, data: 15.320) G_GAN: 3.581 G_L1: 43.222 D_real: 0.047 D_fake: 0.046 \n",
      "saving the model at the end of epoch 90, iters 9000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End of epoch 90 / 200 \t Time Taken: 162 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "real_A shape: torch.Size([10, 4, 256, 256]) max: 8.6378 mean: 0.12211388 min: -4.2943535\n",
      "fake_B shape: torch.Size([10, 1, 256, 256]) max: 110.209045 mean: 1.0070171 min: 0.0\n",
      "real_B shape: torch.Size([10, 1, 256, 256]) max: 74.41238 mean: 1.0324609 min: 0.0\n",
      "fake_B_inverted shape: torch.Size([10, 1, 256, 256]) max: 6988.9795 mean: 63.860664 min: 0.0\n",
      "real_B_inverted shape: torch.Size([10, 1, 256, 256]) max: 4718.91 mean: 65.47419 min: 0.0\n",
      "RMSE: 46.207428\n",
      "saving html\n",
      "(epoch: 91, iters: 100, time: 1.223, data: 11.818) G_GAN: 3.113 G_L1: 32.971 D_real: 1.657 D_fake: 0.007 \n",
      "End of epoch 91 / 200 \t Time Taken: 155 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "real_A shape: torch.Size([10, 4, 256, 256]) max: 7.994336 mean: -0.0072323084 min: -3.6275392\n",
      "fake_B shape: torch.Size([10, 1, 256, 256]) max: 15.607229 mean: 0.94410163 min: 3.9496737e-13\n",
      "real_B shape: torch.Size([10, 1, 256, 256]) max: 73.918175 mean: 1.0564737 min: 0.0\n",
      "fake_B_inverted shape: torch.Size([10, 1, 256, 256]) max: 989.74274 mean: 59.87083 min: 2.5047117e-11\n",
      "real_B_inverted shape: torch.Size([10, 1, 256, 256]) max: 4687.57 mean: 66.99698 min: 0.0\n",
      "RMSE: 47.325867\n",
      "saving html\n",
      "(epoch: 92, iters: 100, time: 1.247, data: 13.659) G_GAN: 2.645 G_L1: 35.627 D_real: 0.340 D_fake: 0.342 \n",
      "End of epoch 92 / 200 \t Time Taken: 155 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "real_A shape: torch.Size([10, 4, 256, 256]) max: 8.600046 mean: -0.21533628 min: -3.683715\n",
      "fake_B shape: torch.Size([10, 1, 256, 256]) max: 67.301605 mean: 0.852802 min: 1.3483248e-32\n",
      "real_B shape: torch.Size([10, 1, 256, 256]) max: 58.405605 mean: 0.85808647 min: 0.0\n",
      "fake_B_inverted shape: torch.Size([10, 1, 256, 256]) max: 4267.9756 mean: 54.081005 min: 8.55049e-31\n",
      "real_B_inverted shape: torch.Size([10, 1, 256, 256]) max: 3703.83 mean: 54.41612 min: 0.0\n",
      "RMSE: 44.60015\n",
      "saving html\n",
      "(epoch: 93, iters: 100, time: 1.232, data: 9.642) G_GAN: 3.059 G_L1: 30.041 D_real: 0.083 D_fake: 0.236 \n",
      "End of epoch 93 / 200 \t Time Taken: 151 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "real_A shape: torch.Size([10, 4, 256, 256]) max: 7.8317804 mean: 0.25462475 min: -3.3638265\n",
      "fake_B shape: torch.Size([10, 1, 256, 256]) max: 16.19676 mean: 1.0327673 min: 1.345275e-14\n",
      "real_B shape: torch.Size([10, 1, 256, 256]) max: 58.405605 mean: 1.10602 min: 0.0\n",
      "fake_B_inverted shape: torch.Size([10, 1, 256, 256]) max: 1027.1283 mean: 65.493614 min: 8.5311505e-13\n",
      "real_B_inverted shape: torch.Size([10, 1, 256, 256]) max: 3703.83 mean: 70.13899 min: 0.0\n",
      "RMSE: 47.981285\n",
      "saving html\n",
      "(epoch: 94, iters: 100, time: 1.250, data: 16.037) G_GAN: 3.078 G_L1: 37.198 D_real: 0.093 D_fake: 0.041 \n",
      "End of epoch 94 / 200 \t Time Taken: 159 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "real_A shape: torch.Size([10, 4, 256, 256]) max: 9.767428 mean: 0.22805946 min: -3.5837924\n",
      "fake_B shape: torch.Size([10, 1, 256, 256]) max: 33.025604 mean: 0.95279276 min: 1.9133318e-17\n",
      "real_B shape: torch.Size([10, 1, 256, 256]) max: 57.138252 mean: 1.0553037 min: 0.0\n",
      "fake_B_inverted shape: torch.Size([10, 1, 256, 256]) max: 2094.3406 mean: 60.421974 min: 1.213352e-15\n",
      "real_B_inverted shape: torch.Size([10, 1, 256, 256]) max: 3623.46 mean: 66.922775 min: 0.0\n",
      "RMSE: 47.26043\n",
      "saving html\n",
      "(epoch: 95, iters: 100, time: 1.229, data: 11.685) G_GAN: 3.737 G_L1: 36.317 D_real: 0.002 D_fake: 2.327 \n",
      "saving the model at the end of epoch 95, iters 9500\n",
      "End of epoch 95 / 200 \t Time Taken: 158 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "real_A shape: torch.Size([10, 4, 256, 256]) max: 7.8317804 mean: 0.047952283 min: -3.683715\n",
      "fake_B shape: torch.Size([10, 1, 256, 256]) max: 12.769055 mean: 0.8929056 min: 3.528416e-14\n",
      "real_B shape: torch.Size([10, 1, 256, 256]) max: 46.684208 mean: 1.0288529 min: 0.0\n",
      "fake_B_inverted shape: torch.Size([10, 1, 256, 256]) max: 809.75806 mean: 56.624195 min: 2.2375684e-12\n",
      "real_B_inverted shape: torch.Size([10, 1, 256, 256]) max: 2960.51 mean: 65.245384 min: 0.0\n",
      "RMSE: 46.653255\n",
      "saving html\n",
      "(epoch: 96, iters: 100, time: 1.235, data: 13.885) G_GAN: 3.448 G_L1: 35.275 D_real: 0.017 D_fake: 0.835 \n",
      "End of epoch 96 / 200 \t Time Taken: 157 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "real_A shape: torch.Size([10, 4, 256, 256]) max: 10.11356 mean: 0.7574812 min: -3.8210413\n",
      "fake_B shape: torch.Size([10, 1, 256, 256]) max: 194.4224 mean: 1.0741943 min: 0.0\n",
      "real_B shape: torch.Size([10, 1, 256, 256]) max: 35.541534 mean: 1.1879723 min: 0.0\n",
      "fake_B_inverted shape: torch.Size([10, 1, 256, 256]) max: 12329.425 mean: 68.12074 min: 0.0\n",
      "real_B_inverted shape: torch.Size([10, 1, 256, 256]) max: 2253.89 mean: 75.33605 min: 0.0\n",
      "RMSE: 53.734905\n",
      "saving html\n",
      "(epoch: 97, iters: 100, time: 1.236, data: 13.358) G_GAN: 2.741 G_L1: 37.410 D_real: 0.182 D_fake: 0.180 \n",
      "End of epoch 97 / 200 \t Time Taken: 156 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "real_A shape: torch.Size([10, 4, 256, 256]) max: 7.994336 mean: 0.0968194 min: -3.5837924\n",
      "fake_B shape: torch.Size([10, 1, 256, 256]) max: 18.346043 mean: 1.0415862 min: 2.0453921e-14\n",
      "real_B shape: torch.Size([10, 1, 256, 256]) max: 43.701035 mean: 1.1007272 min: 0.0\n",
      "fake_B_inverted shape: torch.Size([10, 1, 256, 256]) max: 1163.4264 mean: 66.05287 min: 1.2970989e-12\n",
      "real_B_inverted shape: torch.Size([10, 1, 256, 256]) max: 2771.33 mean: 69.803345 min: 0.0\n",
      "RMSE: 44.52467\n",
      "saving html\n",
      "(epoch: 98, iters: 100, time: 1.226, data: 14.619) G_GAN: 2.371 G_L1: 34.175 D_real: 0.244 D_fake: 0.064 \n",
      "End of epoch 98 / 200 \t Time Taken: 157 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "real_A shape: torch.Size([10, 4, 256, 256]) max: 9.233964 mean: 0.3924044 min: -3.38226\n",
      "fake_B shape: torch.Size([10, 1, 256, 256]) max: 36.838882 mean: 1.0280478 min: 1.4634132e-18\n",
      "real_B shape: torch.Size([10, 1, 256, 256]) max: 54.255207 mean: 1.1074138 min: 0.0\n",
      "fake_B_inverted shape: torch.Size([10, 1, 256, 256]) max: 2336.162 mean: 65.19432 min: 9.280331e-17\n",
      "real_B_inverted shape: torch.Size([10, 1, 256, 256]) max: 3440.63 mean: 70.22738 min: 0.0\n",
      "RMSE: 47.384975\n",
      "saving html\n",
      "(epoch: 99, iters: 100, time: 1.236, data: 9.978) G_GAN: 2.569 G_L1: 36.298 D_real: 0.382 D_fake: 0.047 \n",
      "End of epoch 99 / 200 \t Time Taken: 152 sec\n",
      "learning rate 0.0002000 -> 0.0001980\n",
      "real_A shape: torch.Size([10, 4, 256, 256]) max: 9.767428 mean: 0.24853341 min: -3.5837924\n",
      "fake_B shape: torch.Size([10, 1, 256, 256]) max: 221.29555 mean: 0.9149316 min: 0.0\n",
      "real_B shape: torch.Size([10, 1, 256, 256]) max: 44.700787 mean: 0.88624823 min: 0.0\n",
      "fake_B_inverted shape: torch.Size([10, 1, 256, 256]) max: 14033.604 mean: 58.020996 min: 0.0\n",
      "real_B_inverted shape: torch.Size([10, 1, 256, 256]) max: 2834.73 mean: 56.20202 min: 0.0\n",
      "RMSE: 46.67409\n",
      "saving html\n",
      "(epoch: 100, iters: 100, time: 1.221, data: 10.871) G_GAN: 1.067 G_L1: 30.144 D_real: 1.341 D_fake: 0.058 \n",
      "saving the latest model (epoch 100, total_iters 10000)\n",
      "saving the model at the end of epoch 100, iters 10000\n",
      "End of epoch 100 / 200 \t Time Taken: 159 sec\n",
      "learning rate 0.0001980 -> 0.0001960\n",
      "real_A shape: torch.Size([10, 4, 256, 256]) max: 9.242048 mean: 0.2689852 min: -3.477169\n",
      "fake_B shape: torch.Size([10, 1, 256, 256]) max: 188.65321 mean: 0.97494096 min: 0.0\n",
      "real_B shape: torch.Size([10, 1, 256, 256]) max: 58.405605 mean: 1.0471241 min: 0.0\n",
      "fake_B_inverted shape: torch.Size([10, 1, 256, 256]) max: 11963.568 mean: 61.826527 min: 0.0\n",
      "real_B_inverted shape: torch.Size([10, 1, 256, 256]) max: 3703.83 mean: 66.404076 min: 0.0\n",
      "RMSE: 47.576385\n",
      "saving html\n",
      "(epoch: 101, iters: 100, time: 1.243, data: 14.200) G_GAN: 2.441 G_L1: 31.755 D_real: 0.350 D_fake: 0.030 \n",
      "End of epoch 101 / 200 \t Time Taken: 157 sec\n",
      "learning rate 0.0001960 -> 0.0001941\n",
      "real_A shape: torch.Size([10, 4, 256, 256]) max: 9.767428 mean: 0.5654036 min: -3.334563\n",
      "fake_B shape: torch.Size([10, 1, 256, 256]) max: 23.983648 mean: 1.0967577 min: 5.8330937e-15\n",
      "real_B shape: torch.Size([10, 1, 256, 256]) max: 67.54041 mean: 1.3677421 min: 0.0\n",
      "fake_B_inverted shape: torch.Size([10, 1, 256, 256]) max: 1520.939 mean: 69.551605 min: 3.6990948e-13\n",
      "real_B_inverted shape: torch.Size([10, 1, 256, 256]) max: 4283.12 mean: 86.73627 min: 0.0\n",
      "RMSE: 57.72268\n",
      "saving html\n",
      "(epoch: 102, iters: 100, time: 1.318, data: 10.741) G_GAN: 4.513 G_L1: 47.717 D_real: 0.003 D_fake: 0.623 \n",
      "End of epoch 102 / 200 \t Time Taken: 154 sec\n",
      "learning rate 0.0001941 -> 0.0001921\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "real_A shape: torch.Size([10, 4, 256, 256]) max: 7.33078 mean: 0.21825893 min: -3.4478276\n",
      "fake_B shape: torch.Size([10, 1, 256, 256]) max: 20.819035 mean: 1.1005542 min: 1.261928e-15\n",
      "real_B shape: torch.Size([10, 1, 256, 256]) max: 36.731464 mean: 1.0333999 min: 0.0\n",
      "fake_B_inverted shape: torch.Size([10, 1, 256, 256]) max: 1320.2528 mean: 69.79237 min: 8.0026e-14\n",
      "real_B_inverted shape: torch.Size([10, 1, 256, 256]) max: 2329.35 mean: 65.53374 min: 0.0\n",
      "RMSE: 40.084827\n",
      "saving html\n",
      "(epoch: 103, iters: 100, time: 1.239, data: 10.094) G_GAN: 2.347 G_L1: 32.676 D_real: 0.148 D_fake: 1.273 \n",
      "End of epoch 103 / 200 \t Time Taken: 155 sec\n",
      "learning rate 0.0001921 -> 0.0001901\n",
      "real_A shape: torch.Size([10, 4, 256, 256]) max: 7.8317804 mean: 0.41547275 min: -3.8210413\n",
      "fake_B shape: torch.Size([10, 1, 256, 256]) max: 29.471434 mean: 1.0768945 min: 3.9851367e-19\n",
      "real_B shape: torch.Size([10, 1, 256, 256]) max: 32.899445 mean: 1.126715 min: 0.0\n",
      "fake_B_inverted shape: torch.Size([10, 1, 256, 256]) max: 1868.9504 mean: 68.29197 min: 2.5272007e-17\n",
      "real_B_inverted shape: torch.Size([10, 1, 256, 256]) max: 2086.34 mean: 71.45137 min: 0.0\n",
      "RMSE: 43.834335\n",
      "saving html\n",
      "(epoch: 104, iters: 100, time: 1.227, data: 13.044) G_GAN: 2.711 G_L1: 35.705 D_real: 0.017 D_fake: 0.585 \n",
      "End of epoch 104 / 200 \t Time Taken: 156 sec\n",
      "learning rate 0.0001901 -> 0.0001881\n",
      "real_A shape: torch.Size([10, 4, 256, 256]) max: 7.994336 mean: 0.02576754 min: -4.2943535\n",
      "fake_B shape: torch.Size([10, 1, 256, 256]) max: 20.314444 mean: 0.94024086 min: 3.288558e-17\n",
      "real_B shape: torch.Size([10, 1, 256, 256]) max: 44.700787 mean: 1.1477102 min: 0.0\n",
      "fake_B_inverted shape: torch.Size([10, 1, 256, 256]) max: 1288.2539 mean: 59.626 min: 2.0854608e-15\n",
      "real_B_inverted shape: torch.Size([10, 1, 256, 256]) max: 2834.73 mean: 72.7828 min: 0.0\n",
      "RMSE: 48.877472\n",
      "saving html\n",
      "(epoch: 105, iters: 100, time: 1.225, data: 9.745) G_GAN: 3.342 G_L1: 37.525 D_real: 0.267 D_fake: 0.066 \n",
      "saving the model at the end of epoch 105, iters 10500\n",
      "End of epoch 105 / 200 \t Time Taken: 159 sec\n",
      "learning rate 0.0001881 -> 0.0001861\n",
      "real_A shape: torch.Size([10, 4, 256, 256]) max: 9.767428 mean: 0.41434813 min: -3.5459752\n",
      "fake_B shape: torch.Size([10, 1, 256, 256]) max: 85.00484 mean: 0.98959464 min: 1.0834e-40\n",
      "real_B shape: torch.Size([10, 1, 256, 256]) max: 73.918175 mean: 1.0047344 min: 0.0\n",
      "fake_B_inverted shape: torch.Size([10, 1, 256, 256]) max: 5390.6377 mean: 62.7558 min: 6.870451e-39\n",
      "real_B_inverted shape: torch.Size([10, 1, 256, 256]) max: 4687.57 mean: 63.715893 min: 0.0\n",
      "RMSE: 46.75007\n",
      "saving html\n",
      "(epoch: 106, iters: 100, time: 1.243, data: 12.304) G_GAN: 3.326 G_L1: 33.317 D_real: 0.088 D_fake: 0.096 \n",
      "End of epoch 106 / 200 \t Time Taken: 157 sec\n",
      "learning rate 0.0001861 -> 0.0001842\n",
      "real_A shape: torch.Size([10, 4, 256, 256]) max: 7.33078 mean: 0.15904303 min: -3.8210413\n",
      "fake_B shape: torch.Size([10, 1, 256, 256]) max: 40.10923 mean: 1.0639334 min: 2.8874414e-19\n",
      "real_B shape: torch.Size([10, 1, 256, 256]) max: 67.54041 mean: 1.1238388 min: 0.0\n",
      "fake_B_inverted shape: torch.Size([10, 1, 256, 256]) max: 2543.5532 mean: 67.47004 min: 1.83109e-17\n",
      "real_B_inverted shape: torch.Size([10, 1, 256, 256]) max: 4283.12 mean: 71.26898 min: 0.0\n",
      "RMSE: 44.843845\n",
      "saving html\n",
      "(epoch: 107, iters: 100, time: 1.635, data: 11.543) G_GAN: 3.645 G_L1: 33.983 D_real: 0.025 D_fake: 0.215 \n",
      "End of epoch 107 / 200 \t Time Taken: 163 sec\n",
      "learning rate 0.0001842 -> 0.0001822\n",
      "real_A shape: torch.Size([10, 4, 256, 256]) max: 8.561171 mean: 0.64030516 min: -3.865085\n",
      "fake_B shape: torch.Size([10, 1, 256, 256]) max: 167.16037 mean: 1.116434 min: 0.0\n",
      "real_B shape: torch.Size([10, 1, 256, 256]) max: 58.405605 mean: 1.2528802 min: 0.0\n",
      "fake_B_inverted shape: torch.Size([10, 1, 256, 256]) max: 10600.585 mean: 70.7994 min: 0.0\n",
      "real_B_inverted shape: torch.Size([10, 1, 256, 256]) max: 3703.83 mean: 79.452225 min: 0.0\n",
      "RMSE: 53.726986\n",
      "saving html\n",
      "(epoch: 108, iters: 100, time: 1.224, data: 11.119) G_GAN: 3.683 G_L1: 38.631 D_real: 0.103 D_fake: 0.018 \n",
      "End of epoch 108 / 200 \t Time Taken: 152 sec\n",
      "learning rate 0.0001822 -> 0.0001802\n",
      "real_A shape: torch.Size([10, 4, 256, 256]) max: 9.242048 mean: 0.42716804 min: -4.051862\n",
      "fake_B shape: torch.Size([10, 1, 256, 256]) max: 235.9434 mean: 1.0615723 min: 0.0\n",
      "real_B shape: torch.Size([10, 1, 256, 256]) max: 74.41238 mean: 1.1467903 min: 0.0\n",
      "fake_B_inverted shape: torch.Size([10, 1, 256, 256]) max: 14962.507 mean: 67.320305 min: 0.0\n",
      "real_B_inverted shape: torch.Size([10, 1, 256, 256]) max: 4718.91 mean: 72.724464 min: 0.0\n",
      "RMSE: 50.06868\n",
      "saving html\n",
      "(epoch: 109, iters: 100, time: 1.424, data: 9.539) G_GAN: 1.976 G_L1: 33.264 D_real: 0.521 D_fake: 0.042 \n",
      "End of epoch 109 / 200 \t Time Taken: 154 sec\n",
      "learning rate 0.0001802 -> 0.0001782\n",
      "real_A shape: torch.Size([10, 4, 256, 256]) max: 7.8317804 mean: 0.07685258 min: -3.5837924\n",
      "fake_B shape: torch.Size([10, 1, 256, 256]) max: 18.430815 mean: 0.8827425 min: 1.1610883e-16\n",
      "real_B shape: torch.Size([10, 1, 256, 256]) max: 55.61008 mean: 0.98530847 min: 0.0\n",
      "fake_B_inverted shape: torch.Size([10, 1, 256, 256]) max: 1168.8022 mean: 55.9797 min: 7.363118e-15\n",
      "real_B_inverted shape: torch.Size([10, 1, 256, 256]) max: 3526.55 mean: 62.48399 min: 0.0\n",
      "RMSE: 40.613575\n",
      "saving html\n",
      "(epoch: 110, iters: 100, time: 1.237, data: 12.720) G_GAN: 1.907 G_L1: 29.898 D_real: 0.438 D_fake: 0.086 \n",
      "saving the model at the end of epoch 110, iters 11000\n",
      "End of epoch 110 / 200 \t Time Taken: 162 sec\n",
      "learning rate 0.0001782 -> 0.0001762\n",
      "real_A shape: torch.Size([10, 4, 256, 256]) max: 7.8025866 mean: 0.6104614 min: -6.2594895\n",
      "fake_B shape: torch.Size([10, 1, 256, 256]) max: 24.12283 mean: 1.1101556 min: 1.283409e-17\n",
      "real_B shape: torch.Size([10, 1, 256, 256]) max: 50.913292 mean: 1.3231264 min: 0.0\n",
      "fake_B_inverted shape: torch.Size([10, 1, 256, 256]) max: 1529.7651 mean: 70.40125 min: 8.138823e-16\n",
      "real_B_inverted shape: torch.Size([10, 1, 256, 256]) max: 3228.7 mean: 83.90694 min: 0.0\n",
      "RMSE: 47.732983\n",
      "saving html\n",
      "(epoch: 111, iters: 100, time: 1.324, data: 14.529) G_GAN: 2.050 G_L1: 40.263 D_real: 0.251 D_fake: 0.062 \n",
      "End of epoch 111 / 200 \t Time Taken: 162 sec\n",
      "learning rate 0.0001762 -> 0.0001743\n",
      "real_A shape: torch.Size([10, 4, 256, 256]) max: 10.11356 mean: 0.6086057 min: -3.365688\n",
      "fake_B shape: torch.Size([10, 1, 256, 256]) max: 178.97993 mean: 1.1323538 min: 0.0\n",
      "real_B shape: torch.Size([10, 1, 256, 256]) max: 58.405605 mean: 1.37089 min: 0.0\n",
      "fake_B_inverted shape: torch.Size([10, 1, 256, 256]) max: 11350.131 mean: 71.80896 min: 0.0\n",
      "real_B_inverted shape: torch.Size([10, 1, 256, 256]) max: 3703.83 mean: 86.9359 min: 0.0\n",
      "RMSE: 60.339306\n",
      "saving html\n",
      "(epoch: 112, iters: 100, time: 1.224, data: 13.456) G_GAN: 2.951 G_L1: 45.430 D_real: 0.060 D_fake: 0.402 \n",
      "End of epoch 112 / 200 \t Time Taken: 155 sec\n",
      "learning rate 0.0001743 -> 0.0001723\n",
      "real_A shape: torch.Size([10, 4, 256, 256]) max: 9.242048 mean: 0.22232957 min: -3.6275392\n",
      "fake_B shape: torch.Size([10, 1, 256, 256]) max: 204.37523 mean: 1.0565029 min: 0.0\n",
      "real_B shape: torch.Size([10, 1, 256, 256]) max: 46.684208 mean: 1.0804197 min: 0.0\n",
      "fake_B_inverted shape: torch.Size([10, 1, 256, 256]) max: 12960.59 mean: 66.998825 min: 0.0\n",
      "real_B_inverted shape: torch.Size([10, 1, 256, 256]) max: 2960.51 mean: 68.51552 min: 0.0\n",
      "RMSE: 49.724186\n",
      "saving html\n",
      "(epoch: 113, iters: 100, time: 1.300, data: 9.698) G_GAN: 2.799 G_L1: 32.026 D_real: 0.295 D_fake: 0.062 \n",
      "End of epoch 113 / 200 \t Time Taken: 154 sec\n",
      "learning rate 0.0001723 -> 0.0001703\n",
      "real_A shape: torch.Size([10, 4, 256, 256]) max: 9.767428 mean: 0.45105726 min: -3.477169\n",
      "fake_B shape: torch.Size([10, 1, 256, 256]) max: 185.38806 mean: 1.0461345 min: 0.0\n",
      "real_B shape: torch.Size([10, 1, 256, 256]) max: 35.554623 mean: 1.238898 min: 0.0\n",
      "fake_B_inverted shape: torch.Size([10, 1, 256, 256]) max: 11756.507 mean: 66.34131 min: 0.0\n",
      "real_B_inverted shape: torch.Size([10, 1, 256, 256]) max: 2254.72 mean: 78.56553 min: 0.0\n",
      "RMSE: 54.68929\n",
      "saving html\n",
      "(epoch: 114, iters: 100, time: 1.240, data: 13.939) G_GAN: 3.262 G_L1: 37.748 D_real: 0.203 D_fake: 0.034 \n",
      "End of epoch 114 / 200 \t Time Taken: 158 sec\n",
      "learning rate 0.0001703 -> 0.0001683\n",
      "real_A shape: torch.Size([10, 4, 256, 256]) max: 9.767428 mean: 0.35661632 min: -3.477169\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fake_B shape: torch.Size([10, 1, 256, 256]) max: 36.310284 mean: 1.196701 min: 1.3946564e-20\n",
      "real_B shape: torch.Size([10, 1, 256, 256]) max: 33.503395 mean: 1.1729152 min: 0.0\n",
      "fake_B_inverted shape: torch.Size([10, 1, 256, 256]) max: 2302.6406 mean: 75.88959 min: 8.844306e-19\n",
      "real_B_inverted shape: torch.Size([10, 1, 256, 256]) max: 2124.64 mean: 74.38119 min: 0.0\n",
      "RMSE: 43.27723\n",
      "saving html\n",
      "(epoch: 115, iters: 100, time: 1.245, data: 12.899) G_GAN: 2.921 G_L1: 37.059 D_real: 0.011 D_fake: 0.733 \n",
      "saving the model at the end of epoch 115, iters 11500\n",
      "End of epoch 115 / 200 \t Time Taken: 164 sec\n",
      "learning rate 0.0001683 -> 0.0001663\n",
      "real_A shape: torch.Size([10, 4, 256, 256]) max: 9.233964 mean: 0.36527166 min: -3.8647614\n",
      "fake_B shape: torch.Size([10, 1, 256, 256]) max: 94.14459 mean: 1.0447805 min: 0.0\n",
      "real_B shape: torch.Size([10, 1, 256, 256]) max: 38.414013 mean: 1.1337544 min: 0.0\n",
      "fake_B_inverted shape: torch.Size([10, 1, 256, 256]) max: 5970.2417 mean: 66.25545 min: 0.0\n",
      "real_B_inverted shape: torch.Size([10, 1, 256, 256]) max: 2436.05 mean: 71.89778 min: 0.0\n",
      "RMSE: 45.180393\n",
      "saving html\n",
      "(epoch: 116, iters: 100, time: 1.229, data: 13.231) G_GAN: 2.465 G_L1: 34.428 D_real: 0.224 D_fake: 0.160 \n",
      "End of epoch 116 / 200 \t Time Taken: 155 sec\n",
      "learning rate 0.0001663 -> 0.0001644\n",
      "real_A shape: torch.Size([10, 4, 256, 256]) max: 8.561171 mean: 0.24281669 min: -3.8210413\n",
      "fake_B shape: torch.Size([10, 1, 256, 256]) max: 31.127125 mean: 1.081344 min: 1.1495793e-19\n",
      "real_B shape: torch.Size([10, 1, 256, 256]) max: 34.358074 mean: 1.1143892 min: 0.0\n",
      "fake_B_inverted shape: torch.Size([10, 1, 256, 256]) max: 1973.9471 mean: 68.57414 min: 7.290133e-18\n",
      "real_B_inverted shape: torch.Size([10, 1, 256, 256]) max: 2178.84 mean: 70.66973 min: 0.0\n",
      "RMSE: 41.224754\n",
      "saving html\n",
      "(epoch: 117, iters: 100, time: 1.267, data: 11.501) G_GAN: 2.059 G_L1: 32.650 D_real: 0.088 D_fake: 0.546 \n",
      "End of epoch 117 / 200 \t Time Taken: 161 sec\n",
      "learning rate 0.0001644 -> 0.0001624\n",
      "real_A shape: torch.Size([10, 4, 256, 256]) max: 7.8842535 mean: 0.5661591 min: -3.3714616\n",
      "fake_B shape: torch.Size([10, 1, 256, 256]) max: 256.70517 mean: 1.1324743 min: 0.0\n",
      "real_B shape: torch.Size([10, 1, 256, 256]) max: 37.745407 mean: 1.1880325 min: 0.0\n",
      "fake_B_inverted shape: torch.Size([10, 1, 256, 256]) max: 16279.128 mean: 71.816605 min: 0.0\n",
      "real_B_inverted shape: torch.Size([10, 1, 256, 256]) max: 2393.65 mean: 75.33988 min: 0.0\n",
      "RMSE: 50.13473\n",
      "saving html\n",
      "(epoch: 118, iters: 100, time: 1.337, data: 11.171) G_GAN: 2.004 G_L1: 34.508 D_real: 0.229 D_fake: 0.108 \n",
      "End of epoch 118 / 200 \t Time Taken: 154 sec\n",
      "learning rate 0.0001624 -> 0.0001604\n",
      "real_A shape: torch.Size([10, 4, 256, 256]) max: 8.6378 mean: 0.09711228 min: -3.8210413\n",
      "fake_B shape: torch.Size([10, 1, 256, 256]) max: 158.26074 mean: 1.0287659 min: 0.0\n",
      "real_B shape: torch.Size([10, 1, 256, 256]) max: 31.380892 mean: 0.9637276 min: 0.0\n",
      "fake_B_inverted shape: torch.Size([10, 1, 256, 256]) max: 10036.21 mean: 65.23987 min: 0.0\n",
      "real_B_inverted shape: torch.Size([10, 1, 256, 256]) max: 1990.04 mean: 61.115425 min: 0.0\n",
      "RMSE: 42.729774\n",
      "saving html\n",
      "(epoch: 119, iters: 100, time: 1.450, data: 10.251) G_GAN: 1.253 G_L1: 29.813 D_real: 0.845 D_fake: 0.125 \n",
      "End of epoch 119 / 200 \t Time Taken: 158 sec\n",
      "learning rate 0.0001604 -> 0.0001584\n",
      "real_A shape: torch.Size([10, 4, 256, 256]) max: 8.600046 mean: 0.61515504 min: -4.2943535\n",
      "fake_B shape: torch.Size([10, 1, 256, 256]) max: 195.16362 mean: 0.9735939 min: 0.0\n",
      "real_B shape: torch.Size([10, 1, 256, 256]) max: 67.54041 mean: 1.0141593 min: 0.0\n",
      "fake_B_inverted shape: torch.Size([10, 1, 256, 256]) max: 12376.43 mean: 61.741108 min: 0.0\n",
      "real_B_inverted shape: torch.Size([10, 1, 256, 256]) max: 4283.12 mean: 64.31358 min: 0.0\n",
      "RMSE: 59.624584\n",
      "saving html\n",
      "(epoch: 120, iters: 100, time: 1.225, data: 11.799) G_GAN: 2.554 G_L1: 32.748 D_real: 0.029 D_fake: 0.817 \n",
      "saving the model at the end of epoch 120, iters 12000\n",
      "End of epoch 120 / 200 \t Time Taken: 163 sec\n",
      "learning rate 0.0001584 -> 0.0001564\n",
      "real_A shape: torch.Size([10, 4, 256, 256]) max: 7.994336 mean: 0.40305582 min: -4.2943535\n",
      "fake_B shape: torch.Size([10, 1, 256, 256]) max: 62.275394 mean: 1.1307352 min: 6.446016e-37\n",
      "real_B shape: torch.Size([10, 1, 256, 256]) max: 58.405605 mean: 1.3357359 min: 0.0\n",
      "fake_B_inverted shape: torch.Size([10, 1, 256, 256]) max: 3949.2354 mean: 71.70632 min: 4.0877836e-35\n",
      "real_B_inverted shape: torch.Size([10, 1, 256, 256]) max: 3703.83 mean: 84.706566 min: 0.0\n",
      "RMSE: 48.713478\n",
      "saving html\n",
      "(epoch: 121, iters: 100, time: 1.316, data: 10.367) G_GAN: 2.773 G_L1: 40.045 D_real: 0.693 D_fake: 0.041 \n",
      "End of epoch 121 / 200 \t Time Taken: 156 sec\n",
      "learning rate 0.0001564 -> 0.0001545\n",
      "real_A shape: torch.Size([10, 4, 256, 256]) max: 6.84301 mean: 0.47671142 min: -3.8210413\n",
      "fake_B shape: torch.Size([10, 1, 256, 256]) max: 59.456863 mean: 1.166338 min: 4.5184363e-28\n",
      "real_B shape: torch.Size([10, 1, 256, 256]) max: 74.41238 mean: 1.2892437 min: 0.0\n",
      "fake_B_inverted shape: torch.Size([10, 1, 256, 256]) max: 3770.4963 mean: 73.964096 min: 2.865396e-26\n",
      "real_B_inverted shape: torch.Size([10, 1, 256, 256]) max: 4718.91 mean: 81.75825 min: 0.0\n",
      "RMSE: 48.02258\n",
      "saving html\n",
      "(epoch: 122, iters: 100, time: 1.291, data: 10.457) G_GAN: 3.193 G_L1: 38.282 D_real: 0.096 D_fake: 0.146 \n",
      "End of epoch 122 / 200 \t Time Taken: 153 sec\n",
      "learning rate 0.0001545 -> 0.0001525\n",
      "real_A shape: torch.Size([10, 4, 256, 256]) max: 6.4212174 mean: 0.10936989 min: -3.5837924\n",
      "fake_B shape: torch.Size([10, 1, 256, 256]) max: 35.069435 mean: 1.0378835 min: 3.633837e-21\n",
      "real_B shape: torch.Size([10, 1, 256, 256]) max: 37.956238 mean: 1.0049982 min: 0.0\n",
      "fake_B_inverted shape: torch.Size([10, 1, 256, 256]) max: 2223.9514 mean: 65.81807 min: 2.3044218e-19\n",
      "real_B_inverted shape: torch.Size([10, 1, 256, 256]) max: 2407.02 mean: 63.732628 min: 0.0\n",
      "RMSE: 37.959373\n",
      "saving html\n",
      "(epoch: 123, iters: 100, time: 1.314, data: 11.047) G_GAN: 1.208 G_L1: 30.427 D_real: 0.467 D_fake: 0.487 \n",
      "End of epoch 123 / 200 \t Time Taken: 159 sec\n",
      "learning rate 0.0001525 -> 0.0001505\n",
      "real_A shape: torch.Size([10, 4, 256, 256]) max: 8.600046 mean: 0.19503741 min: -3.4133644\n",
      "fake_B shape: torch.Size([10, 1, 256, 256]) max: 192.07391 mean: 1.0472679 min: 0.0\n",
      "real_B shape: torch.Size([10, 1, 256, 256]) max: 55.61008 mean: 1.1101509 min: 0.0\n",
      "fake_B_inverted shape: torch.Size([10, 1, 256, 256]) max: 12180.494 mean: 66.413185 min: 0.0\n",
      "real_B_inverted shape: torch.Size([10, 1, 256, 256]) max: 3526.55 mean: 70.400955 min: 0.0\n",
      "RMSE: 53.419178\n",
      "saving html\n",
      "(epoch: 124, iters: 100, time: 1.241, data: 13.486) G_GAN: 3.702 G_L1: 32.910 D_real: 0.473 D_fake: 0.013 \n",
      "End of epoch 124 / 200 \t Time Taken: 156 sec\n",
      "learning rate 0.0001505 -> 0.0001485\n",
      "real_A shape: torch.Size([10, 4, 256, 256]) max: 7.7945876 mean: 0.0925495 min: -3.8210413\n",
      "fake_B shape: torch.Size([10, 1, 256, 256]) max: 36.150192 mean: 0.94656676 min: 4.5742194e-24\n",
      "real_B shape: torch.Size([10, 1, 256, 256]) max: 57.138252 mean: 0.935623 min: 0.0\n",
      "fake_B_inverted shape: torch.Size([10, 1, 256, 256]) max: 2292.4883 mean: 60.027153 min: 2.9007716e-22\n",
      "real_B_inverted shape: torch.Size([10, 1, 256, 256]) max: 3623.46 mean: 59.333153 min: 0.0\n",
      "RMSE: 40.377403\n",
      "saving html\n",
      "(epoch: 125, iters: 100, time: 1.314, data: 11.250) G_GAN: 2.001 G_L1: 28.395 D_real: 0.023 D_fake: 1.108 \n",
      "saving the model at the end of epoch 125, iters 12500\n",
      "End of epoch 125 / 200 \t Time Taken: 172 sec\n",
      "learning rate 0.0001485 -> 0.0001465\n",
      "real_A shape: torch.Size([10, 4, 256, 256]) max: 7.8842535 mean: 0.23339483 min: -4.2943535\n",
      "fake_B shape: torch.Size([10, 1, 256, 256]) max: 120.37354 mean: 1.0787301 min: 0.0\n",
      "real_B shape: torch.Size([10, 1, 256, 256]) max: 74.41238 mean: 1.1992447 min: 0.0\n",
      "fake_B_inverted shape: torch.Size([10, 1, 256, 256]) max: 7633.568 mean: 68.40839 min: 0.0\n",
      "real_B_inverted shape: torch.Size([10, 1, 256, 256]) max: 4718.91 mean: 76.0509 min: 0.0\n",
      "RMSE: 47.954506\n",
      "saving html\n",
      "(epoch: 126, iters: 100, time: 1.282, data: 14.890) G_GAN: 2.088 G_L1: 34.698 D_real: 0.021 D_fake: 0.133 \n",
      "End of epoch 126 / 200 \t Time Taken: 157 sec\n",
      "learning rate 0.0001465 -> 0.0001446\n",
      "real_A shape: torch.Size([10, 4, 256, 256]) max: 7.994336 mean: 0.4816095 min: -3.330661\n",
      "fake_B shape: torch.Size([10, 1, 256, 256]) max: 65.66891 mean: 1.1257524 min: 1.0567518e-38\n",
      "real_B shape: torch.Size([10, 1, 256, 256]) max: 67.54041 mean: 1.162965 min: 0.0\n",
      "fake_B_inverted shape: torch.Size([10, 1, 256, 256]) max: 4164.437 mean: 71.39033 min: 6.7014617e-37\n",
      "real_B_inverted shape: torch.Size([10, 1, 256, 256]) max: 4283.12 mean: 73.7502 min: 0.0\n",
      "RMSE: 47.597412\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving html\n",
      "(epoch: 127, iters: 100, time: 1.232, data: 10.017) G_GAN: 2.802 G_L1: 35.992 D_real: 0.049 D_fake: 0.211 \n",
      "End of epoch 127 / 200 \t Time Taken: 156 sec\n",
      "learning rate 0.0001446 -> 0.0001426\n",
      "real_A shape: torch.Size([10, 4, 256, 256]) max: 8.113412 mean: 0.38986352 min: -3.365688\n",
      "fake_B shape: torch.Size([10, 1, 256, 256]) max: 26.527777 mean: 0.9322125 min: 1.5133218e-17\n",
      "real_B shape: torch.Size([10, 1, 256, 256]) max: 44.738163 mean: 0.971131 min: 0.0\n",
      "fake_B_inverted shape: torch.Size([10, 1, 256, 256]) max: 1682.2765 mean: 59.116875 min: 9.59683e-16\n",
      "real_B_inverted shape: torch.Size([10, 1, 256, 256]) max: 2837.1 mean: 61.58491 min: 0.0\n",
      "RMSE: 38.735764\n",
      "saving html\n",
      "(epoch: 128, iters: 100, time: 1.269, data: 15.173) G_GAN: 1.409 G_L1: 29.165 D_real: 0.234 D_fake: 0.446 \n",
      "End of epoch 128 / 200 \t Time Taken: 157 sec\n",
      "learning rate 0.0001426 -> 0.0001406\n",
      "real_A shape: torch.Size([10, 4, 256, 256]) max: 7.8025866 mean: 0.11843131 min: -6.2594895\n",
      "fake_B shape: torch.Size([10, 1, 256, 256]) max: 28.99426 mean: 0.99749726 min: 1.2769452e-14\n",
      "real_B shape: torch.Size([10, 1, 256, 256]) max: 55.61008 mean: 0.89184713 min: 0.0\n",
      "fake_B_inverted shape: torch.Size([10, 1, 256, 256]) max: 1838.6902 mean: 63.256947 min: 8.0978323e-13\n",
      "real_B_inverted shape: torch.Size([10, 1, 256, 256]) max: 3526.55 mean: 56.557076 min: 0.0\n",
      "RMSE: 42.26167\n",
      "saving html\n",
      "(epoch: 129, iters: 100, time: 1.232, data: 10.395) G_GAN: 1.894 G_L1: 30.631 D_real: 0.154 D_fake: 0.550 \n",
      "End of epoch 129 / 200 \t Time Taken: 157 sec\n",
      "learning rate 0.0001406 -> 0.0001386\n",
      "real_A shape: torch.Size([10, 4, 256, 256]) max: 8.113412 mean: 0.15132606 min: -3.4478276\n",
      "fake_B shape: torch.Size([10, 1, 256, 256]) max: 28.268715 mean: 1.0890716 min: 1.1404691e-17\n",
      "real_B shape: torch.Size([10, 1, 256, 256]) max: 57.138252 mean: 1.2159431 min: 0.0\n",
      "fake_B_inverted shape: torch.Size([10, 1, 256, 256]) max: 1792.6792 mean: 69.0642 min: 7.23236e-16\n",
      "real_B_inverted shape: torch.Size([10, 1, 256, 256]) max: 3623.46 mean: 77.10984 min: 0.0\n",
      "RMSE: 42.43104\n",
      "saving html\n",
      "(epoch: 130, iters: 100, time: 1.396, data: 10.298) G_GAN: 1.958 G_L1: 33.268 D_real: 0.053 D_fake: 0.574 \n",
      "saving the model at the end of epoch 130, iters 13000\n",
      "End of epoch 130 / 200 \t Time Taken: 175 sec\n",
      "learning rate 0.0001386 -> 0.0001366\n",
      "real_A shape: torch.Size([10, 4, 256, 256]) max: 7.994336 mean: 0.50778687 min: -4.2943535\n",
      "fake_B shape: torch.Size([10, 1, 256, 256]) max: 53.313663 mean: 1.1590405 min: 2.2471507e-38\n",
      "real_B shape: torch.Size([10, 1, 256, 256]) max: 74.41238 mean: 1.4831076 min: 0.0\n",
      "fake_B_inverted shape: torch.Size([10, 1, 256, 256]) max: 3380.9211 mean: 73.50132 min: 1.4250455e-36\n",
      "real_B_inverted shape: torch.Size([10, 1, 256, 256]) max: 4718.91 mean: 94.052246 min: 0.0\n",
      "RMSE: 54.885803\n",
      "saving html\n",
      "(epoch: 131, iters: 100, time: 1.240, data: 12.475) G_GAN: 2.414 G_L1: 46.660 D_real: 0.015 D_fake: 0.868 \n",
      "End of epoch 131 / 200 \t Time Taken: 163 sec\n",
      "learning rate 0.0001366 -> 0.0001347\n",
      "real_A shape: torch.Size([10, 4, 256, 256]) max: 7.5661025 mean: 0.36639962 min: -3.4478276\n",
      "fake_B shape: torch.Size([10, 1, 256, 256]) max: 83.21452 mean: 1.1585594 min: 0.0\n",
      "real_B shape: torch.Size([10, 1, 256, 256]) max: 54.255207 mean: 1.2336776 min: 0.0\n",
      "fake_B_inverted shape: torch.Size([10, 1, 256, 256]) max: 5277.104 mean: 73.47081 min: 0.0\n",
      "real_B_inverted shape: torch.Size([10, 1, 256, 256]) max: 3440.63 mean: 78.23448 min: 0.0\n",
      "RMSE: 41.314423\n",
      "saving html\n",
      "(epoch: 132, iters: 100, time: 1.241, data: 13.571) G_GAN: 2.042 G_L1: 33.045 D_real: 0.441 D_fake: 0.108 \n",
      "End of epoch 132 / 200 \t Time Taken: 157 sec\n",
      "learning rate 0.0001347 -> 0.0001327\n",
      "real_A shape: torch.Size([10, 4, 256, 256]) max: 7.7945876 mean: 0.013095235 min: -4.051862\n",
      "fake_B shape: torch.Size([10, 1, 256, 256]) max: 33.613693 mean: 0.97073287 min: 1.902769e-26\n",
      "real_B shape: torch.Size([10, 1, 256, 256]) max: 58.405605 mean: 1.1831307 min: 0.0\n",
      "fake_B_inverted shape: torch.Size([10, 1, 256, 256]) max: 2131.6345 mean: 61.55967 min: 1.2066536e-24\n",
      "real_B_inverted shape: torch.Size([10, 1, 256, 256]) max: 3703.83 mean: 75.029015 min: 0.0\n",
      "RMSE: 45.76578\n",
      "saving html\n",
      "(epoch: 133, iters: 100, time: 1.238, data: 10.327) G_GAN: 3.275 G_L1: 34.970 D_real: 0.046 D_fake: 0.658 \n",
      "End of epoch 133 / 200 \t Time Taken: 156 sec\n",
      "learning rate 0.0001327 -> 0.0001307\n",
      "real_A shape: torch.Size([10, 4, 256, 256]) max: 8.600046 mean: 0.10440502 min: -3.4478276\n",
      "fake_B shape: torch.Size([10, 1, 256, 256]) max: 206.75809 mean: 0.9577424 min: 0.0\n",
      "real_B shape: torch.Size([10, 1, 256, 256]) max: 58.405605 mean: 1.0516449 min: 0.0\n",
      "fake_B_inverted shape: torch.Size([10, 1, 256, 256]) max: 13111.701 mean: 60.735863 min: 0.0\n",
      "real_B_inverted shape: torch.Size([10, 1, 256, 256]) max: 3703.83 mean: 66.69076 min: 0.0\n",
      "RMSE: 50.48345\n",
      "saving html\n",
      "(epoch: 134, iters: 100, time: 1.258, data: 13.388) G_GAN: 2.834 G_L1: 30.336 D_real: 0.096 D_fake: 0.090 \n",
      "End of epoch 134 / 200 \t Time Taken: 156 sec\n",
      "learning rate 0.0001307 -> 0.0001287\n",
      "real_A shape: torch.Size([10, 4, 256, 256]) max: 7.8317804 mean: -0.052469313 min: -3.578535\n",
      "fake_B shape: torch.Size([10, 1, 256, 256]) max: 97.73972 mean: 0.8060303 min: 0.0\n",
      "real_B shape: torch.Size([10, 1, 256, 256]) max: 43.39969 mean: 0.948563 min: 0.0\n",
      "fake_B_inverted shape: torch.Size([10, 1, 256, 256]) max: 6198.229 mean: 51.11495 min: 0.0\n",
      "real_B_inverted shape: torch.Size([10, 1, 256, 256]) max: 2752.22 mean: 60.153748 min: 0.0\n",
      "RMSE: 41.98341\n",
      "saving html\n",
      "(epoch: 135, iters: 100, time: 1.251, data: 10.231) G_GAN: 1.854 G_L1: 29.666 D_real: 0.185 D_fake: 0.424 \n",
      "saving the model at the end of epoch 135, iters 13500\n",
      "End of epoch 135 / 200 \t Time Taken: 167 sec\n",
      "learning rate 0.0001287 -> 0.0001267\n",
      "real_A shape: torch.Size([10, 4, 256, 256]) max: 7.994336 mean: 0.110127404 min: -6.2594895\n",
      "fake_B shape: torch.Size([10, 1, 256, 256]) max: 64.447914 mean: 0.99901265 min: 0.0\n",
      "real_B shape: torch.Size([10, 1, 256, 256]) max: 58.405605 mean: 1.0877901 min: 0.0\n",
      "fake_B_inverted shape: torch.Size([10, 1, 256, 256]) max: 4087.007 mean: 63.35304 min: 0.0\n",
      "real_B_inverted shape: torch.Size([10, 1, 256, 256]) max: 3703.83 mean: 68.982925 min: 0.0\n",
      "RMSE: 46.378258\n",
      "saving html\n",
      "(epoch: 136, iters: 100, time: 1.226, data: 12.357) G_GAN: 1.917 G_L1: 34.036 D_real: 0.011 D_fake: 1.361 \n",
      "End of epoch 136 / 200 \t Time Taken: 155 sec\n",
      "learning rate 0.0001267 -> 0.0001248\n",
      "real_A shape: torch.Size([10, 4, 256, 256]) max: 7.8842535 mean: 0.4100913 min: -3.2836716\n",
      "fake_B shape: torch.Size([10, 1, 256, 256]) max: 144.88286 mean: 1.1134504 min: 0.0\n",
      "real_B shape: torch.Size([10, 1, 256, 256]) max: 67.54041 mean: 1.2629406 min: 0.0\n",
      "fake_B_inverted shape: torch.Size([10, 1, 256, 256]) max: 9187.842 mean: 70.61019 min: 0.0\n",
      "real_B_inverted shape: torch.Size([10, 1, 256, 256]) max: 4283.12 mean: 80.090225 min: 0.0\n",
      "RMSE: 45.892326\n",
      "saving html\n",
      "(epoch: 137, iters: 100, time: 1.242, data: 15.043) G_GAN: 2.415 G_L1: 35.778 D_real: 0.069 D_fake: 0.165 \n",
      "End of epoch 137 / 200 \t Time Taken: 158 sec\n",
      "learning rate 0.0001248 -> 0.0001228\n",
      "real_A shape: torch.Size([10, 4, 256, 256]) max: 8.113412 mean: 0.11132809 min: -3.5837924\n",
      "fake_B shape: torch.Size([10, 1, 256, 256]) max: 73.98632 mean: 0.97317183 min: 0.0\n",
      "real_B shape: torch.Size([10, 1, 256, 256]) max: 44.700787 mean: 0.9499348 min: 0.0\n",
      "fake_B_inverted shape: torch.Size([10, 1, 256, 256]) max: 4691.8916 mean: 61.714333 min: 0.0\n",
      "real_B_inverted shape: torch.Size([10, 1, 256, 256]) max: 2834.73 mean: 60.24074 min: 0.0\n",
      "RMSE: 38.493755\n",
      "saving html\n",
      "(epoch: 138, iters: 100, time: 1.246, data: 13.346) G_GAN: 1.416 G_L1: 28.361 D_real: 0.180 D_fake: 0.387 \n",
      "End of epoch 138 / 200 \t Time Taken: 156 sec\n",
      "learning rate 0.0001228 -> 0.0001208\n",
      "real_A shape: torch.Size([10, 4, 256, 256]) max: 10.11356 mean: 0.39457554 min: -6.2594895\n",
      "fake_B shape: torch.Size([10, 1, 256, 256]) max: 120.4972 mean: 1.1116859 min: 0.0\n",
      "real_B shape: torch.Size([10, 1, 256, 256]) max: 50.913292 mean: 1.147105 min: 0.0\n",
      "fake_B_inverted shape: torch.Size([10, 1, 256, 256]) max: 7641.4097 mean: 70.4983 min: 0.0\n",
      "real_B_inverted shape: torch.Size([10, 1, 256, 256]) max: 3228.7 mean: 72.74443 min: 0.0\n",
      "RMSE: 46.79235\n",
      "saving html\n",
      "(epoch: 139, iters: 100, time: 1.264, data: 15.375) G_GAN: 1.848 G_L1: 33.878 D_real: 0.028 D_fake: 0.665 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End of epoch 139 / 200 \t Time Taken: 160 sec\n",
      "learning rate 0.0001208 -> 0.0001188\n",
      "real_A shape: torch.Size([10, 4, 256, 256]) max: 6.3803477 mean: 0.11677972 min: -3.578535\n",
      "fake_B shape: torch.Size([10, 1, 256, 256]) max: 29.068953 mean: 0.8374367 min: 1.3343438e-20\n",
      "real_B shape: torch.Size([10, 1, 256, 256]) max: 54.255207 mean: 0.89230585 min: 0.0\n",
      "fake_B_inverted shape: torch.Size([10, 1, 256, 256]) max: 1843.4269 mean: 53.10659 min: 8.461829e-19\n",
      "real_B_inverted shape: torch.Size([10, 1, 256, 256]) max: 3440.63 mean: 56.58617 min: 0.0\n",
      "RMSE: 36.248924\n",
      "saving html\n",
      "(epoch: 140, iters: 100, time: 1.322, data: 11.234) G_GAN: 1.480 G_L1: 25.430 D_real: 0.115 D_fake: 0.556 \n",
      "saving the model at the end of epoch 140, iters 14000\n",
      "End of epoch 140 / 200 \t Time Taken: 164 sec\n",
      "learning rate 0.0001188 -> 0.0001168\n",
      "real_A shape: torch.Size([10, 4, 256, 256]) max: 6.084272 mean: 0.34082595 min: -4.051862\n",
      "fake_B shape: torch.Size([10, 1, 256, 256]) max: 32.008957 mean: 1.0542166 min: 9.922373e-18\n",
      "real_B shape: torch.Size([10, 1, 256, 256]) max: 54.255207 mean: 1.0606956 min: 0.0\n",
      "fake_B_inverted shape: torch.Size([10, 1, 256, 256]) max: 2029.8691 mean: 66.85384 min: 6.2923383e-16\n",
      "real_B_inverted shape: torch.Size([10, 1, 256, 256]) max: 3440.63 mean: 67.26471 min: 0.0\n",
      "RMSE: 38.039238\n",
      "saving html\n",
      "(epoch: 141, iters: 100, time: 1.251, data: 15.298) G_GAN: 1.189 G_L1: 29.249 D_real: 1.023 D_fake: 0.078 \n",
      "End of epoch 141 / 200 \t Time Taken: 160 sec\n",
      "learning rate 0.0001168 -> 0.0001149\n",
      "real_A shape: torch.Size([10, 4, 256, 256]) max: 6.067777 mean: 0.37396425 min: -3.3714616\n",
      "fake_B shape: torch.Size([10, 1, 256, 256]) max: 35.36224 mean: 1.0760804 min: 1.0177021e-26\n",
      "real_B shape: torch.Size([10, 1, 256, 256]) max: 54.255207 mean: 1.1503686 min: 0.0\n",
      "fake_B_inverted shape: torch.Size([10, 1, 256, 256]) max: 2242.5198 mean: 68.24036 min: 6.4538254e-25\n",
      "real_B_inverted shape: torch.Size([10, 1, 256, 256]) max: 3440.63 mean: 72.951385 min: 0.0\n",
      "RMSE: 38.830032\n",
      "saving html\n",
      "(epoch: 142, iters: 100, time: 1.643, data: 12.397) G_GAN: 0.330 G_L1: 31.622 D_real: 1.480 D_fake: 0.122 \n",
      "End of epoch 142 / 200 \t Time Taken: 175 sec\n",
      "learning rate 0.0001149 -> 0.0001129\n",
      "real_A shape: torch.Size([10, 4, 256, 256]) max: 10.11356 mean: -0.026990205 min: -3.5459752\n",
      "fake_B shape: torch.Size([10, 1, 256, 256]) max: 105.322174 mean: 0.88941365 min: 0.0\n",
      "real_B shape: torch.Size([10, 1, 256, 256]) max: 73.918175 mean: 0.97336566 min: 0.0\n",
      "fake_B_inverted shape: torch.Size([10, 1, 256, 256]) max: 6679.075 mean: 56.40275 min: 0.0\n",
      "real_B_inverted shape: torch.Size([10, 1, 256, 256]) max: 4687.57 mean: 61.726624 min: 0.0\n",
      "RMSE: 41.144146\n",
      "saving html\n",
      "(epoch: 143, iters: 100, time: 1.245, data: 16.198) G_GAN: 1.718 G_L1: 27.485 D_real: 0.172 D_fake: 0.452 \n",
      "End of epoch 143 / 200 \t Time Taken: 158 sec\n",
      "learning rate 0.0001129 -> 0.0001109\n",
      "real_A shape: torch.Size([10, 4, 256, 256]) max: 7.8317804 mean: 0.097342834 min: -3.8210413\n",
      "fake_B shape: torch.Size([10, 1, 256, 256]) max: 45.98224 mean: 0.9701729 min: 1.5199342e-25\n",
      "real_B shape: torch.Size([10, 1, 256, 256]) max: 37.078068 mean: 1.0331895 min: 0.0\n",
      "fake_B_inverted shape: torch.Size([10, 1, 256, 256]) max: 2915.9941 mean: 61.52415 min: 9.638763e-24\n",
      "real_B_inverted shape: torch.Size([10, 1, 256, 256]) max: 2351.33 mean: 65.5204 min: 0.0\n",
      "RMSE: 38.05344\n",
      "saving html\n",
      "(epoch: 144, iters: 100, time: 1.263, data: 9.895) G_GAN: 2.045 G_L1: 28.668 D_real: 0.109 D_fake: 0.497 \n",
      "End of epoch 144 / 200 \t Time Taken: 157 sec\n",
      "learning rate 0.0001109 -> 0.0001089\n",
      "real_A shape: torch.Size([10, 4, 256, 256]) max: 9.767428 mean: 0.49432975 min: -3.477169\n",
      "fake_B shape: torch.Size([10, 1, 256, 256]) max: 81.287315 mean: 1.0678989 min: 0.0\n",
      "real_B shape: torch.Size([10, 1, 256, 256]) max: 37.745407 mean: 1.2055054 min: 0.0\n",
      "fake_B_inverted shape: torch.Size([10, 1, 256, 256]) max: 5154.8887 mean: 67.72151 min: 0.0\n",
      "real_B_inverted shape: torch.Size([10, 1, 256, 256]) max: 2393.65 mean: 76.44792 min: 0.0\n",
      "RMSE: 44.066696\n",
      "saving html\n",
      "(epoch: 145, iters: 100, time: 1.232, data: 12.624) G_GAN: 1.668 G_L1: 34.865 D_real: 0.016 D_fake: 1.284 \n",
      "saving the model at the end of epoch 145, iters 14500\n",
      "End of epoch 145 / 200 \t Time Taken: 163 sec\n",
      "learning rate 0.0001089 -> 0.0001069\n",
      "real_A shape: torch.Size([10, 4, 256, 256]) max: 5.4951596 mean: 0.56672925 min: -3.477169\n",
      "fake_B shape: torch.Size([10, 1, 256, 256]) max: 35.44644 mean: 1.2449223 min: 1.8981432e-19\n",
      "real_B shape: torch.Size([10, 1, 256, 256]) max: 36.731464 mean: 1.2693232 min: 0.0\n",
      "fake_B_inverted shape: torch.Size([10, 1, 256, 256]) max: 2247.8596 mean: 78.94756 min: 1.2037201e-17\n",
      "real_B_inverted shape: torch.Size([10, 1, 256, 256]) max: 2329.35 mean: 80.49497 min: 0.0\n",
      "RMSE: 41.762638\n",
      "saving html\n",
      "(epoch: 146, iters: 100, time: 1.332, data: 18.259) G_GAN: 0.929 G_L1: 34.811 D_real: 0.529 D_fake: 0.133 \n",
      "End of epoch 146 / 200 \t Time Taken: 177 sec\n",
      "learning rate 0.0001069 -> 0.0001050\n",
      "real_A shape: torch.Size([10, 4, 256, 256]) max: 10.11356 mean: 0.6208304 min: -3.477169\n",
      "fake_B shape: torch.Size([10, 1, 256, 256]) max: 79.16322 mean: 1.1653223 min: 0.0\n",
      "real_B shape: torch.Size([10, 1, 256, 256]) max: 43.701035 mean: 1.3070132 min: 0.0\n",
      "fake_B_inverted shape: torch.Size([10, 1, 256, 256]) max: 5020.188 mean: 73.89968 min: 0.0\n",
      "real_B_inverted shape: torch.Size([10, 1, 256, 256]) max: 2771.33 mean: 82.8851 min: 0.0\n",
      "RMSE: 47.813896\n",
      "saving html\n",
      "(epoch: 147, iters: 100, time: 1.277, data: 13.443) G_GAN: 1.653 G_L1: 37.383 D_real: 0.070 D_fake: 0.299 \n",
      "End of epoch 147 / 200 \t Time Taken: 170 sec\n",
      "learning rate 0.0001050 -> 0.0001030\n",
      "real_A shape: torch.Size([10, 4, 256, 256]) max: 7.8025866 mean: 0.22307806 min: -6.2594895\n",
      "fake_B shape: torch.Size([10, 1, 256, 256]) max: 70.23307 mean: 1.1201166 min: 1e-45\n",
      "real_B shape: torch.Size([10, 1, 256, 256]) max: 67.54041 mean: 1.0948882 min: 0.0\n",
      "fake_B_inverted shape: torch.Size([10, 1, 256, 256]) max: 4453.8765 mean: 71.032936 min: 8.8e-44\n",
      "real_B_inverted shape: torch.Size([10, 1, 256, 256]) max: 4283.12 mean: 69.43306 min: 0.0\n",
      "RMSE: 43.313133\n",
      "saving html\n",
      "(epoch: 148, iters: 100, time: 1.236, data: 26.911) G_GAN: 2.454 G_L1: 31.083 D_real: 0.077 D_fake: 0.396 \n",
      "End of epoch 148 / 200 \t Time Taken: 189 sec\n",
      "learning rate 0.0001030 -> 0.0001010\n",
      "real_A shape: torch.Size([10, 4, 256, 256]) max: 10.11356 mean: 0.60177785 min: -3.3241448\n",
      "fake_B shape: torch.Size([10, 1, 256, 256]) max: 59.987644 mean: 1.0503128 min: 0.0\n",
      "real_B shape: torch.Size([10, 1, 256, 256]) max: 55.61008 mean: 1.1558434 min: 0.0\n",
      "fake_B_inverted shape: torch.Size([10, 1, 256, 256]) max: 3804.156 mean: 66.60628 min: 0.0\n",
      "real_B_inverted shape: torch.Size([10, 1, 256, 256]) max: 3526.55 mean: 73.29857 min: 0.0\n",
      "RMSE: 42.91594\n",
      "saving html\n",
      "(epoch: 149, iters: 100, time: 1.253, data: 13.270) G_GAN: 2.132 G_L1: 32.242 D_real: 0.223 D_fake: 0.154 \n",
      "End of epoch 149 / 200 \t Time Taken: 155 sec\n",
      "learning rate 0.0001010 -> 0.0000990\n",
      "real_A shape: torch.Size([10, 4, 256, 256]) max: 7.8317804 mean: 0.08817706 min: -3.8210413\n",
      "fake_B shape: torch.Size([10, 1, 256, 256]) max: 34.453587 mean: 0.97900236 min: 6.1760024e-25\n",
      "real_B shape: torch.Size([10, 1, 256, 256]) max: 54.255207 mean: 0.98087776 min: 0.0\n",
      "fake_B_inverted shape: torch.Size([10, 1, 256, 256]) max: 2184.897 mean: 62.084084 min: 3.9165527e-23\n",
      "real_B_inverted shape: torch.Size([10, 1, 256, 256]) max: 3440.63 mean: 62.203014 min: 0.0\n",
      "RMSE: 36.241314\n",
      "saving html\n",
      "(epoch: 150, iters: 100, time: 1.355, data: 11.033) G_GAN: 0.709 G_L1: 28.059 D_real: 1.798 D_fake: 0.113 \n",
      "saving the latest model (epoch 150, total_iters 15000)\n",
      "saving the model at the end of epoch 150, iters 15000\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/loaner/.pyenv/versions/3.8.15/lib/python3.8/site-packages/torch/serialization.py\", line 423, in save\n",
      "    _save(obj, opened_zipfile, pickle_module, pickle_protocol)\n",
      "  File \"/Users/loaner/.pyenv/versions/3.8.15/lib/python3.8/site-packages/torch/serialization.py\", line 650, in _save\n",
      "    zip_file.write_record(name, storage.data_ptr(), num_bytes)\n",
      "RuntimeError: [enforce fail at inline_container.cc:450] . PytorchStreamWriter failed writing file data/56: file write failed\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"./pix2pix/train.py\", line 76, in <module>\n",
      "    model.save_networks(epoch)\n",
      "  File \"/Users/loaner/projects/dd-biomassters/pix2pix/models/base_model.py\", line 161, in save_networks\n",
      "    torch.save(net.cpu().state_dict(), save_path)\n",
      "  File \"/Users/loaner/.pyenv/versions/3.8.15/lib/python3.8/site-packages/torch/serialization.py\", line 424, in save\n",
      "    return\n",
      "  File \"/Users/loaner/.pyenv/versions/3.8.15/lib/python3.8/site-packages/torch/serialization.py\", line 290, in __exit__\n",
      "    self.file_like.write_end_of_file()\n",
      "RuntimeError: [enforce fail at inline_container.cc:325] . unexpected pos 160007232 vs 160007128\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "libc++abi.dylib: terminating with uncaught exception of type c10::Error: [enforce fail at inline_container.cc:325] . unexpected pos 160007232 vs 160007128\r\n",
      "frame #0: c10::ThrowEnforceNotMet(char const*, int, char const*, std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, void const*) + 79 (0x111b2a40f in libc10.dylib)\r\n",
      "frame #1: caffe2::serialize::ostream_write_func(void*, unsigned long long, void const*, unsigned long) + 163 (0x119341d23 in libtorch_cpu.dylib)\r\n",
      "frame #2: mz_zip_writer_add_mem_ex_v2 + 1974 (0x119339676 in libtorch_cpu.dylib)\r\n",
      "frame #3: caffe2::serialize::PyTorchStreamWriter::writeRecord(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, void const*, unsigned long, bool) + 271 (0x119343fdf in libtorch_cpu.dylib)\r\n",
      "frame #4: caffe2::serialize::PyTorchStreamWriter::writeEndOfFile() + 353 (0x119344671 in libtorch_cpu.dylib)\r\n",
      "frame #5: caffe2::serialize::PyTorchStreamWriter::~PyTorchStreamWriter() + 30 (0x119344d6e in libtorch_cpu.dylib)\r\n",
      "frame #6: pybind11::class_<caffe2::serialize::PyTorchStreamWriter>::dealloc(pybind11::detail::value_and_holder&) + 87 (0x110d0b4e7 in libtorch_python.dylib)\r\n",
      "frame #7: pybind11::detail::clear_instance(_object*) + 475 (0x1106e7a9b in libtorch_python.dylib)\r\n",
      "frame #8: pybind11_object_dealloc + 15 (0x1106e776f in libtorch_python.dylib)\r\n",
      "<omitting python frames>\r\n",
      "frame #20: start + 1 (0x7fff671c9cc9 in libdyld.dylib)\r\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "%cd /Users/loaner/projects/dd-biomassters\n",
    "!python ./pix2pix/train.py \\\n",
    "    --dataroot ./data --name biomassters_softplus_b3p0 --model pix2pix --phase train --gpu_ids -1 \\\n",
    "    --direction AtoB --input_nc 4 --output_nc 1 --dataset_mode biomassters --preprocess \"\" --no_flip  \\\n",
    "    --batch_size 10 --max_dataset_size 100 \\\n",
    "    --n_epochs 100 --n_epochs_decay 100 --lr 0.0002 \\\n",
    "    --display_id 1 --display_freq 100 --print_freq 100 --update_html_freq 100 --save_epoch_freq 5 \\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------- Options ---------------\n",
      "             aspect_ratio: 1.0                           \n",
      "               batch_size: 1                             \n",
      "          checkpoints_dir: ./checkpoints                 \n",
      "                crop_size: 256                           \n",
      "                 dataroot: ./data                        \t[default: data]\n",
      "             dataset_mode: biomassters                   \t[default: aligned]\n",
      "                direction: AtoB                          \n",
      "          display_winsize: 256                           \n",
      "                    epoch: latest                        \n",
      "                     eval: True                          \t[default: False]\n",
      "                  gpu_ids: -1                            \t[default: 0]\n",
      "                init_gain: 0.02                          \n",
      "                init_type: normal                        \n",
      "                 input_nc: 4                             \t[default: 3]\n",
      "                  isTrain: False                         \t[default: None]\n",
      "                load_iter: 0                             \t[default: 0]\n",
      "                load_size: 256                           \n",
      "         max_dataset_size: 10                            \t[default: inf]\n",
      "                    model: pix2pix                       \t[default: test]\n",
      "               n_layers_D: 3                             \n",
      "                     name: biomassters_softplus_b3p0     \t[default: experiment_name]\n",
      "                      ndf: 64                            \n",
      "                     netD: basic                         \n",
      "                     netG: unet_256                      \n",
      "                      ngf: 64                            \n",
      "               no_dropout: False                         \n",
      "                  no_flip: False                         \n",
      "                     norm: batch                         \n",
      "                 num_test: 50                            \n",
      "              num_threads: 4                             \n",
      "                output_nc: 1                             \t[default: 3]\n",
      "                    phase: train                         \t[default: test]\n",
      "               preprocess:                               \t[default: resize_and_crop]\n",
      "              results_dir: ./results/                    \n",
      "           serial_batches: False                         \n",
      "                   suffix:                               \n",
      "                use_wandb: False                         \n",
      "                  verbose: False                         \n",
      "       wandb_project_name: CycleGAN-and-pix2pix          \n",
      "----------------- End -------------------\n",
      "dataset [BioMasstersDataset] was created\n",
      "initialize network with normal\n",
      "model [Pix2PixModel] was created\n",
      "loading the model from ./checkpoints/biomassters_softplus_b3p0/latest_net_G.pth\n",
      "---------- Networks initialized -------------\n",
      "[Network G] Total number of parameters : 54.411 M\n",
      "-----------------------------------------------\n",
      "creating web directory ./results/biomassters_softplus_b3p0/train_latest\n",
      "processing (0000)-th image... ['A_dbe9a663']\n",
      "real_A shape: torch.Size([1, 4, 256, 256]) max: 5.619835 mean: 0.15556042 min: -3.22395 std: 1.188701\n",
      "real_A shape: (256, 256, 3) max: 255 mean: 94.76667785644531 min: 0 mean:\n",
      "fake_B shape: torch.Size([1, 1, 256, 256]) max: 786.1845 mean: 107.81424 min: 1.6389756e-10 std: 113.40957\n",
      "fake_B shape: (256, 256, 3) max: 255 mean: 34.615081787109375 min: 0 mean:\n",
      "real_B shape: torch.Size([1, 1, 256, 256]) max: 974.87 mean: 114.20087 min: 0.0 std: 121.88899\n",
      "real_B shape: (256, 256, 3) max: 255 mean: 29.520095825195312 min: 0 mean:\n",
      "0 ['A_dbe9a663'] RMSE: 46.976963\n",
      "real_A shape: torch.Size([1, 4, 256, 256]) max: 5.1522536 mean: -1.5616206 min: -3.5459752 std: 1.0143974\n",
      "real_A shape: (256, 256, 3) max: 255 mean: 45.87266540527344 min: 0 mean:\n",
      "fake_B shape: torch.Size([1, 1, 256, 256]) max: 650.37225 mean: 16.64096 min: 2.6464038e-09 std: 52.65171\n",
      "fake_B shape: (256, 256, 3) max: 255 mean: 6.449859619140625 min: 0 mean:\n",
      "real_B shape: torch.Size([1, 1, 256, 256]) max: 574.44 mean: 17.447464 min: 0.0 std: 55.384163\n",
      "real_B shape: (256, 256, 3) max: 255 mean: 7.6751556396484375 min: 0 mean:\n",
      "1 ['A_584e3e68'] RMSE: 14.988165\n",
      "real_A shape: torch.Size([1, 4, 256, 256]) max: 8.6378 mean: -0.31318438 min: -3.1054664 std: 1.5301406\n",
      "real_A shape: (256, 256, 3) max: 255 mean: 57.11045837402344 min: 0 mean:\n",
      "fake_B shape: torch.Size([1, 1, 256, 256]) max: 8202.627 mean: 37.916763 min: 0.0 std: 87.6494\n",
      "fake_B shape: (256, 256, 3) max: 255 mean: 1.0175933837890625 min: 0 mean:\n",
      "real_B shape: torch.Size([1, 1, 256, 256]) max: 668.58 mean: 42.17034 min: 0.0 std: 84.58561\n",
      "real_B shape: (256, 256, 3) max: 255 mean: 15.894119262695312 min: 0 mean:\n",
      "2 ['A_55a14920'] RMSE: 54.323715\n",
      "real_A shape: torch.Size([1, 4, 256, 256]) max: 6.084272 mean: 0.48652816 min: -2.3283021 std: 0.55189943\n",
      "real_A shape: (256, 256, 3) max: 255 mean: 79.35478210449219 min: 0 mean:\n",
      "fake_B shape: torch.Size([1, 1, 256, 256]) max: 602.4403 mean: 71.11514 min: 5.107344e-10 std: 72.59292\n",
      "fake_B shape: (256, 256, 3) max: 255 mean: 29.718826293945312 min: 0 mean:\n",
      "real_B shape: torch.Size([1, 1, 256, 256]) max: 742.87 mean: 75.07747 min: 0.0 std: 76.42348\n",
      "real_B shape: (256, 256, 3) max: 255 mean: 25.390472412109375 min: 0 mean:\n",
      "3 ['A_25fd4e5d'] RMSE: 27.546791\n",
      "real_A shape: torch.Size([1, 4, 256, 256]) max: 5.9119744 mean: 0.08318454 min: -3.4074469 std: 1.1311572\n",
      "real_A shape: (256, 256, 3) max: 255 mean: 95.6968994140625 min: 0 mean:\n",
      "fake_B shape: torch.Size([1, 1, 256, 256]) max: 2215.3025 mean: 53.356747 min: 2.2758665e-24 std: 68.77644\n",
      "fake_B shape: (256, 256, 3) max: 255 mean: 5.828948974609375 min: 0 mean:\n",
      "real_B shape: torch.Size([1, 1, 256, 256]) max: 3623.46 mean: 57.408886 min: 0.0 std: 74.66148\n",
      "real_B shape: (256, 256, 3) max: 255 mean: 3.7380828857421875 min: 0 mean:\n",
      "4 ['A_63d80a6c'] RMSE: 40.251476\n",
      "processing (0005)-th image... ['A_baacf334']\n",
      "real_A shape: torch.Size([1, 4, 256, 256]) max: 3.8961132 mean: -1.180161 min: -3.3638265 std: 1.0992024\n",
      "real_A shape: (256, 256, 3) max: 255 mean: 70.28683471679688 min: 0 mean:\n",
      "fake_B shape: torch.Size([1, 1, 256, 256]) max: 1087.4377 mean: 23.045654 min: 1.2565983e-10 std: 51.783424\n",
      "fake_B shape: (256, 256, 3) max: 255 mean: 5.281585693359375 min: 0 mean:\n",
      "real_B shape: torch.Size([1, 1, 256, 256]) max: 1123.73 mean: 24.144222 min: 0.0 std: 54.89416\n",
      "real_B shape: (256, 256, 3) max: 255 mean: 5.3676910400390625 min: 0 mean:\n",
      "5 ['A_baacf334'] RMSE: 18.399532\n",
      "real_A shape: torch.Size([1, 4, 256, 256]) max: 3.769498 mean: 0.6717403 min: -1.9364988 std: 0.44181728\n",
      "real_A shape: (256, 256, 3) max: 255 mean: 119.58769226074219 min: 0 mean:\n",
      "fake_B shape: torch.Size([1, 1, 256, 256]) max: 775.48303 mean: 87.62627 min: 5.7721626e-11 std: 74.677605\n",
      "fake_B shape: (256, 256, 3) max: 255 mean: 28.379638671875 min: 0 mean:\n",
      "real_B shape: torch.Size([1, 1, 256, 256]) max: 2351.33 mean: 91.334015 min: 0.0 std: 81.26584\n",
      "real_B shape: (256, 256, 3) max: 255 mean: 9.483840942382812 min: 0 mean:\n",
      "6 ['A_91f65529'] RMSE: 38.068214\n",
      "real_A shape: torch.Size([1, 4, 256, 256]) max: 10.11356 mean: 1.6910486 min: -2.6656492 std: 1.5493836\n",
      "real_A shape: (256, 256, 3) max: 255 mean: 95.09625244140625 min: 0 mean:\n",
      "fake_B shape: torch.Size([1, 1, 256, 256]) max: 3397.9937 mean: 130.1595 min: 1.3139471e-38 std: 137.8046\n",
      "fake_B shape: (256, 256, 3) max: 255 mean: 9.405654907226562 min: 0 mean:\n",
      "real_B shape: torch.Size([1, 1, 256, 256]) max: 2253.89 mean: 141.49512 min: 0.0 std: 149.18436\n",
      "real_B shape: (256, 256, 3) max: 255 mean: 15.641448974609375 min: 0 mean:\n",
      "7 ['A_d7a3a181'] RMSE: 67.76224\n",
      "real_A shape: torch.Size([1, 4, 256, 256]) max: 4.988312 mean: 0.47915113 min: -1.9367555 std: 0.58073586\n",
      "real_A shape: (256, 256, 3) max: 255 mean: 95.77825927734375 min: 0 mean:\n",
      "fake_B shape: torch.Size([1, 1, 256, 256]) max: 1682.767 mean: 49.997482 min: 3.2147013e-12 std: 72.755226\n",
      "fake_B shape: (256, 256, 3) max: 254 mean: 7.290313720703125 min: 0 mean:\n",
      "real_B shape: torch.Size([1, 1, 256, 256]) max: 2837.1 mean: 55.14382 min: 0.0 std: 82.59521\n",
      "real_B shape: (256, 256, 3) max: 254 mean: 4.694793701171875 min: 0 mean:\n",
      "8 ['A_fec09d0b'] RMSE: 47.737644\n",
      "real_A shape: torch.Size([1, 4, 256, 256]) max: 6.650031 mean: 0.6882906 min: -2.63582 std: 0.5631346\n",
      "real_A shape: (256, 256, 3) max: 255 mean: 95.30752563476562 min: 0 mean:\n",
      "fake_B shape: torch.Size([1, 1, 256, 256]) max: 4209.0835 mean: 82.43591 min: 8.1174574e-38 std: 95.902275\n",
      "fake_B shape: (256, 256, 3) max: 254 mean: 4.6266937255859375 min: 0 mean:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "real_B shape: torch.Size([1, 1, 256, 256]) max: 4283.12 mean: 91.54172 min: 0.0 std: 109.36359\r\n",
      "real_B shape: (256, 256, 3) max: 255 mean: 5.084991455078125 min: 0 mean:\r\n",
      "9 ['A_14d3b92b'] RMSE: 64.65061\r\n"
     ]
    }
   ],
   "source": [
    "!python ./pix2pix/test.py --dataroot ./data --name biomassters_softplus_b3p0 --model pix2pix --direction AtoB \\\n",
    "    --input_nc 4 --output_nc 1 --dataset_mode biomassters --gpu_ids -1 --phase train \\\n",
    "    --max_dataset_size 10 --preprocess \"\" \\\n",
    "    --no_dropout --results_dir ./results/ \\\n",
    "    --eval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scrap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1168.155029296875"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dd.images[1]['y'].max()*.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Options():\n",
    "    def __init__(self):\n",
    "        self.batch_size = 1\n",
    "        self.beta1 = 0.5\n",
    "        self.checkpoints_dir = './checkpoints'\n",
    "        self.continue_train = False\n",
    "        self.crop_size = 256\n",
    "        self.dataroot = './data'\n",
    "        self.dataset_mode = 'biomassters'\n",
    "        self.direction = 'AtoB'\n",
    "        self.display_env = 'main'\n",
    "        self.display_freq = 50\n",
    "        self.display_id = 1\n",
    "        self.display_ncols = 4\n",
    "        self.display_port = 8097\n",
    "        self.display_server = 'http://localhost'\n",
    "        self.display_winsize = 256\n",
    "        self.epoch = 'latest'\n",
    "        self.epoch_count = 1\n",
    "        self.gan_mode = 'vanilla'\n",
    "        self.gpu_ids = ''\n",
    "        self.init_gain = 0.02\n",
    "        self.init_type = 'normal'\n",
    "        self.input_nc = 180\n",
    "        self.isTrain = True\n",
    "        self.lambda_L1 = 100.0\n",
    "        self.load_iter = 0\n",
    "        self.load_size = 286\n",
    "        self.lr = 0.0002\n",
    "        self.lr_decay_iters = 50\n",
    "        self.lr_policy = 'linear'\n",
    "        self.max_dataset_size = 50\n",
    "        self.model = 'pix2pix'\n",
    "        self.n_epochs = 20\n",
    "        self.n_epochs_decay = 20\n",
    "        self.n_layers_D = 3\n",
    "        self.name = 'biomassters'\n",
    "        self.ndf = 64\n",
    "        self.netD = 'basic'\n",
    "        self.netG = 'unet_256'\n",
    "        self.ngf = 64\n",
    "        self.no_dropout = False\n",
    "        self.no_flip = True\n",
    "        self.no_html = False\n",
    "        self.norm = 'batch'\n",
    "        self.num_threads = 4\n",
    "        self.output_nc = 1\n",
    "        self.phase = 'train'\n",
    "        self.pool_size = 0\n",
    "        self.preprocess = ''\n",
    "        self.print_freq = 50\n",
    "        self.save_by_iter = False\n",
    "        self.save_epoch_freq = 5\n",
    "        self.save_latest_freq = 5000\n",
    "        self.serial_batches = False\n",
    "        self.suffix = ''\n",
    "        self.update_html_freq = 50\n",
    "        self.use_wandb = False\n",
    "        self.verbose = False\n",
    "        self.wandb_project_name = 'CycleGAN-and-pix2pix'\n",
    "        self.isTrain = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/loaner/projects/dd-biomassters\n",
      "     chip_id\n",
      "0   1a1f591d\n",
      "1   5521a4ea\n",
      "2   b910d1a7\n",
      "3   eee3ce3a\n",
      "4   49abd286\n",
      "5   187cf18b\n",
      "6   243bad58\n",
      "7   8baffdbd\n",
      "8   138bc232\n",
      "9   2003e1cb\n",
      "10  10cddd46\n",
      "11  31c77f10\n",
      "12  5f5e708d\n",
      "13  9d73fff0\n",
      "14  07765e15\n",
      "15  6dae4dd6\n",
      "16  9d67ba2e\n",
      "17  0964800b\n",
      "18  b4656b97\n",
      "19  81d8de14\n",
      "20  a8ca3a71\n",
      "21  7178cc89\n",
      "22  7d11f2dd\n",
      "23  d1ee88dd\n",
      "24  63ada952\n",
      "25  e6d173c7\n",
      "26  26622ebc\n",
      "27  7f487274\n",
      "28  cce5812b\n",
      "29  f5d88b97\n",
      "30  ee3be0be\n",
      "31  b6634e26\n",
      "32  0f709309\n",
      "33  3ec56f19\n",
      "34  3ae4288f\n",
      "35  81a07e36\n",
      "36  cc143994\n",
      "37  dcf1ba16\n",
      "38  c7687b82\n",
      "39  91f7bc39\n",
      "40  c31eb34f\n",
      "41  521e0fe7\n",
      "42  f42af1ea\n",
      "43  c3771d47\n",
      "44  92289d5a\n",
      "45  f74f7080\n",
      "46  10b290d1\n",
      "47  611cfadd\n",
      "48  46f4332d\n",
      "49  f90477a3\n",
      "dataset [BioMasstersDataset] was created\n",
      "initialize network with normal\n",
      "model [Pix2PixModel] was created\n",
      "loading the model from ./checkpoints/biomassters/latest_net_G.pth\n",
      "---------- Networks initialized -------------\n",
      "[Network G] Total number of parameters : 54.591 M\n",
      "-----------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "%cd /Users/loaner/projects/dd-biomassters/\n",
    "\n",
    "from pix2pix.data import create_dataset\n",
    "from pix2pix.models import create_model\n",
    "\n",
    "opt=Options()\n",
    "dataset = create_dataset(opt)  # create a dataset given opt.dataset_mode and other options\n",
    "model = create_model(opt)      # create a model given opt.model and other options\n",
    "model.setup(opt)               # regular setup: load and print networks; create schedulers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = list(model.netG.named_parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "UnetGenerator(\n",
       "  (model): UnetSkipConnectionBlock(\n",
       "    (model): Sequential(\n",
       "      (0): Conv2d(180, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (1): UnetSkipConnectionBlock(\n",
       "        (model): Sequential(\n",
       "          (0): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "          (1): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (3): UnetSkipConnectionBlock(\n",
       "            (model): Sequential(\n",
       "              (0): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "              (1): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "              (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (3): UnetSkipConnectionBlock(\n",
       "                (model): Sequential(\n",
       "                  (0): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "                  (1): Conv2d(256, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "                  (2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                  (3): UnetSkipConnectionBlock(\n",
       "                    (model): Sequential(\n",
       "                      (0): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "                      (1): Conv2d(512, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "                      (2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                      (3): UnetSkipConnectionBlock(\n",
       "                        (model): Sequential(\n",
       "                          (0): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "                          (1): Conv2d(512, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "                          (2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                          (3): UnetSkipConnectionBlock(\n",
       "                            (model): Sequential(\n",
       "                              (0): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "                              (1): Conv2d(512, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "                              (2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                              (3): UnetSkipConnectionBlock(\n",
       "                                (model): Sequential(\n",
       "                                  (0): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "                                  (1): Conv2d(512, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "                                  (2): ReLU(inplace=True)\n",
       "                                  (3): ConvTranspose2d(512, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "                                  (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                                )\n",
       "                              )\n",
       "                              (4): ReLU(inplace=True)\n",
       "                              (5): ConvTranspose2d(1024, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "                              (6): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                              (7): Dropout(p=0.5, inplace=False)\n",
       "                            )\n",
       "                          )\n",
       "                          (4): ReLU(inplace=True)\n",
       "                          (5): ConvTranspose2d(1024, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "                          (6): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                          (7): Dropout(p=0.5, inplace=False)\n",
       "                        )\n",
       "                      )\n",
       "                      (4): ReLU(inplace=True)\n",
       "                      (5): ConvTranspose2d(1024, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "                      (6): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                      (7): Dropout(p=0.5, inplace=False)\n",
       "                    )\n",
       "                  )\n",
       "                  (4): ReLU(inplace=True)\n",
       "                  (5): ConvTranspose2d(1024, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "                  (6): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                )\n",
       "              )\n",
       "              (4): ReLU(inplace=True)\n",
       "              (5): ConvTranspose2d(512, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "              (6): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (4): ReLU(inplace=True)\n",
       "          (5): ConvTranspose2d(256, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (6): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (2): ReLU(inplace=True)\n",
       "      (3): ConvTranspose2d(128, 1, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "      (4): Tanh()\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.netG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model.model.0.weight \n",
      " torch.Size([64, 180, 4, 4]) <class 'torch.Tensor'> -5.0240527e-05 -0.08555504 0.08721618\n",
      "model.model.1.model.1.weight \n",
      " torch.Size([128, 64, 4, 4]) <class 'torch.Tensor'> -0.000101658414 -0.083866164 0.09596747\n",
      "model.model.1.model.2.weight \n",
      " torch.Size([128]) <class 'torch.Tensor'> 0.99765587 0.95133114 1.0484908\n",
      "model.model.1.model.2.bias \n",
      " torch.Size([128]) <class 'torch.Tensor'> 2.6668804e-05 -0.0026267983 0.0031639268\n",
      "model.model.1.model.3.model.1.weight \n",
      " torch.Size([256, 128, 4, 4]) <class 'torch.Tensor'> 2.077245e-06 -0.0966072 0.09582907\n",
      "model.model.1.model.3.model.2.weight \n",
      " torch.Size([256]) <class 'torch.Tensor'> 0.99932534 0.9414475 1.0576552\n",
      "model.model.1.model.3.model.2.bias \n",
      " torch.Size([256]) <class 'torch.Tensor'> -8.123938e-05 -0.003666533 0.0035154072\n",
      "model.model.1.model.3.model.3.model.1.weight \n",
      " torch.Size([512, 256, 4, 4]) <class 'torch.Tensor'> -1.0472222e-05 -0.0980717 0.10492932\n",
      "model.model.1.model.3.model.3.model.2.weight \n",
      " torch.Size([512]) <class 'torch.Tensor'> 1.0012095 0.94015527 1.0624064\n",
      "model.model.1.model.3.model.3.model.2.bias \n",
      " torch.Size([512]) <class 'torch.Tensor'> -1.5192998e-05 -0.0027545802 0.003460677\n",
      "model.model.1.model.3.model.3.model.3.model.1.weight \n",
      " torch.Size([512, 512, 4, 4]) <class 'torch.Tensor'> 1.5913283e-06 -0.09991952 0.10342821\n",
      "model.model.1.model.3.model.3.model.3.model.2.weight \n",
      " torch.Size([512]) <class 'torch.Tensor'> 1.002148 0.9432624 1.0589885\n",
      "model.model.1.model.3.model.3.model.3.model.2.bias \n",
      " torch.Size([512]) <class 'torch.Tensor'> -6.999272e-06 -0.0035426964 0.0030618568\n",
      "model.model.1.model.3.model.3.model.3.model.3.model.1.weight \n",
      " torch.Size([512, 512, 4, 4]) <class 'torch.Tensor'> 7.011018e-06 -0.0998072 0.096237764\n",
      "model.model.1.model.3.model.3.model.3.model.3.model.2.weight \n",
      " torch.Size([512]) <class 'torch.Tensor'> 0.9984502 0.946666 1.0629287\n",
      "model.model.1.model.3.model.3.model.3.model.3.model.2.bias \n",
      " torch.Size([512]) <class 'torch.Tensor'> 5.4875258e-05 -0.0024301512 0.0030268608\n",
      "model.model.1.model.3.model.3.model.3.model.3.model.3.model.1.weight \n",
      " torch.Size([512, 512, 4, 4]) <class 'torch.Tensor'> 1.5485035e-05 -0.097481005 0.094521075\n",
      "model.model.1.model.3.model.3.model.3.model.3.model.3.model.2.weight \n",
      " torch.Size([512]) <class 'torch.Tensor'> 0.99930894 0.94420564 1.0796902\n",
      "model.model.1.model.3.model.3.model.3.model.3.model.3.model.2.bias \n",
      " torch.Size([512]) <class 'torch.Tensor'> 4.213252e-05 -0.00307718 0.002855226\n",
      "model.model.1.model.3.model.3.model.3.model.3.model.3.model.3.model.1.weight \n",
      " torch.Size([512, 512, 4, 4]) <class 'torch.Tensor'> 3.6662523e-06 -0.10032828 0.1035461\n",
      "model.model.1.model.3.model.3.model.3.model.3.model.3.model.3.model.3.weight \n",
      " torch.Size([512, 512, 4, 4]) <class 'torch.Tensor'> 3.0785134e-06 -0.10200761 0.10371481\n",
      "model.model.1.model.3.model.3.model.3.model.3.model.3.model.3.model.4.weight \n",
      " torch.Size([512]) <class 'torch.Tensor'> 0.999776 0.93560135 1.0530055\n",
      "model.model.1.model.3.model.3.model.3.model.3.model.3.model.3.model.4.bias \n",
      " torch.Size([512]) <class 'torch.Tensor'> 3.5459707e-05 -0.0031221062 0.0028790561\n",
      "model.model.1.model.3.model.3.model.3.model.3.model.3.model.5.weight \n",
      " torch.Size([1024, 512, 4, 4]) <class 'torch.Tensor'> -1.8484345e-06 -0.11044738 0.10491368\n",
      "model.model.1.model.3.model.3.model.3.model.3.model.3.model.6.weight \n",
      " torch.Size([512]) <class 'torch.Tensor'> 1.0004863 0.9306015 1.053325\n",
      "model.model.1.model.3.model.3.model.3.model.3.model.3.model.6.bias \n",
      " torch.Size([512]) <class 'torch.Tensor'> -5.916992e-05 -0.0041970205 0.0029419195\n",
      "model.model.1.model.3.model.3.model.3.model.3.model.5.weight \n",
      " torch.Size([1024, 512, 4, 4]) <class 'torch.Tensor'> -1.6445683e-05 -0.108352765 0.100793146\n",
      "model.model.1.model.3.model.3.model.3.model.3.model.6.weight \n",
      " torch.Size([512]) <class 'torch.Tensor'> 0.9994999 0.94953024 1.0623904\n",
      "model.model.1.model.3.model.3.model.3.model.3.model.6.bias \n",
      " torch.Size([512]) <class 'torch.Tensor'> 3.9674396e-05 -0.003991184 0.0042223246\n",
      "model.model.1.model.3.model.3.model.3.model.5.weight \n",
      " torch.Size([1024, 512, 4, 4]) <class 'torch.Tensor'> 2.53919e-06 -0.10319541 0.11123915\n",
      "model.model.1.model.3.model.3.model.3.model.6.weight \n",
      " torch.Size([512]) <class 'torch.Tensor'> 1.0007806 0.93178433 1.0687594\n",
      "model.model.1.model.3.model.3.model.3.model.6.bias \n",
      " torch.Size([512]) <class 'torch.Tensor'> -2.5577338e-05 -0.0033485456 0.0035107196\n",
      "model.model.1.model.3.model.3.model.5.weight \n",
      " torch.Size([1024, 256, 4, 4]) <class 'torch.Tensor'> 1.9636222e-05 -0.0979512 0.106883205\n",
      "model.model.1.model.3.model.3.model.6.weight \n",
      " torch.Size([256]) <class 'torch.Tensor'> 1.0004734 0.9318577 1.0525563\n",
      "model.model.1.model.3.model.3.model.6.bias \n",
      " torch.Size([256]) <class 'torch.Tensor'> 6.2615e-05 -0.0046957713 0.003958016\n",
      "model.model.1.model.3.model.5.weight \n",
      " torch.Size([512, 128, 4, 4]) <class 'torch.Tensor'> 9.732585e-06 -0.09773208 0.09556032\n",
      "model.model.1.model.3.model.6.weight \n",
      " torch.Size([128]) <class 'torch.Tensor'> 0.99804807 0.9419797 1.0503113\n",
      "model.model.1.model.3.model.6.bias \n",
      " torch.Size([128]) <class 'torch.Tensor'> -0.00012106044 -0.0031639447 0.003787541\n",
      "model.model.1.model.5.weight \n",
      " torch.Size([256, 64, 4, 4]) <class 'torch.Tensor'> -3.1479136e-05 -0.090002336 0.08698964\n",
      "model.model.1.model.6.weight \n",
      " torch.Size([64]) <class 'torch.Tensor'> 1.001941 0.96619374 1.0704508\n",
      "model.model.1.model.6.bias \n",
      " torch.Size([64]) <class 'torch.Tensor'> 0.00032428934 -0.003119918 0.0025210097\n",
      "model.model.3.weight \n",
      " torch.Size([128, 1, 4, 4]) <class 'torch.Tensor'> -0.0015379753 -0.07389148 0.07460423\n",
      "model.model.3.bias \n",
      " torch.Size([1]) <class 'torch.Tensor'> -0.0023177816 -0.0023177816 -0.0023177816\n"
     ]
    }
   ],
   "source": [
    "for name, param in model.netG.named_parameters():\n",
    "    \n",
    "    print(name, '\\n', param.shape, type(param.data), param.data.mean().numpy(), param.data.min().numpy(),param.data.max().numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check for missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chip_id</th>\n",
       "      <th>satellite</th>\n",
       "      <th>month</th>\n",
       "      <th>filename</th>\n",
       "      <th>split</th>\n",
       "      <th>size</th>\n",
       "      <th>cksum</th>\n",
       "      <th>s3path_us</th>\n",
       "      <th>s3path_eu</th>\n",
       "      <th>s3path_as</th>\n",
       "      <th>corresponding_agbm</th>\n",
       "      <th>file_not_found</th>\n",
       "      <th>num_s1_missing</th>\n",
       "      <th>num_s2_obscured</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0003d2eb</td>\n",
       "      <td>S1</td>\n",
       "      <td>1</td>\n",
       "      <td>0003d2eb_S1_04.tif</td>\n",
       "      <td>validation</td>\n",
       "      <td>1049524.0</td>\n",
       "      <td>2.467836e+09</td>\n",
       "      <td>s3://drivendata-competition-biomassters-public...</td>\n",
       "      <td>s3://drivendata-competition-biomassters-public...</td>\n",
       "      <td>s3://drivendata-competition-biomassters-public...</td>\n",
       "      <td>0003d2eb_agbm.tif</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0003d2eb</td>\n",
       "      <td>S1</td>\n",
       "      <td>2</td>\n",
       "      <td>0003d2eb_S1_05.tif</td>\n",
       "      <td>validation</td>\n",
       "      <td>1049524.0</td>\n",
       "      <td>2.955838e+09</td>\n",
       "      <td>s3://drivendata-competition-biomassters-public...</td>\n",
       "      <td>s3://drivendata-competition-biomassters-public...</td>\n",
       "      <td>s3://drivendata-competition-biomassters-public...</td>\n",
       "      <td>0003d2eb_agbm.tif</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0003d2eb</td>\n",
       "      <td>S1</td>\n",
       "      <td>3</td>\n",
       "      <td>0003d2eb_S1_06.tif</td>\n",
       "      <td>validation</td>\n",
       "      <td>1049524.0</td>\n",
       "      <td>9.389132e+08</td>\n",
       "      <td>s3://drivendata-competition-biomassters-public...</td>\n",
       "      <td>s3://drivendata-competition-biomassters-public...</td>\n",
       "      <td>s3://drivendata-competition-biomassters-public...</td>\n",
       "      <td>0003d2eb_agbm.tif</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0003d2eb</td>\n",
       "      <td>S1</td>\n",
       "      <td>4</td>\n",
       "      <td>0003d2eb_S1_07.tif</td>\n",
       "      <td>validation</td>\n",
       "      <td>1049524.0</td>\n",
       "      <td>2.259649e+08</td>\n",
       "      <td>s3://drivendata-competition-biomassters-public...</td>\n",
       "      <td>s3://drivendata-competition-biomassters-public...</td>\n",
       "      <td>s3://drivendata-competition-biomassters-public...</td>\n",
       "      <td>0003d2eb_agbm.tif</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0003d2eb</td>\n",
       "      <td>S1</td>\n",
       "      <td>5</td>\n",
       "      <td>0003d2eb_S1_08.tif</td>\n",
       "      <td>validation</td>\n",
       "      <td>1049524.0</td>\n",
       "      <td>1.351820e+08</td>\n",
       "      <td>s3://drivendata-competition-biomassters-public...</td>\n",
       "      <td>s3://drivendata-competition-biomassters-public...</td>\n",
       "      <td>s3://drivendata-competition-biomassters-public...</td>\n",
       "      <td>0003d2eb_agbm.tif</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    chip_id satellite  month            filename       split       size  \\\n",
       "0  0003d2eb        S1      1  0003d2eb_S1_04.tif  validation  1049524.0   \n",
       "1  0003d2eb        S1      2  0003d2eb_S1_05.tif  validation  1049524.0   \n",
       "2  0003d2eb        S1      3  0003d2eb_S1_06.tif  validation  1049524.0   \n",
       "3  0003d2eb        S1      4  0003d2eb_S1_07.tif  validation  1049524.0   \n",
       "4  0003d2eb        S1      5  0003d2eb_S1_08.tif  validation  1049524.0   \n",
       "\n",
       "          cksum                                          s3path_us  \\\n",
       "0  2.467836e+09  s3://drivendata-competition-biomassters-public...   \n",
       "1  2.955838e+09  s3://drivendata-competition-biomassters-public...   \n",
       "2  9.389132e+08  s3://drivendata-competition-biomassters-public...   \n",
       "3  2.259649e+08  s3://drivendata-competition-biomassters-public...   \n",
       "4  1.351820e+08  s3://drivendata-competition-biomassters-public...   \n",
       "\n",
       "                                           s3path_eu  \\\n",
       "0  s3://drivendata-competition-biomassters-public...   \n",
       "1  s3://drivendata-competition-biomassters-public...   \n",
       "2  s3://drivendata-competition-biomassters-public...   \n",
       "3  s3://drivendata-competition-biomassters-public...   \n",
       "4  s3://drivendata-competition-biomassters-public...   \n",
       "\n",
       "                                           s3path_as corresponding_agbm  \\\n",
       "0  s3://drivendata-competition-biomassters-public...  0003d2eb_agbm.tif   \n",
       "1  s3://drivendata-competition-biomassters-public...  0003d2eb_agbm.tif   \n",
       "2  s3://drivendata-competition-biomassters-public...  0003d2eb_agbm.tif   \n",
       "3  s3://drivendata-competition-biomassters-public...  0003d2eb_agbm.tif   \n",
       "4  s3://drivendata-competition-biomassters-public...  0003d2eb_agbm.tif   \n",
       "\n",
       "   file_not_found  num_s1_missing  num_s2_obscured  \n",
       "0             NaN             0.0              NaN  \n",
       "1             NaN             0.0              NaN  \n",
       "2             NaN             0.0              NaN  \n",
       "3             NaN             0.0              NaN  \n",
       "4             NaN             0.0              NaN  "
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df_metadata = pd.read_csv(\"data/metadata/features_metadata_split_42.csv\",index_col=0)\n",
    "df_metadata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df = df_metadata.copy()\n",
    "df['satellite_month'] = df.apply(lambda row: f\"{row['satellite']}_{row['month']}\", axis=1)\n",
    "df = df.groupby(['split', 'chip_id']).agg({\"satellite_month\": pd.Series.nunique, \"num_s1_missing\": sum, \"num_s2_obscured\": sum}).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total train 5821\n",
      "# with all satellite and monthly data 831\n",
      "# with no S1 missing pixels 4618\n",
      "# with no S2 obscured pixels 5821\n",
      "# complete 339\n",
      "Total validation 2868\n",
      "# with all satellite and monthly data 2868\n",
      "# with no S1 missing pixels 2280\n",
      "# with no S2 obscured pixels 2868\n",
      "# complete 2280\n",
      "Total test 2773\n",
      "# with all satellite and monthly data 539\n",
      "# with no S1 missing pixels 2121\n",
      "# with no S2 obscured pixels 2773\n",
      "# complete 207\n"
     ]
    }
   ],
   "source": [
    "for split in ('train', 'validation', 'test'):\n",
    "    print(f'Total {split}', len(df[(df.split==split)]))\n",
    "    print(f'# with all satellite and monthly data', len(df[(df.split==split)&(df.satellite_month==24)]))\n",
    "    print(f'# with no S1 missing pixels', len(df[(df.split==split)&(df.num_s1_missing==0)]))\n",
    "    print(f'# with no S2 obscured pixels', len(df[(df.split==split)&(df.num_s2_obscured==0)]))\n",
    "    print(f'# complete',len(df[(df.split==split)&(df.satellite_month==24)&(df.num_s1_missing==0)&(df.num_s2_obscured==0)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_chips = df[(df.split==split)&(df.satellite_month==24)&(df.num_s1_missing==0)&(df.num_s2_obscured==0)].chip_id.to_list()\n",
    "df_metadata['is_complete'] = df_metadata.chip_id.isin(complete_chips)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chip_id</th>\n",
       "      <th>satellite</th>\n",
       "      <th>month</th>\n",
       "      <th>filename</th>\n",
       "      <th>split</th>\n",
       "      <th>size</th>\n",
       "      <th>cksum</th>\n",
       "      <th>s3path_us</th>\n",
       "      <th>s3path_eu</th>\n",
       "      <th>s3path_as</th>\n",
       "      <th>corresponding_agbm</th>\n",
       "      <th>file_not_found</th>\n",
       "      <th>num_s1_missing</th>\n",
       "      <th>num_s2_obscured</th>\n",
       "      <th>is_complete</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2400</th>\n",
       "      <td>025109d9</td>\n",
       "      <td>S1</td>\n",
       "      <td>1</td>\n",
       "      <td>025109d9_S1_04.tif</td>\n",
       "      <td>test</td>\n",
       "      <td>1049524.0</td>\n",
       "      <td>1.348541e+09</td>\n",
       "      <td>s3://drivendata-competition-biomassters-public...</td>\n",
       "      <td>s3://drivendata-competition-biomassters-public...</td>\n",
       "      <td>s3://drivendata-competition-biomassters-public...</td>\n",
       "      <td>025109d9_agbm.tif</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2401</th>\n",
       "      <td>025109d9</td>\n",
       "      <td>S1</td>\n",
       "      <td>2</td>\n",
       "      <td>025109d9_S1_05.tif</td>\n",
       "      <td>test</td>\n",
       "      <td>1049524.0</td>\n",
       "      <td>2.937115e+09</td>\n",
       "      <td>s3://drivendata-competition-biomassters-public...</td>\n",
       "      <td>s3://drivendata-competition-biomassters-public...</td>\n",
       "      <td>s3://drivendata-competition-biomassters-public...</td>\n",
       "      <td>025109d9_agbm.tif</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2402</th>\n",
       "      <td>025109d9</td>\n",
       "      <td>S1</td>\n",
       "      <td>3</td>\n",
       "      <td>025109d9_S1_06.tif</td>\n",
       "      <td>test</td>\n",
       "      <td>1049524.0</td>\n",
       "      <td>3.755354e+09</td>\n",
       "      <td>s3://drivendata-competition-biomassters-public...</td>\n",
       "      <td>s3://drivendata-competition-biomassters-public...</td>\n",
       "      <td>s3://drivendata-competition-biomassters-public...</td>\n",
       "      <td>025109d9_agbm.tif</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2403</th>\n",
       "      <td>025109d9</td>\n",
       "      <td>S1</td>\n",
       "      <td>4</td>\n",
       "      <td>025109d9_S1_07.tif</td>\n",
       "      <td>test</td>\n",
       "      <td>1049524.0</td>\n",
       "      <td>2.547600e+09</td>\n",
       "      <td>s3://drivendata-competition-biomassters-public...</td>\n",
       "      <td>s3://drivendata-competition-biomassters-public...</td>\n",
       "      <td>s3://drivendata-competition-biomassters-public...</td>\n",
       "      <td>025109d9_agbm.tif</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2404</th>\n",
       "      <td>025109d9</td>\n",
       "      <td>S1</td>\n",
       "      <td>5</td>\n",
       "      <td>025109d9_S1_08.tif</td>\n",
       "      <td>test</td>\n",
       "      <td>1049524.0</td>\n",
       "      <td>4.067836e+09</td>\n",
       "      <td>s3://drivendata-competition-biomassters-public...</td>\n",
       "      <td>s3://drivendata-competition-biomassters-public...</td>\n",
       "      <td>s3://drivendata-competition-biomassters-public...</td>\n",
       "      <td>025109d9_agbm.tif</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2405</th>\n",
       "      <td>025109d9</td>\n",
       "      <td>S1</td>\n",
       "      <td>6</td>\n",
       "      <td>025109d9_S1_09.tif</td>\n",
       "      <td>test</td>\n",
       "      <td>1049524.0</td>\n",
       "      <td>3.783115e+09</td>\n",
       "      <td>s3://drivendata-competition-biomassters-public...</td>\n",
       "      <td>s3://drivendata-competition-biomassters-public...</td>\n",
       "      <td>s3://drivendata-competition-biomassters-public...</td>\n",
       "      <td>025109d9_agbm.tif</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2406</th>\n",
       "      <td>025109d9</td>\n",
       "      <td>S1</td>\n",
       "      <td>7</td>\n",
       "      <td>025109d9_S1_10.tif</td>\n",
       "      <td>test</td>\n",
       "      <td>1049524.0</td>\n",
       "      <td>8.027817e+08</td>\n",
       "      <td>s3://drivendata-competition-biomassters-public...</td>\n",
       "      <td>s3://drivendata-competition-biomassters-public...</td>\n",
       "      <td>s3://drivendata-competition-biomassters-public...</td>\n",
       "      <td>025109d9_agbm.tif</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2407</th>\n",
       "      <td>025109d9</td>\n",
       "      <td>S1</td>\n",
       "      <td>8</td>\n",
       "      <td>025109d9_S1_11.tif</td>\n",
       "      <td>test</td>\n",
       "      <td>1049524.0</td>\n",
       "      <td>3.990932e+09</td>\n",
       "      <td>s3://drivendata-competition-biomassters-public...</td>\n",
       "      <td>s3://drivendata-competition-biomassters-public...</td>\n",
       "      <td>s3://drivendata-competition-biomassters-public...</td>\n",
       "      <td>025109d9_agbm.tif</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2408</th>\n",
       "      <td>025109d9</td>\n",
       "      <td>S1</td>\n",
       "      <td>9</td>\n",
       "      <td>025109d9_S1_00.tif</td>\n",
       "      <td>test</td>\n",
       "      <td>1049524.0</td>\n",
       "      <td>1.624165e+09</td>\n",
       "      <td>s3://drivendata-competition-biomassters-public...</td>\n",
       "      <td>s3://drivendata-competition-biomassters-public...</td>\n",
       "      <td>s3://drivendata-competition-biomassters-public...</td>\n",
       "      <td>025109d9_agbm.tif</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2409</th>\n",
       "      <td>025109d9</td>\n",
       "      <td>S1</td>\n",
       "      <td>10</td>\n",
       "      <td>025109d9_S1_01.tif</td>\n",
       "      <td>test</td>\n",
       "      <td>1049524.0</td>\n",
       "      <td>4.187200e+09</td>\n",
       "      <td>s3://drivendata-competition-biomassters-public...</td>\n",
       "      <td>s3://drivendata-competition-biomassters-public...</td>\n",
       "      <td>s3://drivendata-competition-biomassters-public...</td>\n",
       "      <td>025109d9_agbm.tif</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2410</th>\n",
       "      <td>025109d9</td>\n",
       "      <td>S1</td>\n",
       "      <td>11</td>\n",
       "      <td>025109d9_S1_02.tif</td>\n",
       "      <td>test</td>\n",
       "      <td>1049524.0</td>\n",
       "      <td>1.028491e+09</td>\n",
       "      <td>s3://drivendata-competition-biomassters-public...</td>\n",
       "      <td>s3://drivendata-competition-biomassters-public...</td>\n",
       "      <td>s3://drivendata-competition-biomassters-public...</td>\n",
       "      <td>025109d9_agbm.tif</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2411</th>\n",
       "      <td>025109d9</td>\n",
       "      <td>S1</td>\n",
       "      <td>12</td>\n",
       "      <td>025109d9_S1_03.tif</td>\n",
       "      <td>test</td>\n",
       "      <td>1049524.0</td>\n",
       "      <td>2.169867e+09</td>\n",
       "      <td>s3://drivendata-competition-biomassters-public...</td>\n",
       "      <td>s3://drivendata-competition-biomassters-public...</td>\n",
       "      <td>s3://drivendata-competition-biomassters-public...</td>\n",
       "      <td>025109d9_agbm.tif</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2412</th>\n",
       "      <td>025109d9</td>\n",
       "      <td>S2</td>\n",
       "      <td>1</td>\n",
       "      <td>025109d9_S2_04.tif</td>\n",
       "      <td>test</td>\n",
       "      <td>1443550.0</td>\n",
       "      <td>1.273585e+09</td>\n",
       "      <td>s3://drivendata-competition-biomassters-public...</td>\n",
       "      <td>s3://drivendata-competition-biomassters-public...</td>\n",
       "      <td>s3://drivendata-competition-biomassters-public...</td>\n",
       "      <td>025109d9_agbm.tif</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2413</th>\n",
       "      <td>025109d9</td>\n",
       "      <td>S2</td>\n",
       "      <td>2</td>\n",
       "      <td>025109d9_S2_05.tif</td>\n",
       "      <td>test</td>\n",
       "      <td>1443550.0</td>\n",
       "      <td>3.765851e+09</td>\n",
       "      <td>s3://drivendata-competition-biomassters-public...</td>\n",
       "      <td>s3://drivendata-competition-biomassters-public...</td>\n",
       "      <td>s3://drivendata-competition-biomassters-public...</td>\n",
       "      <td>025109d9_agbm.tif</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2414</th>\n",
       "      <td>025109d9</td>\n",
       "      <td>S2</td>\n",
       "      <td>3</td>\n",
       "      <td>025109d9_S2_06.tif</td>\n",
       "      <td>test</td>\n",
       "      <td>1443550.0</td>\n",
       "      <td>8.402782e+08</td>\n",
       "      <td>s3://drivendata-competition-biomassters-public...</td>\n",
       "      <td>s3://drivendata-competition-biomassters-public...</td>\n",
       "      <td>s3://drivendata-competition-biomassters-public...</td>\n",
       "      <td>025109d9_agbm.tif</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2415</th>\n",
       "      <td>025109d9</td>\n",
       "      <td>S2</td>\n",
       "      <td>4</td>\n",
       "      <td>025109d9_S2_07.tif</td>\n",
       "      <td>test</td>\n",
       "      <td>1443550.0</td>\n",
       "      <td>1.198143e+06</td>\n",
       "      <td>s3://drivendata-competition-biomassters-public...</td>\n",
       "      <td>s3://drivendata-competition-biomassters-public...</td>\n",
       "      <td>s3://drivendata-competition-biomassters-public...</td>\n",
       "      <td>025109d9_agbm.tif</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2416</th>\n",
       "      <td>025109d9</td>\n",
       "      <td>S2</td>\n",
       "      <td>5</td>\n",
       "      <td>025109d9_S2_08.tif</td>\n",
       "      <td>test</td>\n",
       "      <td>1443550.0</td>\n",
       "      <td>1.002951e+09</td>\n",
       "      <td>s3://drivendata-competition-biomassters-public...</td>\n",
       "      <td>s3://drivendata-competition-biomassters-public...</td>\n",
       "      <td>s3://drivendata-competition-biomassters-public...</td>\n",
       "      <td>025109d9_agbm.tif</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2417</th>\n",
       "      <td>025109d9</td>\n",
       "      <td>S2</td>\n",
       "      <td>6</td>\n",
       "      <td>025109d9_S2_09.tif</td>\n",
       "      <td>test</td>\n",
       "      <td>1443550.0</td>\n",
       "      <td>9.087269e+07</td>\n",
       "      <td>s3://drivendata-competition-biomassters-public...</td>\n",
       "      <td>s3://drivendata-competition-biomassters-public...</td>\n",
       "      <td>s3://drivendata-competition-biomassters-public...</td>\n",
       "      <td>025109d9_agbm.tif</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2418</th>\n",
       "      <td>025109d9</td>\n",
       "      <td>S2</td>\n",
       "      <td>7</td>\n",
       "      <td>025109d9_S2_10.tif</td>\n",
       "      <td>test</td>\n",
       "      <td>1443550.0</td>\n",
       "      <td>7.477092e+08</td>\n",
       "      <td>s3://drivendata-competition-biomassters-public...</td>\n",
       "      <td>s3://drivendata-competition-biomassters-public...</td>\n",
       "      <td>s3://drivendata-competition-biomassters-public...</td>\n",
       "      <td>025109d9_agbm.tif</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2419</th>\n",
       "      <td>025109d9</td>\n",
       "      <td>S2</td>\n",
       "      <td>8</td>\n",
       "      <td>025109d9_S2_11.tif</td>\n",
       "      <td>test</td>\n",
       "      <td>1443550.0</td>\n",
       "      <td>3.752667e+09</td>\n",
       "      <td>s3://drivendata-competition-biomassters-public...</td>\n",
       "      <td>s3://drivendata-competition-biomassters-public...</td>\n",
       "      <td>s3://drivendata-competition-biomassters-public...</td>\n",
       "      <td>025109d9_agbm.tif</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2420</th>\n",
       "      <td>025109d9</td>\n",
       "      <td>S2</td>\n",
       "      <td>9</td>\n",
       "      <td>025109d9_S2_00.tif</td>\n",
       "      <td>test</td>\n",
       "      <td>1443550.0</td>\n",
       "      <td>3.534979e+09</td>\n",
       "      <td>s3://drivendata-competition-biomassters-public...</td>\n",
       "      <td>s3://drivendata-competition-biomassters-public...</td>\n",
       "      <td>s3://drivendata-competition-biomassters-public...</td>\n",
       "      <td>025109d9_agbm.tif</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2421</th>\n",
       "      <td>025109d9</td>\n",
       "      <td>S2</td>\n",
       "      <td>10</td>\n",
       "      <td>025109d9_S2_01.tif</td>\n",
       "      <td>test</td>\n",
       "      <td>1443550.0</td>\n",
       "      <td>3.937654e+08</td>\n",
       "      <td>s3://drivendata-competition-biomassters-public...</td>\n",
       "      <td>s3://drivendata-competition-biomassters-public...</td>\n",
       "      <td>s3://drivendata-competition-biomassters-public...</td>\n",
       "      <td>025109d9_agbm.tif</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2422</th>\n",
       "      <td>025109d9</td>\n",
       "      <td>S2</td>\n",
       "      <td>11</td>\n",
       "      <td>025109d9_S2_02.tif</td>\n",
       "      <td>test</td>\n",
       "      <td>1443550.0</td>\n",
       "      <td>2.975049e+09</td>\n",
       "      <td>s3://drivendata-competition-biomassters-public...</td>\n",
       "      <td>s3://drivendata-competition-biomassters-public...</td>\n",
       "      <td>s3://drivendata-competition-biomassters-public...</td>\n",
       "      <td>025109d9_agbm.tif</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2423</th>\n",
       "      <td>025109d9</td>\n",
       "      <td>S2</td>\n",
       "      <td>12</td>\n",
       "      <td>025109d9_S2_03.tif</td>\n",
       "      <td>test</td>\n",
       "      <td>1443550.0</td>\n",
       "      <td>1.334223e+09</td>\n",
       "      <td>s3://drivendata-competition-biomassters-public...</td>\n",
       "      <td>s3://drivendata-competition-biomassters-public...</td>\n",
       "      <td>s3://drivendata-competition-biomassters-public...</td>\n",
       "      <td>025109d9_agbm.tif</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       chip_id satellite  month            filename split       size  \\\n",
       "2400  025109d9        S1      1  025109d9_S1_04.tif  test  1049524.0   \n",
       "2401  025109d9        S1      2  025109d9_S1_05.tif  test  1049524.0   \n",
       "2402  025109d9        S1      3  025109d9_S1_06.tif  test  1049524.0   \n",
       "2403  025109d9        S1      4  025109d9_S1_07.tif  test  1049524.0   \n",
       "2404  025109d9        S1      5  025109d9_S1_08.tif  test  1049524.0   \n",
       "2405  025109d9        S1      6  025109d9_S1_09.tif  test  1049524.0   \n",
       "2406  025109d9        S1      7  025109d9_S1_10.tif  test  1049524.0   \n",
       "2407  025109d9        S1      8  025109d9_S1_11.tif  test  1049524.0   \n",
       "2408  025109d9        S1      9  025109d9_S1_00.tif  test  1049524.0   \n",
       "2409  025109d9        S1     10  025109d9_S1_01.tif  test  1049524.0   \n",
       "2410  025109d9        S1     11  025109d9_S1_02.tif  test  1049524.0   \n",
       "2411  025109d9        S1     12  025109d9_S1_03.tif  test  1049524.0   \n",
       "2412  025109d9        S2      1  025109d9_S2_04.tif  test  1443550.0   \n",
       "2413  025109d9        S2      2  025109d9_S2_05.tif  test  1443550.0   \n",
       "2414  025109d9        S2      3  025109d9_S2_06.tif  test  1443550.0   \n",
       "2415  025109d9        S2      4  025109d9_S2_07.tif  test  1443550.0   \n",
       "2416  025109d9        S2      5  025109d9_S2_08.tif  test  1443550.0   \n",
       "2417  025109d9        S2      6  025109d9_S2_09.tif  test  1443550.0   \n",
       "2418  025109d9        S2      7  025109d9_S2_10.tif  test  1443550.0   \n",
       "2419  025109d9        S2      8  025109d9_S2_11.tif  test  1443550.0   \n",
       "2420  025109d9        S2      9  025109d9_S2_00.tif  test  1443550.0   \n",
       "2421  025109d9        S2     10  025109d9_S2_01.tif  test  1443550.0   \n",
       "2422  025109d9        S2     11  025109d9_S2_02.tif  test  1443550.0   \n",
       "2423  025109d9        S2     12  025109d9_S2_03.tif  test  1443550.0   \n",
       "\n",
       "             cksum                                          s3path_us  \\\n",
       "2400  1.348541e+09  s3://drivendata-competition-biomassters-public...   \n",
       "2401  2.937115e+09  s3://drivendata-competition-biomassters-public...   \n",
       "2402  3.755354e+09  s3://drivendata-competition-biomassters-public...   \n",
       "2403  2.547600e+09  s3://drivendata-competition-biomassters-public...   \n",
       "2404  4.067836e+09  s3://drivendata-competition-biomassters-public...   \n",
       "2405  3.783115e+09  s3://drivendata-competition-biomassters-public...   \n",
       "2406  8.027817e+08  s3://drivendata-competition-biomassters-public...   \n",
       "2407  3.990932e+09  s3://drivendata-competition-biomassters-public...   \n",
       "2408  1.624165e+09  s3://drivendata-competition-biomassters-public...   \n",
       "2409  4.187200e+09  s3://drivendata-competition-biomassters-public...   \n",
       "2410  1.028491e+09  s3://drivendata-competition-biomassters-public...   \n",
       "2411  2.169867e+09  s3://drivendata-competition-biomassters-public...   \n",
       "2412  1.273585e+09  s3://drivendata-competition-biomassters-public...   \n",
       "2413  3.765851e+09  s3://drivendata-competition-biomassters-public...   \n",
       "2414  8.402782e+08  s3://drivendata-competition-biomassters-public...   \n",
       "2415  1.198143e+06  s3://drivendata-competition-biomassters-public...   \n",
       "2416  1.002951e+09  s3://drivendata-competition-biomassters-public...   \n",
       "2417  9.087269e+07  s3://drivendata-competition-biomassters-public...   \n",
       "2418  7.477092e+08  s3://drivendata-competition-biomassters-public...   \n",
       "2419  3.752667e+09  s3://drivendata-competition-biomassters-public...   \n",
       "2420  3.534979e+09  s3://drivendata-competition-biomassters-public...   \n",
       "2421  3.937654e+08  s3://drivendata-competition-biomassters-public...   \n",
       "2422  2.975049e+09  s3://drivendata-competition-biomassters-public...   \n",
       "2423  1.334223e+09  s3://drivendata-competition-biomassters-public...   \n",
       "\n",
       "                                              s3path_eu  \\\n",
       "2400  s3://drivendata-competition-biomassters-public...   \n",
       "2401  s3://drivendata-competition-biomassters-public...   \n",
       "2402  s3://drivendata-competition-biomassters-public...   \n",
       "2403  s3://drivendata-competition-biomassters-public...   \n",
       "2404  s3://drivendata-competition-biomassters-public...   \n",
       "2405  s3://drivendata-competition-biomassters-public...   \n",
       "2406  s3://drivendata-competition-biomassters-public...   \n",
       "2407  s3://drivendata-competition-biomassters-public...   \n",
       "2408  s3://drivendata-competition-biomassters-public...   \n",
       "2409  s3://drivendata-competition-biomassters-public...   \n",
       "2410  s3://drivendata-competition-biomassters-public...   \n",
       "2411  s3://drivendata-competition-biomassters-public...   \n",
       "2412  s3://drivendata-competition-biomassters-public...   \n",
       "2413  s3://drivendata-competition-biomassters-public...   \n",
       "2414  s3://drivendata-competition-biomassters-public...   \n",
       "2415  s3://drivendata-competition-biomassters-public...   \n",
       "2416  s3://drivendata-competition-biomassters-public...   \n",
       "2417  s3://drivendata-competition-biomassters-public...   \n",
       "2418  s3://drivendata-competition-biomassters-public...   \n",
       "2419  s3://drivendata-competition-biomassters-public...   \n",
       "2420  s3://drivendata-competition-biomassters-public...   \n",
       "2421  s3://drivendata-competition-biomassters-public...   \n",
       "2422  s3://drivendata-competition-biomassters-public...   \n",
       "2423  s3://drivendata-competition-biomassters-public...   \n",
       "\n",
       "                                              s3path_as corresponding_agbm  \\\n",
       "2400  s3://drivendata-competition-biomassters-public...  025109d9_agbm.tif   \n",
       "2401  s3://drivendata-competition-biomassters-public...  025109d9_agbm.tif   \n",
       "2402  s3://drivendata-competition-biomassters-public...  025109d9_agbm.tif   \n",
       "2403  s3://drivendata-competition-biomassters-public...  025109d9_agbm.tif   \n",
       "2404  s3://drivendata-competition-biomassters-public...  025109d9_agbm.tif   \n",
       "2405  s3://drivendata-competition-biomassters-public...  025109d9_agbm.tif   \n",
       "2406  s3://drivendata-competition-biomassters-public...  025109d9_agbm.tif   \n",
       "2407  s3://drivendata-competition-biomassters-public...  025109d9_agbm.tif   \n",
       "2408  s3://drivendata-competition-biomassters-public...  025109d9_agbm.tif   \n",
       "2409  s3://drivendata-competition-biomassters-public...  025109d9_agbm.tif   \n",
       "2410  s3://drivendata-competition-biomassters-public...  025109d9_agbm.tif   \n",
       "2411  s3://drivendata-competition-biomassters-public...  025109d9_agbm.tif   \n",
       "2412  s3://drivendata-competition-biomassters-public...  025109d9_agbm.tif   \n",
       "2413  s3://drivendata-competition-biomassters-public...  025109d9_agbm.tif   \n",
       "2414  s3://drivendata-competition-biomassters-public...  025109d9_agbm.tif   \n",
       "2415  s3://drivendata-competition-biomassters-public...  025109d9_agbm.tif   \n",
       "2416  s3://drivendata-competition-biomassters-public...  025109d9_agbm.tif   \n",
       "2417  s3://drivendata-competition-biomassters-public...  025109d9_agbm.tif   \n",
       "2418  s3://drivendata-competition-biomassters-public...  025109d9_agbm.tif   \n",
       "2419  s3://drivendata-competition-biomassters-public...  025109d9_agbm.tif   \n",
       "2420  s3://drivendata-competition-biomassters-public...  025109d9_agbm.tif   \n",
       "2421  s3://drivendata-competition-biomassters-public...  025109d9_agbm.tif   \n",
       "2422  s3://drivendata-competition-biomassters-public...  025109d9_agbm.tif   \n",
       "2423  s3://drivendata-competition-biomassters-public...  025109d9_agbm.tif   \n",
       "\n",
       "      file_not_found  num_s1_missing  num_s2_obscured  is_complete  \n",
       "2400             NaN             0.0              NaN         True  \n",
       "2401             NaN             0.0              NaN         True  \n",
       "2402             NaN             0.0              NaN         True  \n",
       "2403             NaN             0.0              NaN         True  \n",
       "2404             NaN             0.0              NaN         True  \n",
       "2405             NaN             0.0              NaN         True  \n",
       "2406             NaN             0.0              NaN         True  \n",
       "2407             NaN             0.0              NaN         True  \n",
       "2408             NaN             0.0              NaN         True  \n",
       "2409             NaN             0.0              NaN         True  \n",
       "2410             NaN             0.0              NaN         True  \n",
       "2411             NaN             0.0              NaN         True  \n",
       "2412             NaN             NaN              0.0         True  \n",
       "2413             NaN             NaN              0.0         True  \n",
       "2414             NaN             NaN              0.0         True  \n",
       "2415             NaN             NaN              0.0         True  \n",
       "2416             NaN             NaN              0.0         True  \n",
       "2417             NaN             NaN              0.0         True  \n",
       "2418             NaN             NaN              0.0         True  \n",
       "2419             NaN             NaN              0.0         True  \n",
       "2420             NaN             NaN              0.0         True  \n",
       "2421             NaN             NaN              0.0         True  \n",
       "2422             NaN             NaN              0.0         True  \n",
       "2423             NaN             NaN              0.0         True  "
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_metadata[df_metadata.chip_id == '025109d9']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": ".env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
