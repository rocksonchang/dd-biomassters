{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run Training and Testing Scripts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/loaner/projects/dd-biomassters\n",
      "----------------- Options ---------------\n",
      "               batch_size: 10                            \t[default: 1]\n",
      "                    beta1: 0.5                           \n",
      "          checkpoints_dir: ./checkpoints                 \n",
      "           continue_train: False                         \n",
      "                crop_size: 256                           \n",
      "                 dataroot: ./data                        \t[default: data]\n",
      "             dataset_mode: biomassters                   \t[default: aligned]\n",
      "                direction: AtoB                          \n",
      "              display_env: main                          \n",
      "             display_freq: 100                           \t[default: 400]\n",
      "               display_id: 1                             \n",
      "            display_ncols: 4                             \n",
      "             display_port: 8097                          \n",
      "           display_server: http://localhost              \n",
      "          display_winsize: 256                           \n",
      "                    epoch: latest                        \n",
      "              epoch_count: 1                             \n",
      "             g_activation: Softplus                      \t[default: Tanh]\n",
      "                 gan_mode: vanilla                       \n",
      "                  gpu_ids: -1                            \t[default: 0]\n",
      "                init_gain: 0.02                          \n",
      "                init_type: normal                        \n",
      "                 input_nc: 16                            \t[default: 3]\n",
      "                  isTrain: True                          \t[default: None]\n",
      "                lambda_L1: 100.0                         \n",
      "                load_iter: 0                             \t[default: 0]\n",
      "                load_size: 286                           \n",
      "                       lr: 0.0002                        \n",
      "           lr_decay_iters: 50                            \n",
      "                lr_policy: linear                        \n",
      "         max_dataset_size: 100                           \t[default: inf]\n",
      "                    model: pix2pix_bio                   \t[default: cycle_gan]\n",
      "                 n_epochs: 40                            \t[default: 100]\n",
      "           n_epochs_decay: 5                             \t[default: 100]\n",
      "               n_layers_D: 3                             \n",
      "                     name: biomassters_20221202          \t[default: experiment_name]\n",
      "                      ndf: 64                            \n",
      "                     netD: basic                         \n",
      "                     netG: unet_256                      \n",
      "                      ngf: 64                            \n",
      "               no_dropout: False                         \n",
      "                  no_flip: True                          \t[default: False]\n",
      "                  no_html: False                         \n",
      "                     norm: batch                         \n",
      "              num_threads: 4                             \n",
      "                output_nc: 1                             \t[default: 3]\n",
      "                    phase: train                         \n",
      "                pool_size: 0                             \n",
      "               preprocess:                               \t[default: resize_and_crop]\n",
      "               print_freq: 100                           \n",
      "             save_by_iter: False                         \n",
      "          save_epoch_freq: 10                            \t[default: 5]\n",
      "         save_latest_freq: 5000                          \n",
      "           serial_batches: False                         \n",
      "                   suffix:                               \n",
      "         update_html_freq: 500                           \t[default: 1000]\n",
      "                use_wandb: False                         \n",
      "                  verbose: False                         \n",
      "       wandb_project_name: CycleGAN-and-pix2pix          \n",
      "----------------- End -------------------\n",
      "dataset [BioMasstersDataset] was created\n",
      "The number of training images = 100\n",
      "initialize network with normal\n",
      "initialize network with normal\n",
      "model [Pix2PixBioModel] was created\n",
      "---------- Networks initialized -------------\n",
      "[Network G] Total number of parameters : 54.423 M\n",
      "[Network D] Total number of parameters : 2.780 M\n",
      "-----------------------------------------------\n",
      "Setting up a new session...\n",
      "create web directory ./checkpoints/biomassters_20221202/web...\n",
      "/Users/loaner/.pyenv/versions/3.8.15/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:138: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  warnings.warn(\"Detected call of `lr_scheduler.step()` before `optimizer.step()`. \"\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "RMSE fake image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 400.68, min: 61.78, mean: 197.44, std: 20.97\n",
      "RMSE real image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 1419.47, min: 0.00, mean: 65.43, std: 68.20\n",
      "(epoch: 1, iters: 100, time: 1.447, data: 14.371) G_GAN: 0.723 G_L1: 35.874 D_real: 0.736 D_fake: 0.744 RMSE: 149.773 \n",
      "End of epoch 1 / 45 \t Time Taken: 172 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "RMSE fake image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 275.93, min: 37.78, mean: 140.67, std: 26.79\n",
      "RMSE real image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 587.90, min: 0.00, mean: 61.48, std: 73.76\n",
      "(epoch: 2, iters: 100, time: 1.332, data: 14.595) G_GAN: 0.715 G_L1: 25.094 D_real: 0.720 D_fake: 0.713 RMSE: 109.406 \n",
      "End of epoch 2 / 45 \t Time Taken: 168 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "RMSE fake image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 255.10, min: 9.47, mean: 92.23, std: 26.43\n",
      "RMSE real image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 489.57, min: 0.00, mean: 44.45, std: 57.59\n",
      "(epoch: 3, iters: 100, time: 1.498, data: 14.635) G_GAN: 0.706 G_L1: 16.760 D_real: 0.730 D_fake: 0.704 RMSE: 74.945 \n",
      "End of epoch 3 / 45 \t Time Taken: 179 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "RMSE fake image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 247.29, min: 0.08, mean: 67.21, std: 25.82\n",
      "RMSE real image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 2834.73, min: 0.00, mean: 54.53, std: 75.88\n",
      "(epoch: 4, iters: 100, time: 1.710, data: 15.292) G_GAN: 0.704 G_L1: 14.588 D_real: 0.705 D_fake: 0.695 RMSE: 76.248 \n",
      "End of epoch 4 / 45 \t Time Taken: 202 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n"
     ]
    }
   ],
   "source": [
    "%cd /Users/loaner/projects/dd-biomassters\n",
    "!python ./pix2pix/train.py \\\n",
    "    --dataroot ./data --name biomassters_20221202 --model pix2pix_bio --phase train --gpu_ids -1 \\\n",
    "    --direction AtoB --input_nc 16 --output_nc 1 --dataset_mode biomassters --preprocess \"\" --no_flip  \\\n",
    "    --g_activation Softplus \\\n",
    "    --batch_size 10 --max_dataset_size 100 \\\n",
    "    --n_epochs 40 --n_epochs_decay 5 --lr 0.0002 \\\n",
    "    --display_id 1 --display_freq 100 --print_freq 100 --update_html_freq 500 --save_epoch_freq 10 \\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".dd-biomassters",
   "language": "python",
   "name": ".dd-biomassters"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
