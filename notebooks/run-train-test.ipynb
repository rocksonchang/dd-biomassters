{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run Training and Testing Scripts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train\n",
    "Start visdom server: `python -m visdom.server` \n",
    "\n",
    "Otherwise set display id to -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/projects/dd-biomassters\n",
      "----------------- Options ---------------\n",
      "               batch_size: 10                            \t[default: 1]\n",
      "                    beta1: 0.5                           \n",
      "          checkpoints_dir: ./checkpoints                 \n",
      "           continue_train: False                         \n",
      "                crop_size: 256                           \n",
      "                 dataroot: ./data                        \t[default: data]\n",
      "             dataset_mode: biomassters                   \t[default: aligned]\n",
      "                direction: AtoB                          \n",
      "              display_env: main                          \n",
      "             display_freq: 500                           \t[default: 400]\n",
      "               display_id: 1                             \n",
      "            display_ncols: 4                             \n",
      "             display_port: 8097                          \n",
      "           display_server: http://localhost              \n",
      "          display_winsize: 256                           \n",
      "                    epoch: latest                        \n",
      "              epoch_count: 1                             \n",
      "             g_activation: Softplus                      \t[default: Tanh]\n",
      "                 gan_mode: vanilla                       \n",
      "                  gpu_ids: 0                             \n",
      "                init_gain: 0.02                          \n",
      "                init_type: normal                        \n",
      "                 input_nc: 16                            \t[default: 3]\n",
      "                  isTrain: True                          \t[default: None]\n",
      "                lambda_L1: 100.0                         \n",
      "                load_iter: 0                             \t[default: 0]\n",
      "                load_size: 286                           \n",
      "                       lr: 0.0002                        \n",
      "           lr_decay_iters: 50                            \n",
      "                lr_policy: linear                        \n",
      "         max_dataset_size: 1000                          \t[default: inf]\n",
      "                    model: pix2pix_bio                   \t[default: cycle_gan]\n",
      "                 n_epochs: 100                           \n",
      "           n_epochs_decay: 100                           \n",
      "               n_layers_D: 3                             \n",
      "                     name: biomassters_20221203_02       \t[default: experiment_name]\n",
      "                      ndf: 64                            \n",
      "                     netD: basic                         \n",
      "                     netG: unet_256                      \n",
      "                      ngf: 64                            \n",
      "               no_dropout: False                         \n",
      "                  no_flip: True                          \t[default: False]\n",
      "                  no_html: False                         \n",
      "                     norm: batch                         \n",
      "              num_threads: 4                             \n",
      "                output_nc: 1                             \t[default: 3]\n",
      "                    phase: train                         \n",
      "                pool_size: 0                             \n",
      "               preprocess:                               \t[default: resize_and_crop]\n",
      "               print_freq: 500                           \t[default: 100]\n",
      "             save_by_iter: False                         \n",
      "          save_epoch_freq: 1000                          \t[default: 5]\n",
      "         save_latest_freq: 5000                          \n",
      "           serial_batches: False                         \n",
      "                   suffix:                               \n",
      "         update_html_freq: 1000                          \n",
      "                use_wandb: False                         \n",
      "                  verbose: False                         \n",
      "       wandb_project_name: CycleGAN-and-pix2pix          \n",
      "----------------- End -------------------\n",
      "dataset [BioMasstersDataset] was created\n",
      "The number of training images = 1000\n",
      "initialize network with normal\n",
      "initialize network with normal\n",
      "model [Pix2PixBioModel] was created\n",
      "---------- Networks initialized -------------\n",
      "[Network G] Total number of parameters : 54.423 M\n",
      "[Network D] Total number of parameters : 2.780 M\n",
      "-----------------------------------------------\n",
      "Setting up a new session...\n",
      "create web directory ./checkpoints/biomassters_20221203_02/web...\n",
      "/opt/conda/envs/pytorch/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:138: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  warnings.warn(\"Detected call of `lr_scheduler.step()` before `optimizer.step()`. \"\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "RMSE fake image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 239.41, min: 3.00, mean: 75.06, std: 24.89\n",
      "RMSE real image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 1709.82, min: 0.00, mean: 49.86, std: 61.91\n",
      "(epoch: 1, iters: 500, time: 0.062, data: 2.229) G_GAN: 0.710 G_L1: 13.242 D_real: 0.690 D_fake: 0.712 RMSE: 62.363 \n",
      "RMSE fake image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 236.17, min: 0.76, mean: 54.96, std: 32.75\n",
      "RMSE real image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 1198.81, min: 0.00, mean: 54.37, std: 56.97\n",
      "(epoch: 1, iters: 1000, time: 0.077, data: 0.727) G_GAN: 0.748 G_L1: 7.380 D_real: 0.702 D_fake: 0.660 RMSE: 41.375 \n",
      "End of epoch 1 / 200 \t Time Taken: 59 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "RMSE fake image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 393.13, min: 0.03, mean: 60.51, std: 44.39\n",
      "RMSE real image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 3221.46, min: 0.00, mean: 54.85, std: 72.19\n",
      "(epoch: 2, iters: 500, time: 0.064, data: 2.137) G_GAN: 0.773 G_L1: 8.263 D_real: 0.692 D_fake: 0.624 RMSE: 49.930 \n",
      "RMSE fake image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 365.88, min: 0.03, mean: 55.89, std: 45.96\n",
      "RMSE real image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 1454.35, min: 0.00, mean: 63.14, std: 70.68\n",
      "(epoch: 2, iters: 1000, time: 0.056, data: 0.014) G_GAN: 0.783 G_L1: 7.749 D_real: 0.693 D_fake: 0.509 RMSE: 49.453 \n",
      "End of epoch 2 / 200 \t Time Taken: 53 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "RMSE fake image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 387.49, min: 0.01, mean: 48.07, std: 40.44\n",
      "RMSE real image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 593.06, min: 0.00, mean: 64.01, std: 60.96\n",
      "(epoch: 3, iters: 500, time: 0.085, data: 2.043) G_GAN: 0.907 G_L1: 7.775 D_real: 0.609 D_fake: 0.669 RMSE: 46.235 \n",
      "RMSE fake image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 494.15, min: 0.00, mean: 56.18, std: 46.76\n",
      "RMSE real image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 749.28, min: 0.00, mean: 69.00, std: 73.52\n",
      "(epoch: 3, iters: 1000, time: 0.078, data: 0.009) G_GAN: 0.856 G_L1: 7.899 D_real: 0.447 D_fake: 0.751 RMSE: 49.431 \n",
      "End of epoch 3 / 200 \t Time Taken: 54 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "RMSE fake image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 384.11, min: 0.00, mean: 55.55, std: 51.45\n",
      "RMSE real image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 1027.58, min: 0.00, mean: 56.35, std: 66.37\n",
      "(epoch: 4, iters: 500, time: 0.086, data: 2.097) G_GAN: 0.802 G_L1: 6.115 D_real: 0.649 D_fake: 0.562 RMSE: 38.563 \n",
      "RMSE fake image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 392.23, min: 0.00, mean: 56.00, std: 52.07\n",
      "RMSE real image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 1254.59, min: 0.00, mean: 69.94, std: 69.96\n",
      "(epoch: 4, iters: 1000, time: 0.081, data: 0.017) G_GAN: 0.875 G_L1: 7.488 D_real: 0.442 D_fake: 0.845 RMSE: 46.527 \n",
      "End of epoch 4 / 200 \t Time Taken: 53 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE fake image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 378.01, min: 0.00, mean: 52.76, std: 51.86\n",
      "RMSE real image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 983.96, min: 0.00, mean: 48.38, std: 53.98\n",
      "(epoch: 5, iters: 500, time: 0.090, data: 2.073) G_GAN: 0.671 G_L1: 5.189 D_real: 0.720 D_fake: 0.598 RMSE: 33.547 \n",
      "RMSE fake image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 461.77, min: 0.00, mean: 58.61, std: 61.95\n",
      "RMSE real image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 1024.05, min: 0.00, mean: 42.87, std: 54.99\n",
      "(epoch: 5, iters: 1000, time: 0.082, data: 0.011) G_GAN: 0.680 G_L1: 6.196 D_real: 0.750 D_fake: 0.818 RMSE: 39.194 \n",
      "saving the latest model (epoch 5, total_iters 5000)\n",
      "End of epoch 5 / 200 \t Time Taken: 54 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "RMSE fake image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 497.32, min: 0.00, mean: 56.46, std: 45.92\n",
      "RMSE real image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 2577.69, min: 0.00, mean: 74.72, std: 74.57\n",
      "(epoch: 6, iters: 500, time: 0.091, data: 2.250) G_GAN: 1.101 G_L1: 8.826 D_real: 0.427 D_fake: 0.700 RMSE: 58.480 \n",
      "RMSE fake image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 401.68, min: 0.00, mean: 55.97, std: 54.07\n",
      "RMSE real image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 3221.46, min: 0.00, mean: 57.76, std: 65.42\n",
      "(epoch: 6, iters: 1000, time: 0.079, data: 0.010) G_GAN: 0.804 G_L1: 6.163 D_real: 0.467 D_fake: 0.763 RMSE: 40.052 \n",
      "End of epoch 6 / 200 \t Time Taken: 54 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "RMSE fake image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 356.47, min: 0.00, mean: 56.44, std: 54.85\n",
      "RMSE real image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 569.67, min: 0.00, mean: 70.83, std: 73.49\n",
      "(epoch: 7, iters: 500, time: 0.068, data: 2.211) G_GAN: 0.797 G_L1: 7.328 D_real: 0.579 D_fake: 0.634 RMSE: 46.440 \n",
      "RMSE fake image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 441.83, min: 0.00, mean: 60.36, std: 62.36\n",
      "RMSE real image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 738.57, min: 0.00, mean: 46.20, std: 52.59\n",
      "(epoch: 7, iters: 1000, time: 0.075, data: 0.013) G_GAN: 0.710 G_L1: 6.134 D_real: 0.945 D_fake: 0.643 RMSE: 37.316 \n",
      "End of epoch 7 / 200 \t Time Taken: 52 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "RMSE fake image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 423.89, min: 0.00, mean: 48.05, std: 57.21\n",
      "RMSE real image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 6551.64, min: 0.00, mean: 50.43, std: 68.83\n",
      "(epoch: 8, iters: 500, time: 0.089, data: 2.014) G_GAN: 0.669 G_L1: 5.785 D_real: 0.546 D_fake: 0.840 RMSE: 45.311 \n",
      "RMSE fake image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 466.77, min: 0.00, mean: 53.62, std: 57.62\n",
      "RMSE real image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 1574.11, min: 0.00, mean: 47.44, std: 56.14\n",
      "(epoch: 8, iters: 1000, time: 0.084, data: 0.012) G_GAN: 0.600 G_L1: 5.226 D_real: 0.700 D_fake: 0.810 RMSE: 34.853 \n",
      "End of epoch 8 / 200 \t Time Taken: 53 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "RMSE fake image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 422.99, min: 0.00, mean: 58.94, std: 58.30\n",
      "RMSE real image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 2493.77, min: 0.00, mean: 73.19, std: 78.91\n",
      "(epoch: 9, iters: 500, time: 0.087, data: 1.948) G_GAN: 0.704 G_L1: 7.849 D_real: 0.700 D_fake: 0.545 RMSE: 52.067 \n",
      "RMSE fake image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 390.87, min: 0.00, mean: 58.96, std: 52.26\n",
      "RMSE real image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 1417.84, min: 0.00, mean: 63.75, std: 66.74\n",
      "(epoch: 9, iters: 1000, time: 0.055, data: 0.031) G_GAN: 0.749 G_L1: 6.421 D_real: 0.800 D_fake: 0.432 RMSE: 40.599 \n",
      "End of epoch 9 / 200 \t Time Taken: 52 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "RMSE fake image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 488.95, min: 0.00, mean: 53.95, std: 57.12\n",
      "RMSE real image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 2172.72, min: 0.00, mean: 60.88, std: 73.51\n",
      "(epoch: 10, iters: 500, time: 0.072, data: 1.917) G_GAN: 0.977 G_L1: 6.137 D_real: 0.424 D_fake: 0.814 RMSE: 43.202 \n",
      "RMSE fake image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 422.58, min: 0.00, mean: 60.86, std: 57.94\n",
      "RMSE real image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 5311.07, min: 0.00, mean: 55.50, std: 61.38\n",
      "(epoch: 10, iters: 1000, time: 0.083, data: 0.013) G_GAN: 0.851 G_L1: 5.771 D_real: 0.944 D_fake: 0.498 RMSE: 37.095 \n",
      "saving the latest model (epoch 10, total_iters 10000)\n",
      "End of epoch 10 / 200 \t Time Taken: 54 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "RMSE fake image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 419.75, min: 0.00, mean: 60.55, std: 58.70\n",
      "RMSE real image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 1309.19, min: 0.00, mean: 67.35, std: 70.42\n",
      "(epoch: 11, iters: 500, time: 0.087, data: 2.204) G_GAN: 0.867 G_L1: 6.370 D_real: 0.552 D_fake: 0.730 RMSE: 41.340 \n",
      "RMSE fake image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 482.51, min: 0.00, mean: 57.79, std: 56.21\n",
      "RMSE real image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 1742.75, min: 0.00, mean: 73.42, std: 72.40\n",
      "(epoch: 11, iters: 1000, time: 0.083, data: 0.019) G_GAN: 0.699 G_L1: 7.561 D_real: 0.666 D_fake: 0.547 RMSE: 46.020 \n",
      "End of epoch 11 / 200 \t Time Taken: 54 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "RMSE fake image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 466.24, min: 0.00, mean: 53.70, std: 60.57\n",
      "RMSE real image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 1685.10, min: 0.00, mean: 57.95, std: 67.23\n",
      "(epoch: 12, iters: 500, time: 0.065, data: 2.073) G_GAN: 0.830 G_L1: 5.294 D_real: 0.591 D_fake: 0.736 RMSE: 35.659 \n",
      "RMSE fake image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 450.33, min: 0.00, mean: 53.04, std: 58.73\n",
      "RMSE real image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 1247.29, min: 0.00, mean: 54.23, std: 68.41\n",
      "(epoch: 12, iters: 1000, time: 0.084, data: 0.012) G_GAN: 0.938 G_L1: 5.456 D_real: 0.553 D_fake: 0.757 RMSE: 38.160 \n",
      "End of epoch 12 / 200 \t Time Taken: 53 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "RMSE fake image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 385.29, min: 0.00, mean: 49.72, std: 53.57\n",
      "RMSE real image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 2592.55, min: 0.00, mean: 52.53, std: 62.96\n",
      "(epoch: 13, iters: 500, time: 0.066, data: 2.171) G_GAN: 0.860 G_L1: 5.029 D_real: 0.515 D_fake: 0.803 RMSE: 34.210 \n",
      "RMSE fake image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 456.83, min: 0.00, mean: 61.64, std: 57.33\n",
      "RMSE real image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 2296.38, min: 0.00, mean: 76.16, std: 73.58\n",
      "(epoch: 13, iters: 1000, time: 0.083, data: 0.012) G_GAN: 0.814 G_L1: 7.028 D_real: 0.596 D_fake: 0.579 RMSE: 44.173 \n",
      "End of epoch 13 / 200 \t Time Taken: 53 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "RMSE fake image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 420.18, min: 0.00, mean: 52.41, std: 55.80\n",
      "RMSE real image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 1772.06, min: 0.00, mean: 55.63, std: 62.82\n",
      "(epoch: 14, iters: 500, time: 0.095, data: 2.095) G_GAN: 0.732 G_L1: 5.348 D_real: 0.736 D_fake: 0.546 RMSE: 35.169 \n",
      "RMSE fake image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 449.05, min: 0.00, mean: 54.39, std: 56.67\n",
      "RMSE real image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 3167.06, min: 0.00, mean: 65.74, std: 78.30\n",
      "(epoch: 14, iters: 1000, time: 0.085, data: 0.013) G_GAN: 1.040 G_L1: 6.898 D_real: 0.394 D_fake: 0.726 RMSE: 47.785 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End of epoch 14 / 200 \t Time Taken: 54 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "RMSE fake image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 555.00, min: 0.00, mean: 49.54, std: 56.16\n",
      "RMSE real image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 4946.73, min: 0.00, mean: 49.03, std: 62.01\n",
      "(epoch: 15, iters: 500, time: 0.094, data: 1.996) G_GAN: 0.679 G_L1: 4.964 D_real: 0.806 D_fake: 0.510 RMSE: 35.868 \n",
      "RMSE fake image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 457.00, min: 0.00, mean: 57.25, std: 55.32\n",
      "RMSE real image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 889.89, min: 0.00, mean: 61.46, std: 65.11\n",
      "(epoch: 15, iters: 1000, time: 0.086, data: 0.012) G_GAN: 0.830 G_L1: 5.658 D_real: 0.780 D_fake: 0.416 RMSE: 36.579 \n",
      "saving the latest model (epoch 15, total_iters 15000)\n",
      "End of epoch 15 / 200 \t Time Taken: 55 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "RMSE fake image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 540.85, min: 0.00, mean: 60.43, std: 56.54\n",
      "RMSE real image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 759.53, min: 0.00, mean: 58.79, std: 52.77\n",
      "(epoch: 16, iters: 500, time: 0.085, data: 2.232) G_GAN: 0.510 G_L1: 5.679 D_real: 1.078 D_fake: 0.489 RMSE: 34.576 \n",
      "RMSE fake image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 548.34, min: 0.00, mean: 46.97, std: 58.36\n",
      "RMSE real image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 6212.39, min: 0.00, mean: 50.76, std: 71.19\n",
      "(epoch: 16, iters: 1000, time: 0.086, data: 0.023) G_GAN: 1.102 G_L1: 5.566 D_real: 0.469 D_fake: 0.667 RMSE: 42.524 \n",
      "End of epoch 16 / 200 \t Time Taken: 55 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "RMSE fake image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 734.86, min: 0.00, mean: 56.31, std: 62.41\n",
      "RMSE real image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 542.05, min: 0.00, mean: 56.28, std: 63.05\n",
      "(epoch: 17, iters: 500, time: 0.094, data: 2.149) G_GAN: 0.617 G_L1: 5.336 D_real: 0.908 D_fake: 0.504 RMSE: 35.126 \n",
      "RMSE fake image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 600.51, min: 0.00, mean: 64.33, std: 65.97\n",
      "RMSE real image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 4571.59, min: 0.00, mean: 70.11, std: 74.19\n",
      "(epoch: 17, iters: 1000, time: 0.088, data: 0.016) G_GAN: 0.746 G_L1: 6.459 D_real: 0.736 D_fake: 0.548 RMSE: 43.000 \n",
      "End of epoch 17 / 200 \t Time Taken: 53 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "RMSE fake image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 766.68, min: 0.00, mean: 53.32, std: 54.93\n",
      "RMSE real image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 2407.02, min: 0.00, mean: 53.12, std: 53.08\n",
      "(epoch: 18, iters: 500, time: 0.072, data: 2.111) G_GAN: 0.698 G_L1: 5.194 D_real: 0.663 D_fake: 0.781 RMSE: 32.684 \n",
      "RMSE fake image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 1074.87, min: 0.00, mean: 50.40, std: 56.42\n",
      "RMSE real image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 4946.73, min: 0.00, mean: 57.33, std: 70.09\n",
      "(epoch: 18, iters: 1000, time: 0.059, data: 0.154) G_GAN: 1.050 G_L1: 5.873 D_real: 0.490 D_fake: 0.762 RMSE: 42.994 \n",
      "End of epoch 18 / 200 \t Time Taken: 54 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "RMSE fake image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 1082.76, min: 0.00, mean: 53.58, std: 63.43\n",
      "RMSE real image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 1597.18, min: 0.00, mean: 57.25, std: 66.25\n",
      "(epoch: 19, iters: 500, time: 0.092, data: 2.337) G_GAN: 1.051 G_L1: 5.417 D_real: 0.377 D_fake: 0.979 RMSE: 37.466 \n",
      "RMSE fake image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 5800.25, min: 0.00, mean: 51.14, std: 63.68\n",
      "RMSE real image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 810.89, min: 0.00, mean: 57.53, std: 70.58\n",
      "(epoch: 19, iters: 1000, time: 0.085, data: 0.058) G_GAN: 0.991 G_L1: 5.869 D_real: 0.483 D_fake: 0.828 RMSE: 49.122 \n",
      "End of epoch 19 / 200 \t Time Taken: 53 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "RMSE fake image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 1757.51, min: 0.00, mean: 55.11, std: 56.05\n",
      "RMSE real image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 756.52, min: 0.00, mean: 57.20, std: 57.78\n",
      "(epoch: 20, iters: 500, time: 0.091, data: 2.012) G_GAN: 0.757 G_L1: 5.256 D_real: 0.757 D_fake: 0.638 RMSE: 35.667 \n",
      "RMSE fake image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 2873.59, min: 0.00, mean: 52.96, std: 57.20\n",
      "RMSE real image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 4858.87, min: 0.00, mean: 52.53, std: 62.95\n",
      "(epoch: 20, iters: 1000, time: 0.086, data: 0.011) G_GAN: 0.924 G_L1: 5.720 D_real: 0.668 D_fake: 0.603 RMSE: 45.954 \n",
      "saving the latest model (epoch 20, total_iters 20000)\n",
      "End of epoch 20 / 200 \t Time Taken: 56 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "RMSE fake image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 2247.43, min: 0.00, mean: 61.87, std: 68.19\n",
      "RMSE real image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 3195.57, min: 0.00, mean: 64.40, std: 77.66\n",
      "(epoch: 21, iters: 500, time: 0.082, data: 2.116) G_GAN: 1.141 G_L1: 6.244 D_real: 0.406 D_fake: 0.903 RMSE: 44.715 \n",
      "RMSE fake image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 2658.96, min: 0.00, mean: 57.72, std: 60.87\n",
      "RMSE real image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 1313.12, min: 0.00, mean: 60.68, std: 64.47\n",
      "(epoch: 21, iters: 1000, time: 0.087, data: 0.013) G_GAN: 0.958 G_L1: 6.005 D_real: 0.490 D_fake: 0.692 RMSE: 40.358 \n",
      "End of epoch 21 / 200 \t Time Taken: 55 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "RMSE fake image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 3181.42, min: 0.00, mean: 57.91, std: 58.72\n",
      "RMSE real image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 661.43, min: 0.00, mean: 59.12, std: 63.90\n",
      "(epoch: 22, iters: 500, time: 0.083, data: 2.182) G_GAN: 0.806 G_L1: 5.623 D_real: 0.661 D_fake: 0.567 RMSE: 36.384 \n",
      "RMSE fake image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 5030.42, min: 0.00, mean: 52.74, std: 61.12\n",
      "RMSE real image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 750.63, min: 0.00, mean: 51.77, std: 64.16\n",
      "(epoch: 22, iters: 1000, time: 0.085, data: 0.016) G_GAN: 0.781 G_L1: 5.046 D_real: 0.933 D_fake: 0.461 RMSE: 39.354 \n",
      "End of epoch 22 / 200 \t Time Taken: 54 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "RMSE fake image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 2714.68, min: 0.00, mean: 59.14, std: 64.49\n",
      "RMSE real image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 2089.24, min: 0.00, mean: 58.64, std: 70.14\n",
      "(epoch: 23, iters: 500, time: 0.099, data: 2.185) G_GAN: 0.831 G_L1: 5.314 D_real: 0.571 D_fake: 0.687 RMSE: 37.260 \n",
      "RMSE fake image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 4742.09, min: 0.00, mean: 52.44, std: 61.19\n",
      "RMSE real image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 2123.89, min: 0.00, mean: 62.14, std: 73.19\n",
      "(epoch: 23, iters: 1000, time: 0.088, data: 0.017) G_GAN: 0.945 G_L1: 6.335 D_real: 0.467 D_fake: 0.956 RMSE: 48.541 \n",
      "End of epoch 23 / 200 \t Time Taken: 54 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "RMSE fake image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 1720.91, min: 0.00, mean: 61.15, std: 60.56\n",
      "RMSE real image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 2837.10, min: 0.00, mean: 70.31, std: 70.57\n",
      "(epoch: 24, iters: 500, time: 0.075, data: 1.996) G_GAN: 1.123 G_L1: 6.555 D_real: 0.374 D_fake: 0.764 RMSE: 42.301 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE fake image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 1994.30, min: 0.00, mean: 59.76, std: 65.12\n",
      "RMSE real image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 2095.70, min: 0.00, mean: 52.72, std: 64.40\n",
      "(epoch: 24, iters: 1000, time: 0.089, data: 0.012) G_GAN: 0.988 G_L1: 5.865 D_real: 0.560 D_fake: 0.826 RMSE: 40.640 \n",
      "End of epoch 24 / 200 \t Time Taken: 54 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "RMSE fake image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 896.75, min: 0.00, mean: 47.52, std: 58.22\n",
      "RMSE real image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 1071.09, min: 0.00, mean: 44.09, std: 57.18\n",
      "(epoch: 25, iters: 500, time: 0.099, data: 2.048) G_GAN: 0.519 G_L1: 4.313 D_real: 0.907 D_fake: 0.624 RMSE: 29.942 \n",
      "RMSE fake image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 2971.13, min: 0.00, mean: 46.77, std: 59.62\n",
      "RMSE real image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 1496.20, min: 0.00, mean: 53.79, std: 78.63\n",
      "(epoch: 25, iters: 1000, time: 0.084, data: 0.012) G_GAN: 1.401 G_L1: 6.272 D_real: 0.370 D_fake: 0.884 RMSE: 49.402 \n",
      "saving the latest model (epoch 25, total_iters 25000)\n",
      "End of epoch 25 / 200 \t Time Taken: 55 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "RMSE fake image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 1126.87, min: 0.00, mean: 52.48, std: 54.00\n",
      "RMSE real image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 2599.55, min: 0.00, mean: 61.43, std: 65.80\n",
      "(epoch: 26, iters: 500, time: 0.074, data: 2.050) G_GAN: 1.024 G_L1: 5.242 D_real: 0.430 D_fake: 0.784 RMSE: 35.754 \n",
      "RMSE fake image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 3183.79, min: 0.00, mean: 59.37, std: 57.58\n",
      "RMSE real image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 3233.36, min: 0.00, mean: 64.91, std: 69.32\n",
      "(epoch: 26, iters: 1000, time: 0.088, data: 0.012) G_GAN: 0.935 G_L1: 6.086 D_real: 0.608 D_fake: 0.457 RMSE: 41.786 \n",
      "End of epoch 26 / 200 \t Time Taken: 55 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "RMSE fake image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 1426.33, min: 0.00, mean: 54.37, std: 62.92\n",
      "RMSE real image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 1650.92, min: 0.00, mean: 55.04, std: 68.53\n",
      "(epoch: 27, iters: 500, time: 0.075, data: 2.118) G_GAN: 0.609 G_L1: 5.131 D_real: 0.837 D_fake: 0.537 RMSE: 35.477 \n",
      "RMSE fake image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 5237.35, min: 0.00, mean: 57.93, std: 63.84\n",
      "RMSE real image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 3153.37, min: 0.00, mean: 53.32, std: 59.53\n",
      "(epoch: 27, iters: 1000, time: 0.090, data: 0.013) G_GAN: 0.653 G_L1: 5.367 D_real: 0.756 D_fake: 0.567 RMSE: 43.986 \n",
      "End of epoch 27 / 200 \t Time Taken: 56 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "RMSE fake image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 970.73, min: 0.00, mean: 65.85, std: 59.30\n",
      "RMSE real image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 2407.02, min: 0.00, mean: 80.42, std: 77.96\n",
      "(epoch: 28, iters: 500, time: 0.093, data: 2.198) G_GAN: 1.277 G_L1: 7.873 D_real: 0.239 D_fake: 0.763 RMSE: 48.399 \n",
      "RMSE fake image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 665.21, min: 0.00, mean: 52.77, std: 55.23\n",
      "RMSE real image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 593.06, min: 0.00, mean: 50.59, std: 53.22\n",
      "(epoch: 28, iters: 1000, time: 0.090, data: 0.012) G_GAN: 0.630 G_L1: 4.685 D_real: 1.113 D_fake: 0.493 RMSE: 29.593 \n",
      "End of epoch 28 / 200 \t Time Taken: 59 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "RMSE fake image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 1923.54, min: 0.00, mean: 55.86, std: 56.84\n",
      "RMSE real image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 633.03, min: 0.00, mean: 61.74, std: 58.78\n",
      "(epoch: 29, iters: 500, time: 0.100, data: 2.130) G_GAN: 0.698 G_L1: 5.796 D_real: 0.975 D_fake: 0.489 RMSE: 37.560 \n",
      "RMSE fake image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 3599.72, min: 0.00, mean: 64.33, std: 63.36\n",
      "RMSE real image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 6078.89, min: 0.00, mean: 72.16, std: 70.79\n",
      "(epoch: 29, iters: 1000, time: 0.089, data: 0.014) G_GAN: 0.854 G_L1: 6.142 D_real: 0.586 D_fake: 0.486 RMSE: 42.358 \n",
      "End of epoch 29 / 200 \t Time Taken: 59 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "RMSE fake image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 859.58, min: 0.00, mean: 61.36, std: 61.74\n",
      "RMSE real image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 1597.18, min: 0.00, mean: 66.94, std: 69.20\n",
      "(epoch: 30, iters: 500, time: 0.107, data: 2.126) G_GAN: 0.806 G_L1: 5.760 D_real: 0.780 D_fake: 0.496 RMSE: 37.225 \n",
      "RMSE fake image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 1352.30, min: 0.00, mean: 55.92, std: 60.93\n",
      "RMSE real image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 761.18, min: 0.00, mean: 59.16, std: 63.97\n",
      "(epoch: 30, iters: 1000, time: 0.088, data: 0.013) G_GAN: 0.866 G_L1: 5.441 D_real: 0.702 D_fake: 0.702 RMSE: 36.252 \n",
      "saving the latest model (epoch 30, total_iters 30000)\n",
      "End of epoch 30 / 200 \t Time Taken: 60 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "RMSE fake image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 568.06, min: 0.00, mean: 53.82, std: 49.96\n",
      "RMSE real image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 527.50, min: 0.00, mean: 52.83, std: 49.98\n",
      "(epoch: 31, iters: 500, time: 0.107, data: 2.383) G_GAN: 0.899 G_L1: 4.488 D_real: 0.699 D_fake: 0.533 RMSE: 27.743 \n",
      "RMSE fake image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 719.43, min: 0.00, mean: 58.89, std: 61.17\n",
      "RMSE real image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 1091.48, min: 0.00, mean: 62.15, std: 65.34\n",
      "(epoch: 31, iters: 1000, time: 0.084, data: 0.014) G_GAN: 0.695 G_L1: 5.223 D_real: 0.789 D_fake: 0.544 RMSE: 34.243 \n",
      "End of epoch 31 / 200 \t Time Taken: 56 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "RMSE fake image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 3649.04, min: 0.00, mean: 66.31, std: 64.79\n",
      "RMSE real image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 4946.73, min: 0.00, mean: 73.21, std: 73.32\n",
      "(epoch: 32, iters: 500, time: 0.075, data: 1.945) G_GAN: 0.891 G_L1: 6.780 D_real: 0.404 D_fake: 0.718 RMSE: 48.216 \n",
      "RMSE fake image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 2222.75, min: 0.00, mean: 49.26, std: 56.65\n",
      "RMSE real image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 2232.49, min: 0.00, mean: 47.66, std: 63.02\n",
      "(epoch: 32, iters: 1000, time: 0.089, data: 0.014) G_GAN: 0.664 G_L1: 4.888 D_real: 0.820 D_fake: 0.485 RMSE: 33.731 \n",
      "End of epoch 32 / 200 \t Time Taken: 55 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "RMSE fake image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 718.88, min: 0.00, mean: 64.66, std: 63.53\n",
      "RMSE real image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 2095.70, min: 0.00, mean: 69.28, std: 68.93\n",
      "(epoch: 33, iters: 500, time: 0.106, data: 2.120) G_GAN: 0.779 G_L1: 5.634 D_real: 0.648 D_fake: 0.555 RMSE: 36.182 \n",
      "RMSE fake image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 1695.56, min: 0.00, mean: 47.74, std: 56.45\n",
      "RMSE real image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 2837.10, min: 0.00, mean: 42.65, std: 54.53\n",
      "(epoch: 33, iters: 1000, time: 0.090, data: 0.013) G_GAN: 0.529 G_L1: 4.672 D_real: 0.962 D_fake: 0.612 RMSE: 34.611 \n",
      "End of epoch 33 / 200 \t Time Taken: 56 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE fake image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 866.54, min: 0.00, mean: 50.14, std: 57.10\n",
      "RMSE real image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 1654.40, min: 0.00, mean: 56.53, std: 68.13\n",
      "(epoch: 34, iters: 500, time: 0.101, data: 2.106) G_GAN: 0.954 G_L1: 5.039 D_real: 0.506 D_fake: 0.648 RMSE: 36.086 \n",
      "RMSE fake image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 2211.79, min: 0.00, mean: 53.19, std: 62.90\n",
      "RMSE real image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 1262.69, min: 0.00, mean: 59.45, std: 70.03\n",
      "(epoch: 34, iters: 1000, time: 0.090, data: 0.013) G_GAN: 0.931 G_L1: 5.126 D_real: 0.556 D_fake: 0.816 RMSE: 36.895 \n",
      "End of epoch 34 / 200 \t Time Taken: 56 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "RMSE fake image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 3144.59, min: 0.00, mean: 48.26, std: 59.81\n",
      "RMSE real image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 1752.54, min: 0.00, mean: 49.93, std: 65.05\n",
      "(epoch: 35, iters: 500, time: 0.078, data: 2.137) G_GAN: 1.183 G_L1: 4.795 D_real: 0.438 D_fake: 0.905 RMSE: 36.006 \n",
      "RMSE fake image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 639.36, min: 0.00, mean: 45.46, std: 53.26\n",
      "RMSE real image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 946.32, min: 0.00, mean: 47.66, std: 55.79\n",
      "(epoch: 35, iters: 1000, time: 0.085, data: 0.014) G_GAN: 1.145 G_L1: 4.285 D_real: 0.398 D_fake: 0.817 RMSE: 29.279 \n",
      "saving the latest model (epoch 35, total_iters 35000)\n",
      "End of epoch 35 / 200 \t Time Taken: 54 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "RMSE fake image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 1158.94, min: 0.00, mean: 54.75, std: 61.56\n",
      "RMSE real image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 10450.77, min: 0.00, mean: 53.39, std: 68.40\n",
      "(epoch: 36, iters: 500, time: 0.077, data: 1.960) G_GAN: 0.779 G_L1: 4.437 D_real: 0.581 D_fake: 0.736 RMSE: 37.015 \n",
      "RMSE fake image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 3633.53, min: 0.00, mean: 53.03, std: 70.03\n",
      "RMSE real image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 2253.89, min: 0.00, mean: 61.15, std: 80.24\n",
      "(epoch: 36, iters: 1000, time: 0.088, data: 0.013) G_GAN: 1.021 G_L1: 6.280 D_real: 0.546 D_fake: 0.522 RMSE: 53.545 \n",
      "End of epoch 36 / 200 \t Time Taken: 55 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "RMSE fake image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 1096.76, min: 0.00, mean: 46.54, std: 60.52\n",
      "RMSE real image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 1548.89, min: 0.00, mean: 53.98, std: 72.37\n",
      "(epoch: 37, iters: 500, time: 0.106, data: 2.104) G_GAN: 1.602 G_L1: 5.210 D_real: 0.385 D_fake: 0.768 RMSE: 38.620 \n",
      "RMSE fake image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 1001.39, min: 0.00, mean: 50.76, std: 59.53\n",
      "RMSE real image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 3623.46, min: 0.00, mean: 52.78, std: 64.74\n",
      "(epoch: 37, iters: 1000, time: 0.094, data: 0.038) G_GAN: 0.580 G_L1: 4.928 D_real: 0.796 D_fake: 0.545 RMSE: 34.445 \n",
      "End of epoch 37 / 200 \t Time Taken: 55 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "RMSE fake image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 703.92, min: 0.00, mean: 59.36, std: 67.23\n",
      "RMSE real image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 3233.36, min: 0.00, mean: 55.92, std: 71.69\n",
      "(epoch: 38, iters: 500, time: 0.075, data: 2.138) G_GAN: 0.856 G_L1: 5.138 D_real: 0.604 D_fake: 0.587 RMSE: 36.839 \n",
      "RMSE fake image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 1689.36, min: 0.00, mean: 62.60, std: 69.14\n",
      "RMSE real image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 5151.87, min: 0.00, mean: 64.66, std: 76.85\n",
      "(epoch: 38, iters: 1000, time: 0.091, data: 0.011) G_GAN: 1.044 G_L1: 6.021 D_real: 0.405 D_fake: 0.741 RMSE: 47.009 \n",
      "End of epoch 38 / 200 \t Time Taken: 53 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "RMSE fake image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 848.45, min: 0.00, mean: 48.73, std: 58.14\n",
      "RMSE real image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 1307.76, min: 0.00, mean: 49.84, std: 58.10\n",
      "(epoch: 39, iters: 500, time: 0.108, data: 2.242) G_GAN: 0.596 G_L1: 4.345 D_real: 1.202 D_fake: 0.568 RMSE: 29.451 \n",
      "RMSE fake image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 900.08, min: 0.00, mean: 62.79, std: 64.79\n",
      "RMSE real image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 2430.66, min: 0.00, mean: 60.47, std: 62.09\n",
      "(epoch: 39, iters: 1000, time: 0.093, data: 0.015) G_GAN: 0.594 G_L1: 5.398 D_real: 0.891 D_fake: 0.633 RMSE: 34.442 \n",
      "End of epoch 39 / 200 \t Time Taken: 55 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "RMSE fake image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 585.17, min: 0.00, mean: 52.94, std: 53.12\n",
      "RMSE real image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 561.33, min: 0.00, mean: 49.99, std: 50.76\n",
      "(epoch: 40, iters: 500, time: 0.102, data: 2.214) G_GAN: 0.655 G_L1: 4.421 D_real: 0.743 D_fake: 0.703 RMSE: 26.961 \n",
      "RMSE fake image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 915.31, min: 0.00, mean: 60.87, std: 64.55\n",
      "RMSE real image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 2407.02, min: 0.00, mean: 60.89, std: 66.24\n",
      "(epoch: 40, iters: 1000, time: 0.094, data: 0.015) G_GAN: 1.287 G_L1: 5.747 D_real: 0.377 D_fake: 0.930 RMSE: 36.726 \n",
      "saving the latest model (epoch 40, total_iters 40000)\n",
      "End of epoch 40 / 200 \t Time Taken: 57 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "RMSE fake image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 613.90, min: 0.00, mean: 71.86, std: 62.91\n",
      "RMSE real image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 3623.46, min: 0.00, mean: 77.69, std: 70.10\n",
      "(epoch: 41, iters: 500, time: 0.106, data: 2.122) G_GAN: 0.905 G_L1: 5.968 D_real: 0.478 D_fake: 0.702 RMSE: 37.090 \n",
      "RMSE fake image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 932.62, min: 0.00, mean: 60.98, std: 66.39\n",
      "RMSE real image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 1654.40, min: 0.00, mean: 62.38, std: 70.90\n",
      "(epoch: 41, iters: 1000, time: 0.093, data: 0.013) G_GAN: 0.849 G_L1: 5.064 D_real: 0.785 D_fake: 0.431 RMSE: 35.207 \n",
      "End of epoch 41 / 200 \t Time Taken: 55 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "RMSE fake image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 705.43, min: 0.00, mean: 44.17, std: 56.28\n",
      "RMSE real image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 1871.07, min: 0.00, mean: 48.45, std: 62.38\n",
      "(epoch: 42, iters: 500, time: 0.105, data: 2.244) G_GAN: 0.887 G_L1: 4.314 D_real: 0.487 D_fake: 0.758 RMSE: 31.469 \n",
      "RMSE fake image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 1057.97, min: 0.00, mean: 61.82, std: 66.05\n",
      "RMSE real image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 3221.46, min: 0.00, mean: 69.42, std: 73.68\n",
      "(epoch: 42, iters: 1000, time: 0.093, data: 0.014) G_GAN: 0.911 G_L1: 5.911 D_real: 0.431 D_fake: 0.698 RMSE: 39.110 \n",
      "End of epoch 42 / 200 \t Time Taken: 54 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "RMSE fake image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 1221.20, min: 0.00, mean: 55.25, std: 61.61\n",
      "RMSE real image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 2246.04, min: 0.00, mean: 53.77, std: 66.66\n",
      "(epoch: 43, iters: 500, time: 0.105, data: 2.116) G_GAN: 0.714 G_L1: 4.741 D_real: 0.764 D_fake: 0.544 RMSE: 32.877 \n",
      "RMSE fake image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 865.15, min: 0.00, mean: 46.16, std: 56.67\n",
      "RMSE real image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 557.88, min: 0.00, mean: 52.09, std: 65.99\n",
      "(epoch: 43, iters: 1000, time: 0.100, data: 0.012) G_GAN: 0.926 G_L1: 4.464 D_real: 0.531 D_fake: 0.827 RMSE: 31.445 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End of epoch 43 / 200 \t Time Taken: 56 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "RMSE fake image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 1470.77, min: 0.00, mean: 51.95, std: 56.18\n",
      "RMSE real image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 2170.76, min: 0.00, mean: 54.29, std: 58.30\n",
      "(epoch: 44, iters: 500, time: 0.084, data: 2.007) G_GAN: 0.757 G_L1: 4.544 D_real: 0.654 D_fake: 0.613 RMSE: 30.889 \n",
      "RMSE fake image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 1344.05, min: 0.00, mean: 62.52, std: 63.16\n",
      "RMSE real image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 471.15, min: 0.00, mean: 62.76, std: 63.43\n",
      "(epoch: 44, iters: 1000, time: 0.091, data: 0.016) G_GAN: 0.759 G_L1: 5.220 D_real: 0.771 D_fake: 0.594 RMSE: 33.215 \n",
      "End of epoch 44 / 200 \t Time Taken: 56 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "RMSE fake image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 610.26, min: 0.00, mean: 53.34, std: 56.66\n",
      "RMSE real image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 600.00, min: 0.00, mean: 49.55, std: 55.54\n",
      "(epoch: 45, iters: 500, time: 0.096, data: 2.148) G_GAN: 0.766 G_L1: 4.364 D_real: 0.652 D_fake: 0.800 RMSE: 27.901 \n",
      "RMSE fake image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 662.16, min: 0.00, mean: 50.54, std: 62.36\n",
      "RMSE real image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 2256.45, min: 0.00, mean: 51.64, std: 63.02\n",
      "(epoch: 45, iters: 1000, time: 0.093, data: 0.013) G_GAN: 0.556 G_L1: 4.101 D_real: 0.978 D_fake: 0.443 RMSE: 28.536 \n",
      "saving the latest model (epoch 45, total_iters 45000)\n",
      "End of epoch 45 / 200 \t Time Taken: 56 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "RMSE fake image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 2080.72, min: 0.00, mean: 58.91, std: 66.10\n",
      "RMSE real image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 2834.73, min: 0.00, mean: 54.89, std: 62.94\n",
      "(epoch: 46, iters: 500, time: 0.111, data: 2.166) G_GAN: 0.753 G_L1: 4.939 D_real: 0.904 D_fake: 0.516 RMSE: 34.887 \n",
      "RMSE fake image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 1819.07, min: 0.00, mean: 53.48, std: 59.96\n",
      "RMSE real image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 1503.70, min: 0.00, mean: 55.49, std: 63.29\n",
      "(epoch: 46, iters: 1000, time: 0.093, data: 0.034) G_GAN: 0.706 G_L1: 4.716 D_real: 1.100 D_fake: 0.405 RMSE: 32.358 \n",
      "End of epoch 46 / 200 \t Time Taken: 55 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "RMSE fake image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 2289.73, min: 0.00, mean: 54.29, std: 66.13\n",
      "RMSE real image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 2834.73, min: 0.00, mean: 54.13, std: 67.96\n",
      "(epoch: 47, iters: 500, time: 0.096, data: 2.229) G_GAN: 1.018 G_L1: 4.669 D_real: 0.645 D_fake: 0.705 RMSE: 35.560 \n",
      "RMSE fake image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 14103.66, min: 0.00, mean: 59.93, std: 78.82\n",
      "RMSE real image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 2577.69, min: 0.00, mean: 64.63, std: 72.78\n",
      "(epoch: 47, iters: 1000, time: 0.092, data: 0.033) G_GAN: 1.072 G_L1: 6.300 D_real: 0.402 D_fake: 0.907 RMSE: 65.055 \n",
      "End of epoch 47 / 200 \t Time Taken: 54 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "RMSE fake image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 2031.61, min: 0.00, mean: 52.56, std: 58.67\n",
      "RMSE real image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 1871.07, min: 0.00, mean: 50.07, std: 58.18\n",
      "(epoch: 48, iters: 500, time: 0.107, data: 2.067) G_GAN: 0.727 G_L1: 4.209 D_real: 0.743 D_fake: 0.576 RMSE: 28.544 \n",
      "RMSE fake image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 878.46, min: 0.00, mean: 48.61, std: 58.21\n",
      "RMSE real image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 739.00, min: 0.00, mean: 50.88, std: 60.05\n",
      "(epoch: 48, iters: 1000, time: 0.102, data: 0.012) G_GAN: 0.945 G_L1: 3.972 D_real: 0.629 D_fake: 0.675 RMSE: 26.928 \n",
      "End of epoch 48 / 200 \t Time Taken: 56 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "RMSE fake image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 916.88, min: 0.00, mean: 57.88, std: 70.39\n",
      "RMSE real image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 1238.97, min: 0.00, mean: 54.96, std: 66.89\n",
      "(epoch: 49, iters: 500, time: 0.082, data: 2.006) G_GAN: 0.475 G_L1: 4.630 D_real: 1.002 D_fake: 0.704 RMSE: 32.921 \n",
      "RMSE fake image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 690.24, min: 0.00, mean: 53.92, std: 67.81\n",
      "RMSE real image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 1597.18, min: 0.00, mean: 57.65, std: 70.87\n",
      "(epoch: 49, iters: 1000, time: 0.096, data: 0.050) G_GAN: 1.134 G_L1: 4.590 D_real: 0.458 D_fake: 0.796 RMSE: 32.839 \n",
      "End of epoch 49 / 200 \t Time Taken: 53 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "RMSE fake image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 774.92, min: 0.00, mean: 56.25, std: 62.92\n",
      "RMSE real image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 1383.39, min: 0.00, mean: 58.91, std: 65.09\n",
      "(epoch: 50, iters: 500, time: 0.111, data: 1.970) G_GAN: 0.998 G_L1: 4.793 D_real: 0.549 D_fake: 0.633 RMSE: 31.281 \n",
      "RMSE fake image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 1909.28, min: 0.00, mean: 56.46, std: 60.30\n",
      "RMSE real image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 1044.56, min: 0.00, mean: 55.30, std: 59.74\n",
      "(epoch: 50, iters: 1000, time: 0.092, data: 0.027) G_GAN: 0.591 G_L1: 4.578 D_real: 0.794 D_fake: 0.706 RMSE: 30.749 \n",
      "saving the latest model (epoch 50, total_iters 50000)\n",
      "End of epoch 50 / 200 \t Time Taken: 57 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "RMSE fake image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 954.18, min: 0.00, mean: 59.00, std: 59.78\n",
      "RMSE real image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 635.36, min: 0.00, mean: 61.21, std: 63.35\n",
      "(epoch: 51, iters: 500, time: 0.109, data: 2.106) G_GAN: 0.823 G_L1: 4.837 D_real: 0.600 D_fake: 0.694 RMSE: 30.524 \n",
      "RMSE fake image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 2794.57, min: 0.00, mean: 55.89, std: 58.69\n",
      "RMSE real image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 2146.95, min: 0.00, mean: 56.13, std: 57.25\n",
      "(epoch: 51, iters: 1000, time: 0.096, data: 0.051) G_GAN: 0.732 G_L1: 4.948 D_real: 0.788 D_fake: 0.605 RMSE: 32.864 \n",
      "End of epoch 51 / 200 \t Time Taken: 55 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "RMSE fake image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 970.91, min: 0.00, mean: 56.88, std: 55.70\n",
      "RMSE real image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 1069.14, min: 0.00, mean: 52.85, std: 50.87\n",
      "(epoch: 52, iters: 500, time: 0.117, data: 2.040) G_GAN: 0.706 G_L1: 4.759 D_real: 0.817 D_fake: 0.680 RMSE: 29.899 \n",
      "RMSE fake image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 1313.29, min: 0.00, mean: 43.16, std: 60.58\n",
      "RMSE real image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 6078.89, min: 0.00, mean: 45.15, std: 67.95\n",
      "(epoch: 52, iters: 1000, time: 0.097, data: 0.013) G_GAN: 1.139 G_L1: 3.898 D_real: 0.527 D_fake: 0.870 RMSE: 33.507 \n",
      "End of epoch 52 / 200 \t Time Taken: 54 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "RMSE fake image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 1622.85, min: 0.00, mean: 67.86, std: 64.57\n",
      "RMSE real image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 1591.30, min: 0.00, mean: 70.44, std: 67.51\n",
      "(epoch: 53, iters: 500, time: 0.097, data: 2.298) G_GAN: 0.687 G_L1: 5.578 D_real: 0.654 D_fake: 0.629 RMSE: 34.786 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE fake image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 2648.78, min: 0.00, mean: 54.51, std: 75.08\n",
      "RMSE real image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 2253.89, min: 0.00, mean: 56.74, std: 80.34\n",
      "(epoch: 53, iters: 1000, time: 0.090, data: 0.013) G_GAN: 0.818 G_L1: 5.340 D_real: 0.607 D_fake: 0.606 RMSE: 45.809 \n",
      "End of epoch 53 / 200 \t Time Taken: 55 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "RMSE fake image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 1053.35, min: 0.00, mean: 51.09, std: 61.46\n",
      "RMSE real image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 1710.22, min: 0.00, mean: 53.52, std: 67.11\n",
      "(epoch: 54, iters: 500, time: 0.095, data: 2.095) G_GAN: 0.879 G_L1: 4.355 D_real: 0.537 D_fake: 0.753 RMSE: 31.645 \n",
      "RMSE fake image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 1517.62, min: 0.00, mean: 47.50, std: 61.43\n",
      "RMSE real image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 1126.49, min: 0.00, mean: 47.66, std: 60.22\n",
      "(epoch: 54, iters: 1000, time: 0.096, data: 0.040) G_GAN: 0.875 G_L1: 4.479 D_real: 0.614 D_fake: 0.720 RMSE: 31.942 \n",
      "End of epoch 54 / 200 \t Time Taken: 59 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "RMSE fake image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 4863.20, min: 0.00, mean: 67.61, std: 65.74\n",
      "RMSE real image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 1174.10, min: 0.00, mean: 61.64, std: 59.17\n",
      "(epoch: 55, iters: 500, time: 0.109, data: 1.991) G_GAN: 0.908 G_L1: 5.370 D_real: 0.392 D_fake: 0.982 RMSE: 34.858 \n",
      "RMSE fake image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 1389.09, min: 0.00, mean: 60.79, std: 62.51\n",
      "RMSE real image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 599.27, min: 0.00, mean: 63.63, std: 63.40\n",
      "(epoch: 55, iters: 1000, time: 0.095, data: 0.390) G_GAN: 1.053 G_L1: 4.969 D_real: 0.551 D_fake: 0.467 RMSE: 32.224 \n",
      "saving the latest model (epoch 55, total_iters 55000)\n",
      "End of epoch 55 / 200 \t Time Taken: 57 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "RMSE fake image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 1348.47, min: 0.00, mean: 65.22, std: 63.15\n",
      "RMSE real image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 1848.90, min: 0.00, mean: 62.94, std: 60.99\n",
      "(epoch: 56, iters: 500, time: 0.084, data: 2.050) G_GAN: 0.859 G_L1: 5.633 D_real: 0.774 D_fake: 0.759 RMSE: 35.878 \n",
      "RMSE fake image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 2453.41, min: 0.00, mean: 54.69, std: 60.25\n",
      "RMSE real image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 793.17, min: 0.00, mean: 55.98, std: 62.86\n",
      "(epoch: 56, iters: 1000, time: 0.094, data: 0.013) G_GAN: 0.893 G_L1: 4.786 D_real: 0.733 D_fake: 0.488 RMSE: 33.342 \n",
      "End of epoch 56 / 200 \t Time Taken: 54 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "RMSE fake image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 906.99, min: 0.00, mean: 52.51, std: 58.00\n",
      "RMSE real image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 531.95, min: 0.00, mean: 58.98, std: 63.26\n",
      "(epoch: 57, iters: 500, time: 0.124, data: 2.030) G_GAN: 0.832 G_L1: 4.909 D_real: 0.631 D_fake: 0.615 RMSE: 31.636 \n",
      "RMSE fake image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 2805.70, min: 0.00, mean: 62.60, std: 72.87\n",
      "RMSE real image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 4773.41, min: 0.00, mean: 62.58, std: 78.80\n",
      "(epoch: 57, iters: 1000, time: 0.101, data: 0.028) G_GAN: 1.354 G_L1: 5.666 D_real: 0.285 D_fake: 0.886 RMSE: 42.095 \n",
      "End of epoch 57 / 200 \t Time Taken: 54 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "RMSE fake image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 1121.46, min: 0.00, mean: 50.74, std: 55.84\n",
      "RMSE real image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 510.54, min: 0.00, mean: 53.40, std: 63.01\n",
      "(epoch: 58, iters: 500, time: 0.107, data: 1.976) G_GAN: 1.540 G_L1: 4.707 D_real: 0.424 D_fake: 1.012 RMSE: 31.272 \n",
      "RMSE fake image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 1266.24, min: 0.00, mean: 61.06, std: 62.01\n",
      "RMSE real image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 610.49, min: 0.00, mean: 64.98, std: 67.18\n",
      "(epoch: 58, iters: 1000, time: 0.099, data: 0.012) G_GAN: 0.932 G_L1: 5.141 D_real: 0.630 D_fake: 0.461 RMSE: 33.603 \n",
      "End of epoch 58 / 200 \t Time Taken: 56 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "RMSE fake image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 892.73, min: 0.00, mean: 62.59, std: 60.88\n",
      "RMSE real image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 3153.37, min: 0.00, mean: 63.72, std: 63.10\n",
      "(epoch: 59, iters: 500, time: 0.108, data: 2.053) G_GAN: 0.972 G_L1: 5.304 D_real: 0.643 D_fake: 0.678 RMSE: 34.931 \n",
      "RMSE fake image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 19062.45, min: 0.00, mean: 64.00, std: 102.04\n",
      "RMSE real image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 2577.69, min: 0.00, mean: 65.83, std: 90.49\n",
      "(epoch: 59, iters: 1000, time: 0.095, data: 0.015) G_GAN: 1.450 G_L1: 6.537 D_real: 0.444 D_fake: 0.519 RMSE: 78.652 \n",
      "End of epoch 59 / 200 \t Time Taken: 55 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "RMSE fake image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 882.11, min: 0.00, mean: 60.88, std: 66.80\n",
      "RMSE real image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 1307.76, min: 0.00, mean: 60.07, std: 65.69\n",
      "(epoch: 60, iters: 500, time: 0.086, data: 2.062) G_GAN: 0.794 G_L1: 5.024 D_real: 0.998 D_fake: 0.507 RMSE: 33.334 \n",
      "RMSE fake image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 727.47, min: 0.00, mean: 51.32, std: 55.47\n",
      "RMSE real image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 1419.47, min: 0.00, mean: 48.93, std: 52.18\n",
      "(epoch: 60, iters: 1000, time: 0.096, data: 0.061) G_GAN: 0.924 G_L1: 4.307 D_real: 0.922 D_fake: 0.442 RMSE: 28.545 \n",
      "saving the latest model (epoch 60, total_iters 60000)\n",
      "End of epoch 60 / 200 \t Time Taken: 57 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "RMSE fake image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 1073.89, min: 0.00, mean: 66.30, std: 68.65\n",
      "RMSE real image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 1709.82, min: 0.00, mean: 64.82, std: 70.05\n",
      "(epoch: 61, iters: 500, time: 0.125, data: 2.138) G_GAN: 0.944 G_L1: 5.198 D_real: 0.659 D_fake: 0.552 RMSE: 35.536 \n",
      "RMSE fake image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 1440.70, min: 0.00, mean: 55.14, std: 61.87\n",
      "RMSE real image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 1933.50, min: 0.00, mean: 61.31, std: 68.05\n",
      "(epoch: 61, iters: 1000, time: 0.097, data: 0.009) G_GAN: 0.897 G_L1: 4.832 D_real: 0.572 D_fake: 0.661 RMSE: 31.987 \n",
      "End of epoch 61 / 200 \t Time Taken: 58 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "RMSE fake image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 1350.38, min: 0.00, mean: 55.20, std: 66.54\n",
      "RMSE real image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 10450.77, min: 0.00, mean: 51.31, std: 68.78\n",
      "(epoch: 62, iters: 500, time: 0.093, data: 2.214) G_GAN: 0.804 G_L1: 4.865 D_real: 0.787 D_fake: 0.772 RMSE: 42.481 \n",
      "RMSE fake image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 1701.25, min: 0.00, mean: 71.97, std: 71.23\n",
      "RMSE real image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 1780.63, min: 0.00, mean: 78.73, std: 79.12\n",
      "(epoch: 62, iters: 1000, time: 0.097, data: 0.014) G_GAN: 1.169 G_L1: 6.249 D_real: 0.512 D_fake: 0.492 RMSE: 39.519 \n",
      "End of epoch 62 / 200 \t Time Taken: 56 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE fake image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 1163.09, min: 0.00, mean: 47.84, std: 56.22\n",
      "RMSE real image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 1240.27, min: 0.00, mean: 47.23, std: 56.39\n",
      "(epoch: 63, iters: 500, time: 0.114, data: 2.257) G_GAN: 0.813 G_L1: 4.064 D_real: 0.455 D_fake: 0.970 RMSE: 28.318 \n",
      "RMSE fake image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 1551.26, min: 0.00, mean: 63.62, std: 62.34\n",
      "RMSE real image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 909.85, min: 0.00, mean: 63.58, std: 65.69\n",
      "(epoch: 63, iters: 1000, time: 0.100, data: 0.014) G_GAN: 0.808 G_L1: 5.415 D_real: 0.698 D_fake: 0.523 RMSE: 33.732 \n",
      "End of epoch 63 / 200 \t Time Taken: 59 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "RMSE fake image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 1154.00, min: 0.00, mean: 74.77, std: 76.02\n",
      "RMSE real image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 4718.91, min: 0.00, mean: 73.32, std: 78.39\n",
      "(epoch: 64, iters: 500, time: 0.088, data: 2.212) G_GAN: 1.046 G_L1: 6.177 D_real: 0.579 D_fake: 0.561 RMSE: 40.699 \n",
      "RMSE fake image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 3623.84, min: 0.00, mean: 57.50, std: 75.30\n",
      "RMSE real image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 3225.43, min: 0.00, mean: 62.33, std: 84.09\n",
      "(epoch: 64, iters: 1000, time: 0.100, data: 0.013) G_GAN: 1.169 G_L1: 5.568 D_real: 0.458 D_fake: 0.683 RMSE: 45.957 \n",
      "End of epoch 64 / 200 \t Time Taken: 55 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "RMSE fake image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 1729.74, min: 0.00, mean: 62.97, std: 60.89\n",
      "RMSE real image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 564.68, min: 0.00, mean: 66.82, std: 65.02\n",
      "(epoch: 65, iters: 500, time: 0.098, data: 2.022) G_GAN: 0.818 G_L1: 5.562 D_real: 0.476 D_fake: 0.830 RMSE: 34.978 \n",
      "RMSE fake image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 3025.00, min: 0.00, mean: 49.54, std: 59.77\n",
      "RMSE real image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 5004.70, min: 0.00, mean: 53.22, std: 67.41\n",
      "(epoch: 65, iters: 1000, time: 0.098, data: 0.025) G_GAN: 0.911 G_L1: 4.441 D_real: 0.682 D_fake: 0.572 RMSE: 35.606 \n",
      "saving the latest model (epoch 65, total_iters 65000)\n",
      "End of epoch 65 / 200 \t Time Taken: 56 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "RMSE fake image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 1034.44, min: 0.00, mean: 64.97, std: 67.87\n",
      "RMSE real image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 1813.82, min: 0.00, mean: 65.01, std: 66.23\n",
      "(epoch: 66, iters: 500, time: 0.109, data: 2.223) G_GAN: 0.739 G_L1: 5.223 D_real: 0.709 D_fake: 0.665 RMSE: 33.354 \n",
      "RMSE fake image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 1369.94, min: 0.00, mean: 57.47, std: 70.50\n",
      "RMSE real image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 1574.11, min: 0.00, mean: 51.86, std: 68.00\n",
      "(epoch: 66, iters: 1000, time: 0.098, data: 0.012) G_GAN: 0.549 G_L1: 4.836 D_real: 0.862 D_fake: 0.596 RMSE: 33.694 \n",
      "End of epoch 66 / 200 \t Time Taken: 57 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "RMSE fake image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 2869.40, min: 0.00, mean: 65.93, std: 67.47\n",
      "RMSE real image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 7339.64, min: 0.00, mean: 67.61, std: 73.68\n",
      "(epoch: 67, iters: 500, time: 0.078, data: 2.138) G_GAN: 1.101 G_L1: 5.211 D_real: 0.532 D_fake: 0.568 RMSE: 40.488 \n",
      "RMSE fake image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 799.63, min: 0.00, mean: 53.75, std: 56.32\n",
      "RMSE real image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 1772.06, min: 0.00, mean: 56.17, std: 59.72\n",
      "(epoch: 67, iters: 1000, time: 0.102, data: 0.009) G_GAN: 1.071 G_L1: 4.372 D_real: 0.510 D_fake: 0.753 RMSE: 28.236 \n",
      "End of epoch 67 / 200 \t Time Taken: 54 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "RMSE fake image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 1943.77, min: 0.00, mean: 56.80, std: 57.07\n",
      "RMSE real image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 1091.48, min: 0.00, mean: 65.82, std: 63.50\n",
      "(epoch: 68, iters: 500, time: 0.110, data: 1.958) G_GAN: 0.792 G_L1: 5.057 D_real: 0.551 D_fake: 0.650 RMSE: 32.075 \n",
      "RMSE fake image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 1020.10, min: 0.00, mean: 61.35, std: 66.78\n",
      "RMSE real image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 2407.02, min: 0.00, mean: 65.91, std: 73.19\n",
      "(epoch: 68, iters: 1000, time: 0.112, data: 0.011) G_GAN: 1.263 G_L1: 5.408 D_real: 0.367 D_fake: 0.794 RMSE: 36.049 \n",
      "End of epoch 68 / 200 \t Time Taken: 57 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "RMSE fake image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 1573.92, min: 0.00, mean: 66.36, std: 67.44\n",
      "RMSE real image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 1650.92, min: 0.00, mean: 69.92, std: 70.72\n",
      "(epoch: 69, iters: 500, time: 0.117, data: 2.009) G_GAN: 1.144 G_L1: 5.349 D_real: 0.385 D_fake: 0.748 RMSE: 34.015 \n",
      "RMSE fake image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 1161.94, min: 0.00, mean: 70.11, std: 69.88\n",
      "RMSE real image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 1428.65, min: 0.00, mean: 66.41, std: 69.32\n",
      "(epoch: 69, iters: 1000, time: 0.101, data: 0.008) G_GAN: 1.057 G_L1: 5.562 D_real: 0.596 D_fake: 0.646 RMSE: 36.005 \n",
      "End of epoch 69 / 200 \t Time Taken: 53 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "RMSE fake image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 2412.36, min: 0.00, mean: 62.09, std: 56.92\n",
      "RMSE real image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 1813.82, min: 0.00, mean: 64.65, std: 58.84\n",
      "(epoch: 70, iters: 500, time: 0.116, data: 2.023) G_GAN: 0.735 G_L1: 4.607 D_real: 0.688 D_fake: 0.596 RMSE: 28.713 \n",
      "RMSE fake image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 703.82, min: 0.00, mean: 73.81, std: 69.76\n",
      "RMSE real image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 4753.29, min: 0.00, mean: 70.75, std: 74.16\n",
      "(epoch: 70, iters: 1000, time: 0.101, data: 0.051) G_GAN: 1.123 G_L1: 5.602 D_real: 0.628 D_fake: 0.442 RMSE: 40.418 \n",
      "saving the latest model (epoch 70, total_iters 70000)\n",
      "End of epoch 70 / 200 \t Time Taken: 57 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "RMSE fake image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 1714.69, min: 0.00, mean: 51.49, std: 53.95\n",
      "RMSE real image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 437.77, min: 0.00, mean: 55.86, std: 53.15\n",
      "(epoch: 71, iters: 500, time: 0.114, data: 2.048) G_GAN: 0.751 G_L1: 4.786 D_real: 0.669 D_fake: 0.556 RMSE: 28.834 \n",
      "RMSE fake image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 2401.86, min: 0.00, mean: 50.46, std: 59.59\n",
      "RMSE real image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 1580.31, min: 0.00, mean: 54.81, std: 63.90\n",
      "(epoch: 71, iters: 1000, time: 0.102, data: 0.013) G_GAN: 0.857 G_L1: 4.572 D_real: 0.685 D_fake: 0.465 RMSE: 32.960 \n",
      "End of epoch 71 / 200 \t Time Taken: 56 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "RMSE fake image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 3295.48, min: 0.00, mean: 62.13, std: 76.04\n",
      "RMSE real image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 1454.35, min: 0.00, mean: 61.90, std: 80.92\n",
      "(epoch: 72, iters: 500, time: 0.089, data: 2.249) G_GAN: 1.216 G_L1: 5.451 D_real: 0.419 D_fake: 0.598 RMSE: 40.397 \n",
      "RMSE fake image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 2301.03, min: 0.00, mean: 68.99, std: 66.56\n",
      "RMSE real image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 3225.43, min: 0.00, mean: 68.46, std: 67.34\n",
      "(epoch: 72, iters: 1000, time: 0.099, data: 0.014) G_GAN: 0.652 G_L1: 5.306 D_real: 0.700 D_fake: 0.630 RMSE: 35.295 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End of epoch 72 / 200 \t Time Taken: 55 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "RMSE fake image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 838.96, min: 0.00, mean: 59.83, std: 74.79\n",
      "RMSE real image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 3221.46, min: 0.00, mean: 61.27, std: 76.69\n",
      "(epoch: 73, iters: 500, time: 0.103, data: 2.275) G_GAN: 1.103 G_L1: 4.870 D_real: 0.567 D_fake: 0.631 RMSE: 35.328 \n",
      "RMSE fake image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 724.96, min: 0.00, mean: 67.29, std: 65.96\n",
      "RMSE real image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 1257.58, min: 0.00, mean: 64.02, std: 63.95\n",
      "(epoch: 73, iters: 1000, time: 0.103, data: 0.024) G_GAN: 0.664 G_L1: 5.143 D_real: 0.742 D_fake: 0.594 RMSE: 31.878 \n",
      "End of epoch 73 / 200 \t Time Taken: 59 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "RMSE fake image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 2099.11, min: 0.00, mean: 56.94, std: 66.46\n",
      "RMSE real image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 3225.43, min: 0.00, mean: 60.17, std: 71.96\n",
      "(epoch: 74, iters: 500, time: 0.096, data: 2.062) G_GAN: 0.857 G_L1: 4.819 D_real: 0.657 D_fake: 0.551 RMSE: 34.780 \n",
      "RMSE fake image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 11446.17, min: 0.00, mean: 53.09, std: 72.89\n",
      "RMSE real image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 2407.02, min: 0.00, mean: 60.32, std: 75.96\n",
      "(epoch: 74, iters: 1000, time: 0.096, data: 0.063) G_GAN: 1.214 G_L1: 5.461 D_real: 0.331 D_fake: 0.960 RMSE: 47.819 \n",
      "End of epoch 74 / 200 \t Time Taken: 54 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "RMSE fake image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 1046.96, min: 0.00, mean: 69.97, std: 79.43\n",
      "RMSE real image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 3201.03, min: 0.00, mean: 74.31, std: 84.33\n",
      "(epoch: 75, iters: 500, time: 0.133, data: 2.148) G_GAN: 1.155 G_L1: 5.766 D_real: 0.308 D_fake: 0.960 RMSE: 39.165 \n",
      "RMSE fake image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 810.46, min: 0.00, mean: 32.98, std: 50.42\n",
      "RMSE real image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 530.44, min: 0.00, mean: 32.20, std: 48.01\n",
      "(epoch: 75, iters: 1000, time: 0.077, data: 0.056) G_GAN: 0.345 G_L1: 3.015 D_real: 1.372 D_fake: 0.347 RMSE: 22.589 \n",
      "saving the latest model (epoch 75, total_iters 75000)\n",
      "End of epoch 75 / 200 \t Time Taken: 55 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "RMSE fake image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 12123.38, min: 0.00, mean: 56.91, std: 79.75\n",
      "RMSE real image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 2070.09, min: 0.00, mean: 56.43, std: 71.46\n",
      "(epoch: 76, iters: 500, time: 0.112, data: 2.175) G_GAN: 0.783 G_L1: 5.059 D_real: 0.817 D_fake: 0.514 RMSE: 52.815 \n",
      "RMSE fake image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 757.00, min: 0.00, mean: 70.30, std: 69.42\n",
      "RMSE real image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 1710.22, min: 0.00, mean: 71.73, std: 70.21\n",
      "(epoch: 76, iters: 1000, time: 0.103, data: 0.107) G_GAN: 0.858 G_L1: 5.186 D_real: 0.500 D_fake: 0.629 RMSE: 32.686 \n",
      "End of epoch 76 / 200 \t Time Taken: 54 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "RMSE fake image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 889.06, min: 0.00, mean: 52.22, std: 57.79\n",
      "RMSE real image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 836.99, min: 0.00, mean: 55.91, std: 63.55\n",
      "(epoch: 77, iters: 500, time: 0.101, data: 2.152) G_GAN: 0.911 G_L1: 4.795 D_real: 0.607 D_fake: 0.565 RMSE: 31.585 \n",
      "RMSE fake image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 1085.47, min: 0.00, mean: 56.60, std: 67.70\n",
      "RMSE real image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 6078.89, min: 0.00, mean: 55.90, std: 69.92\n",
      "(epoch: 77, iters: 1000, time: 0.101, data: 0.083) G_GAN: 0.807 G_L1: 4.502 D_real: 0.670 D_fake: 0.595 RMSE: 34.941 \n",
      "End of epoch 77 / 200 \t Time Taken: 54 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "RMSE fake image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 4190.71, min: 0.00, mean: 61.70, std: 84.46\n",
      "RMSE real image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 2253.89, min: 0.00, mean: 60.69, std: 83.68\n",
      "(epoch: 78, iters: 500, time: 0.132, data: 2.170) G_GAN: 0.590 G_L1: 5.291 D_real: 0.778 D_fake: 0.500 RMSE: 43.176 \n",
      "RMSE fake image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 2253.28, min: 0.00, mean: 56.00, std: 63.51\n",
      "RMSE real image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 1234.01, min: 0.00, mean: 57.12, std: 65.73\n",
      "(epoch: 78, iters: 1000, time: 0.071, data: 0.023) G_GAN: 0.989 G_L1: 4.685 D_real: 0.497 D_fake: 0.663 RMSE: 31.458 \n",
      "End of epoch 78 / 200 \t Time Taken: 56 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "RMSE fake image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 960.71, min: 0.00, mean: 63.33, std: 73.37\n",
      "RMSE real image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 4718.91, min: 0.00, mean: 64.60, std: 75.42\n",
      "(epoch: 79, iters: 500, time: 0.115, data: 2.222) G_GAN: 1.138 G_L1: 5.088 D_real: 0.620 D_fake: 0.567 RMSE: 36.481 \n",
      "RMSE fake image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 5687.20, min: 0.00, mean: 64.63, std: 67.75\n",
      "RMSE real image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 5004.70, min: 0.00, mean: 64.79, std: 75.85\n",
      "(epoch: 79, iters: 1000, time: 0.104, data: 0.025) G_GAN: 1.302 G_L1: 5.337 D_real: 0.253 D_fake: 0.796 RMSE: 45.550 \n",
      "End of epoch 79 / 200 \t Time Taken: 55 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "RMSE fake image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 4153.21, min: 0.00, mean: 65.48, std: 64.05\n",
      "RMSE real image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 7339.64, min: 0.00, mean: 68.09, std: 71.05\n",
      "(epoch: 80, iters: 500, time: 0.095, data: 2.045) G_GAN: 0.899 G_L1: 5.272 D_real: 0.496 D_fake: 0.569 RMSE: 41.134 \n",
      "RMSE fake image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 666.56, min: 0.00, mean: 64.27, std: 64.92\n",
      "RMSE real image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 2296.38, min: 0.00, mean: 68.14, std: 65.56\n",
      "(epoch: 80, iters: 1000, time: 0.104, data: 0.050) G_GAN: 0.867 G_L1: 5.237 D_real: 0.685 D_fake: 0.533 RMSE: 32.288 \n",
      "saving the latest model (epoch 80, total_iters 80000)\n",
      "End of epoch 80 / 200 \t Time Taken: 59 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "RMSE fake image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 969.09, min: 0.00, mean: 63.44, std: 67.86\n",
      "RMSE real image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 2178.84, min: 0.00, mean: 65.04, std: 69.79\n",
      "(epoch: 81, iters: 500, time: 0.116, data: 2.158) G_GAN: 0.811 G_L1: 4.840 D_real: 0.709 D_fake: 0.522 RMSE: 31.775 \n",
      "RMSE fake image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 1001.78, min: 0.00, mean: 67.64, std: 66.08\n",
      "RMSE real image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 1550.95, min: 0.00, mean: 73.55, std: 70.53\n",
      "(epoch: 81, iters: 1000, time: 0.105, data: 0.013) G_GAN: 0.590 G_L1: 5.645 D_real: 0.847 D_fake: 0.407 RMSE: 34.821 \n",
      "End of epoch 81 / 200 \t Time Taken: 57 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "RMSE fake image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 1454.07, min: 0.00, mean: 43.60, std: 61.44\n",
      "RMSE real image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 4718.91, min: 0.00, mean: 45.80, std: 63.14\n",
      "(epoch: 82, iters: 500, time: 0.091, data: 2.286) G_GAN: 0.907 G_L1: 3.929 D_real: 0.615 D_fake: 0.749 RMSE: 30.945 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE fake image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 1183.92, min: 0.00, mean: 58.63, std: 66.41\n",
      "RMSE real image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 5004.70, min: 0.00, mean: 53.79, std: 64.32\n",
      "(epoch: 82, iters: 1000, time: 0.075, data: 0.011) G_GAN: 0.788 G_L1: 4.539 D_real: 1.015 D_fake: 0.407 RMSE: 34.919 \n",
      "End of epoch 82 / 200 \t Time Taken: 54 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "RMSE fake image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 681.14, min: 0.00, mean: 56.61, std: 60.63\n",
      "RMSE real image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 705.75, min: 0.00, mean: 59.66, std: 64.61\n",
      "(epoch: 83, iters: 500, time: 0.099, data: 2.013) G_GAN: 0.996 G_L1: 4.503 D_real: 0.483 D_fake: 0.598 RMSE: 29.140 \n",
      "RMSE fake image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 1027.82, min: 0.00, mean: 61.27, std: 59.26\n",
      "RMSE real image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 641.64, min: 0.00, mean: 59.97, std: 60.48\n",
      "(epoch: 83, iters: 1000, time: 0.105, data: 0.025) G_GAN: 1.005 G_L1: 4.717 D_real: 0.639 D_fake: 0.622 RMSE: 29.197 \n",
      "End of epoch 83 / 200 \t Time Taken: 55 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "RMSE fake image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 822.98, min: 0.00, mean: 55.29, std: 63.08\n",
      "RMSE real image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 1328.50, min: 0.00, mean: 53.52, std: 62.22\n",
      "(epoch: 84, iters: 500, time: 0.142, data: 2.332) G_GAN: 0.664 G_L1: 4.340 D_real: 0.831 D_fake: 0.517 RMSE: 28.809 \n",
      "RMSE fake image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 859.73, min: 0.00, mean: 54.74, std: 61.22\n",
      "RMSE real image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 3221.46, min: 0.00, mean: 57.17, std: 62.41\n",
      "(epoch: 84, iters: 1000, time: 0.107, data: 0.026) G_GAN: 1.027 G_L1: 4.386 D_real: 0.460 D_fake: 0.927 RMSE: 28.843 \n",
      "End of epoch 84 / 200 \t Time Taken: 59 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "RMSE fake image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 823.54, min: 0.00, mean: 62.06, std: 73.28\n",
      "RMSE real image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 2554.51, min: 0.00, mean: 60.64, std: 76.37\n",
      "(epoch: 85, iters: 500, time: 0.118, data: 2.078) G_GAN: 0.919 G_L1: 4.894 D_real: 0.543 D_fake: 0.705 RMSE: 34.815 \n",
      "RMSE fake image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 638.14, min: 0.00, mean: 45.80, std: 56.85\n",
      "RMSE real image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 774.18, min: 0.00, mean: 48.39, std: 59.92\n",
      "(epoch: 85, iters: 1000, time: 0.073, data: 0.012) G_GAN: 0.797 G_L1: 3.733 D_real: 0.521 D_fake: 0.828 RMSE: 25.631 \n",
      "saving the latest model (epoch 85, total_iters 85000)\n",
      "End of epoch 85 / 200 \t Time Taken: 56 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "RMSE fake image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 5424.07, min: 0.00, mean: 50.42, std: 65.18\n",
      "RMSE real image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 7339.64, min: 0.00, mean: 50.29, std: 66.65\n",
      "(epoch: 86, iters: 500, time: 0.123, data: 2.136) G_GAN: 1.308 G_L1: 4.299 D_real: 0.461 D_fake: 0.632 RMSE: 38.031 \n",
      "RMSE fake image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 5382.29, min: 0.00, mean: 60.87, std: 66.94\n",
      "RMSE real image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 5004.70, min: 0.00, mean: 61.52, std: 70.61\n",
      "(epoch: 86, iters: 1000, time: 0.113, data: 0.009) G_GAN: 0.888 G_L1: 4.891 D_real: 0.365 D_fake: 0.685 RMSE: 38.981 \n",
      "End of epoch 86 / 200 \t Time Taken: 57 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "RMSE fake image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 811.97, min: 0.00, mean: 47.62, std: 60.97\n",
      "RMSE real image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 1565.99, min: 0.00, mean: 44.88, std: 59.48\n",
      "(epoch: 87, iters: 500, time: 0.098, data: 2.100) G_GAN: 0.527 G_L1: 3.689 D_real: 0.925 D_fake: 0.498 RMSE: 26.559 \n",
      "RMSE fake image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 1965.98, min: 0.00, mean: 62.76, std: 73.68\n",
      "RMSE real image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 2329.35, min: 0.00, mean: 61.08, std: 71.35\n",
      "(epoch: 87, iters: 1000, time: 0.107, data: 0.027) G_GAN: 0.952 G_L1: 4.878 D_real: 0.745 D_fake: 0.613 RMSE: 34.430 \n",
      "End of epoch 87 / 200 \t Time Taken: 52 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "RMSE fake image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 2003.64, min: 0.00, mean: 63.05, std: 63.45\n",
      "RMSE real image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 3225.43, min: 0.00, mean: 59.05, std: 60.69\n",
      "(epoch: 88, iters: 500, time: 0.124, data: 2.164) G_GAN: 0.749 G_L1: 4.894 D_real: 1.197 D_fake: 0.315 RMSE: 31.946 \n",
      "RMSE fake image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 2042.47, min: 0.00, mean: 60.48, std: 66.41\n",
      "RMSE real image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 1650.92, min: 0.00, mean: 60.93, std: 69.50\n",
      "(epoch: 88, iters: 1000, time: 0.106, data: 0.020) G_GAN: 1.343 G_L1: 4.384 D_real: 0.411 D_fake: 0.835 RMSE: 29.157 \n",
      "End of epoch 88 / 200 \t Time Taken: 57 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "RMSE fake image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 1278.49, min: 0.00, mean: 54.96, std: 65.72\n",
      "RMSE real image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 1565.99, min: 0.00, mean: 54.50, std: 65.96\n",
      "(epoch: 89, iters: 500, time: 0.101, data: 2.178) G_GAN: 1.025 G_L1: 4.528 D_real: 0.475 D_fake: 0.681 RMSE: 31.284 \n",
      "RMSE fake image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 1243.34, min: 0.00, mean: 54.57, std: 64.47\n",
      "RMSE real image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 1481.80, min: 0.00, mean: 54.13, std: 62.60\n",
      "(epoch: 89, iters: 1000, time: 0.114, data: 0.009) G_GAN: 0.672 G_L1: 4.299 D_real: 0.868 D_fake: 0.434 RMSE: 29.218 \n",
      "End of epoch 89 / 200 \t Time Taken: 56 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "RMSE fake image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 5418.73, min: 0.00, mean: 62.54, std: 64.90\n",
      "RMSE real image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 1685.10, min: 0.00, mean: 64.51, std: 68.30\n",
      "(epoch: 90, iters: 500, time: 0.098, data: 2.129) G_GAN: 0.884 G_L1: 4.630 D_real: 0.712 D_fake: 0.537 RMSE: 31.779 \n",
      "RMSE fake image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 1089.07, min: 0.00, mean: 40.60, std: 51.73\n",
      "RMSE real image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 6212.39, min: 0.00, mean: 42.70, std: 56.70\n",
      "(epoch: 90, iters: 1000, time: 0.105, data: 0.013) G_GAN: 1.114 G_L1: 3.849 D_real: 0.480 D_fake: 0.649 RMSE: 30.214 \n",
      "saving the latest model (epoch 90, total_iters 90000)\n",
      "End of epoch 90 / 200 \t Time Taken: 58 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "RMSE fake image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 2608.86, min: 0.00, mean: 62.74, std: 84.19\n",
      "RMSE real image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 10450.77, min: 0.00, mean: 56.03, std: 79.08\n",
      "(epoch: 91, iters: 500, time: 0.120, data: 2.555) G_GAN: 0.721 G_L1: 5.556 D_real: 1.143 D_fake: 0.379 RMSE: 47.336 \n",
      "RMSE fake image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 768.93, min: 0.00, mean: 66.75, std: 70.08\n",
      "RMSE real image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 1848.90, min: 0.00, mean: 66.89, std: 68.67\n",
      "(epoch: 91, iters: 1000, time: 0.109, data: 0.011) G_GAN: 1.077 G_L1: 5.112 D_real: 0.583 D_fake: 0.609 RMSE: 32.752 \n",
      "End of epoch 91 / 200 \t Time Taken: 57 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE fake image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 725.04, min: 0.00, mean: 54.43, std: 57.28\n",
      "RMSE real image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 1606.04, min: 0.00, mean: 54.41, std: 59.43\n",
      "(epoch: 92, iters: 500, time: 0.143, data: 2.302) G_GAN: 1.036 G_L1: 4.426 D_real: 0.416 D_fake: 0.649 RMSE: 27.939 \n",
      "RMSE fake image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 623.36, min: 0.00, mean: 55.12, std: 60.94\n",
      "RMSE real image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 1428.65, min: 0.00, mean: 59.10, std: 64.81\n",
      "(epoch: 92, iters: 1000, time: 0.071, data: 0.011) G_GAN: 0.969 G_L1: 4.445 D_real: 0.703 D_fake: 0.467 RMSE: 30.064 \n",
      "End of epoch 92 / 200 \t Time Taken: 57 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "RMSE fake image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 1937.06, min: 0.00, mean: 52.36, std: 66.77\n",
      "RMSE real image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 1650.92, min: 0.00, mean: 54.40, std: 72.46\n",
      "(epoch: 93, iters: 500, time: 0.119, data: 2.250) G_GAN: 1.329 G_L1: 4.571 D_real: 0.294 D_fake: 0.742 RMSE: 33.289 \n",
      "RMSE fake image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 1948.01, min: 0.00, mean: 49.21, std: 60.83\n",
      "RMSE real image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 4773.41, min: 0.00, mean: 49.55, std: 64.44\n",
      "(epoch: 93, iters: 1000, time: 0.102, data: 0.034) G_GAN: 1.006 G_L1: 3.834 D_real: 0.694 D_fake: 0.397 RMSE: 31.065 \n",
      "End of epoch 93 / 200 \t Time Taken: 56 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "RMSE fake image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 2473.19, min: 0.00, mean: 53.30, std: 63.82\n",
      "RMSE real image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 2837.10, min: 0.00, mean: 48.81, std: 60.17\n",
      "(epoch: 94, iters: 500, time: 0.100, data: 2.303) G_GAN: 1.008 G_L1: 4.446 D_real: 0.586 D_fake: 0.732 RMSE: 31.318 \n",
      "RMSE fake image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 938.76, min: 0.00, mean: 64.98, std: 62.66\n",
      "RMSE real image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 966.59, min: 0.00, mean: 62.73, std: 60.17\n",
      "(epoch: 94, iters: 1000, time: 0.110, data: 0.012) G_GAN: 0.983 G_L1: 4.931 D_real: 0.501 D_fake: 0.828 RMSE: 30.117 \n",
      "End of epoch 94 / 200 \t Time Taken: 60 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "RMSE fake image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 672.02, min: 0.00, mean: 63.47, std: 66.96\n",
      "RMSE real image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 3400.48, min: 0.00, mean: 59.98, std: 66.05\n",
      "(epoch: 95, iters: 500, time: 0.123, data: 2.062) G_GAN: 1.265 G_L1: 4.896 D_real: 0.424 D_fake: 0.791 RMSE: 32.849 \n",
      "RMSE fake image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 944.91, min: 0.00, mean: 53.01, std: 65.17\n",
      "RMSE real image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 1089.84, min: 0.00, mean: 58.14, std: 71.06\n",
      "(epoch: 95, iters: 1000, time: 0.109, data: 0.015) G_GAN: 1.417 G_L1: 4.250 D_real: 0.421 D_fake: 0.692 RMSE: 29.418 \n",
      "saving the latest model (epoch 95, total_iters 95000)\n",
      "End of epoch 95 / 200 \t Time Taken: 60 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "RMSE fake image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 4354.67, min: 0.00, mean: 62.01, std: 69.92\n",
      "RMSE real image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 1689.28, min: 0.00, mean: 60.83, std: 69.81\n",
      "(epoch: 96, iters: 500, time: 0.125, data: 2.088) G_GAN: 1.126 G_L1: 4.856 D_real: 0.588 D_fake: 0.569 RMSE: 34.118 \n",
      "RMSE fake image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 635.23, min: 0.00, mean: 50.87, std: 57.34\n",
      "RMSE real image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 793.17, min: 0.00, mean: 48.58, std: 54.81\n",
      "(epoch: 96, iters: 1000, time: 0.107, data: 0.013) G_GAN: 0.668 G_L1: 4.057 D_real: 0.914 D_fake: 0.382 RMSE: 26.537 \n",
      "End of epoch 96 / 200 \t Time Taken: 80 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "RMSE fake image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 2528.80, min: 0.00, mean: 60.41, std: 61.52\n",
      "RMSE real image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 1654.40, min: 0.00, mean: 61.24, std: 62.48\n",
      "(epoch: 97, iters: 500, time: 0.115, data: 2.873) G_GAN: 1.391 G_L1: 4.835 D_real: 0.491 D_fake: 0.439 RMSE: 30.668 \n",
      "RMSE fake image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 787.88, min: 0.00, mean: 54.31, std: 57.05\n",
      "RMSE real image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 1022.96, min: 0.00, mean: 52.95, std: 56.19\n",
      "(epoch: 97, iters: 1000, time: 0.078, data: 0.036) G_GAN: 0.635 G_L1: 4.133 D_real: 0.790 D_fake: 0.573 RMSE: 25.932 \n",
      "End of epoch 97 / 200 \t Time Taken: 72 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "RMSE fake image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 594.34, min: 0.00, mean: 57.67, std: 55.94\n",
      "RMSE real image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 1005.30, min: 0.00, mean: 59.40, std: 56.00\n",
      "(epoch: 98, iters: 500, time: 0.124, data: 2.981) G_GAN: 1.033 G_L1: 4.610 D_real: 0.426 D_fake: 0.568 RMSE: 27.246 \n",
      "RMSE fake image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 1944.55, min: 0.00, mean: 61.86, std: 68.55\n",
      "RMSE real image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 2752.22, min: 0.00, mean: 58.22, std: 66.61\n",
      "(epoch: 98, iters: 1000, time: 0.107, data: 0.012) G_GAN: 1.086 G_L1: 4.801 D_real: 0.557 D_fake: 0.668 RMSE: 32.670 \n",
      "End of epoch 98 / 200 \t Time Taken: 56 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "RMSE fake image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 1716.06, min: 0.00, mean: 64.54, std: 66.29\n",
      "RMSE real image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 855.41, min: 0.00, mean: 63.79, std: 65.09\n",
      "(epoch: 99, iters: 500, time: 0.132, data: 2.193) G_GAN: 0.877 G_L1: 4.878 D_real: 0.956 D_fake: 0.369 RMSE: 30.427 \n",
      "RMSE fake image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 8585.02, min: 0.00, mean: 60.18, std: 76.23\n",
      "RMSE real image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 2577.69, min: 0.00, mean: 60.13, std: 66.24\n",
      "(epoch: 99, iters: 1000, time: 0.118, data: 0.012) G_GAN: 1.253 G_L1: 5.264 D_real: 0.552 D_fake: 0.490 RMSE: 50.631 \n",
      "End of epoch 99 / 200 \t Time Taken: 56 sec\n",
      "learning rate 0.0002000 -> 0.0001980\n",
      "RMSE fake image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 1111.22, min: 0.00, mean: 62.15, std: 68.53\n",
      "RMSE real image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 814.07, min: 0.00, mean: 62.09, std: 68.22\n",
      "(epoch: 100, iters: 500, time: 0.117, data: 2.136) G_GAN: 1.100 G_L1: 4.718 D_real: 0.507 D_fake: 0.461 RMSE: 31.622 \n",
      "RMSE fake image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 783.30, min: 0.00, mean: 54.54, std: 65.56\n",
      "RMSE real image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 1198.81, min: 0.00, mean: 53.28, std: 66.38\n",
      "(epoch: 100, iters: 1000, time: 0.108, data: 0.012) G_GAN: 1.155 G_L1: 4.427 D_real: 0.756 D_fake: 0.285 RMSE: 29.986 \n",
      "saving the latest model (epoch 100, total_iters 100000)\n",
      "End of epoch 100 / 200 \t Time Taken: 58 sec\n",
      "learning rate 0.0001980 -> 0.0001960\n",
      "RMSE fake image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 5729.51, min: 0.00, mean: 59.82, std: 70.55\n",
      "RMSE real image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 2577.69, min: 0.00, mean: 61.36, std: 68.23\n",
      "(epoch: 101, iters: 500, time: 0.102, data: 2.057) G_GAN: 0.987 G_L1: 5.278 D_real: 0.537 D_fake: 0.444 RMSE: 42.160 \n",
      "RMSE fake image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 700.57, min: 0.00, mean: 48.90, std: 57.79\n",
      "RMSE real image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 3221.46, min: 0.00, mean: 48.87, std: 57.26\n",
      "(epoch: 101, iters: 1000, time: 0.120, data: 0.011) G_GAN: 0.581 G_L1: 4.004 D_real: 1.056 D_fake: 0.423 RMSE: 27.007 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End of epoch 101 / 200 \t Time Taken: 56 sec\n",
      "learning rate 0.0001960 -> 0.0001941\n",
      "RMSE fake image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 981.88, min: 0.00, mean: 52.04, std: 63.84\n",
      "RMSE real image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 1069.14, min: 0.00, mean: 53.38, std: 66.48\n",
      "(epoch: 102, iters: 500, time: 0.123, data: 2.211) G_GAN: 1.332 G_L1: 4.189 D_real: 0.412 D_fake: 0.607 RMSE: 28.420 \n",
      "RMSE fake image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 1290.59, min: 0.00, mean: 67.43, std: 74.33\n",
      "RMSE real image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 4718.91, min: 0.00, mean: 67.94, std: 75.63\n",
      "(epoch: 102, iters: 1000, time: 0.111, data: 0.012) G_GAN: 1.570 G_L1: 5.111 D_real: 0.386 D_fake: 0.535 RMSE: 34.740 \n",
      "End of epoch 102 / 200 \t Time Taken: 55 sec\n",
      "learning rate 0.0001941 -> 0.0001921\n",
      "RMSE fake image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 1120.79, min: 0.00, mean: 60.39, std: 65.04\n",
      "RMSE real image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 1933.50, min: 0.00, mean: 56.94, std: 63.06\n",
      "(epoch: 103, iters: 500, time: 0.104, data: 2.059) G_GAN: 0.875 G_L1: 4.372 D_real: 0.800 D_fake: 0.408 RMSE: 29.680 \n",
      "RMSE fake image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 1504.41, min: 0.00, mean: 54.26, std: 65.62\n",
      "RMSE real image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 1597.18, min: 0.00, mean: 53.03, std: 63.63\n",
      "(epoch: 103, iters: 1000, time: 0.111, data: 0.013) G_GAN: 0.852 G_L1: 4.399 D_real: 0.539 D_fake: 0.479 RMSE: 29.766 \n",
      "End of epoch 103 / 200 \t Time Taken: 55 sec\n",
      "learning rate 0.0001921 -> 0.0001901\n",
      "RMSE fake image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 1046.83, min: 0.00, mean: 61.71, std: 66.34\n",
      "RMSE real image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 1022.96, min: 0.00, mean: 63.99, std: 72.49\n",
      "(epoch: 104, iters: 500, time: 0.146, data: 2.045) G_GAN: 0.955 G_L1: 4.897 D_real: 0.685 D_fake: 0.430 RMSE: 31.843 \n",
      "RMSE fake image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 616.98, min: 0.00, mean: 56.82, std: 62.28\n",
      "RMSE real image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 2752.22, min: 0.00, mean: 58.85, std: 65.96\n",
      "(epoch: 104, iters: 1000, time: 0.112, data: 0.014) G_GAN: 1.510 G_L1: 4.356 D_real: 0.428 D_fake: 0.731 RMSE: 30.080 \n",
      "End of epoch 104 / 200 \t Time Taken: 54 sec\n",
      "learning rate 0.0001901 -> 0.0001881\n",
      "RMSE fake image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 1357.09, min: 0.00, mean: 56.04, std: 62.49\n",
      "RMSE real image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 6551.64, min: 0.00, mean: 55.39, std: 65.70\n",
      "(epoch: 105, iters: 500, time: 0.127, data: 2.085) G_GAN: 1.026 G_L1: 4.662 D_real: 0.531 D_fake: 0.382 RMSE: 36.069 \n",
      "RMSE fake image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 738.85, min: 0.00, mean: 62.68, std: 67.50\n",
      "RMSE real image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 828.31, min: 0.00, mean: 61.37, std: 68.03\n",
      "(epoch: 105, iters: 1000, time: 0.112, data: 0.113) G_GAN: 1.063 G_L1: 4.546 D_real: 0.455 D_fake: 0.607 RMSE: 28.679 \n",
      "saving the latest model (epoch 105, total_iters 105000)\n",
      "End of epoch 105 / 200 \t Time Taken: 57 sec\n",
      "learning rate 0.0001881 -> 0.0001861\n",
      "RMSE fake image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 596.50, min: 0.00, mean: 59.04, std: 60.20\n",
      "RMSE real image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 2246.04, min: 0.00, mean: 59.58, std: 59.97\n",
      "(epoch: 106, iters: 500, time: 0.116, data: 2.102) G_GAN: 1.101 G_L1: 4.575 D_real: 0.538 D_fake: 0.472 RMSE: 28.616 \n",
      "RMSE fake image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 5401.64, min: 0.00, mean: 59.52, std: 73.24\n",
      "RMSE real image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 1742.75, min: 0.00, mean: 62.60, std: 75.29\n",
      "(epoch: 106, iters: 1000, time: 0.109, data: 0.013) G_GAN: 1.416 G_L1: 4.654 D_real: 0.207 D_fake: 1.099 RMSE: 37.101 \n",
      "End of epoch 106 / 200 \t Time Taken: 57 sec\n",
      "learning rate 0.0001861 -> 0.0001842\n",
      "RMSE fake image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 638.56, min: 0.00, mean: 51.09, std: 56.14\n",
      "RMSE real image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 601.61, min: 0.00, mean: 48.50, std: 53.11\n",
      "(epoch: 107, iters: 500, time: 0.104, data: 2.229) G_GAN: 0.696 G_L1: 3.854 D_real: 0.832 D_fake: 0.417 RMSE: 25.137 \n",
      "RMSE fake image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 1286.72, min: 0.00, mean: 56.08, std: 63.95\n",
      "RMSE real image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 1710.22, min: 0.00, mean: 56.47, std: 65.47\n",
      "(epoch: 107, iters: 1000, time: 0.085, data: 0.013) G_GAN: 0.828 G_L1: 4.126 D_real: 0.854 D_fake: 0.345 RMSE: 27.223 \n",
      "End of epoch 107 / 200 \t Time Taken: 53 sec\n",
      "learning rate 0.0001842 -> 0.0001822\n",
      "RMSE fake image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 3458.12, min: 0.00, mean: 58.27, std: 67.72\n",
      "RMSE real image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 706.92, min: 0.00, mean: 60.71, std: 70.82\n",
      "(epoch: 108, iters: 500, time: 0.128, data: 2.044) G_GAN: 1.834 G_L1: 4.479 D_real: 0.303 D_fake: 0.820 RMSE: 30.791 \n",
      "RMSE fake image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 725.13, min: 0.00, mean: 56.25, std: 58.70\n",
      "RMSE real image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 1454.35, min: 0.00, mean: 54.78, std: 56.01\n",
      "(epoch: 108, iters: 1000, time: 0.122, data: 0.014) G_GAN: 0.766 G_L1: 4.432 D_real: 0.724 D_fake: 0.466 RMSE: 28.858 \n",
      "End of epoch 108 / 200 \t Time Taken: 57 sec\n",
      "learning rate 0.0001822 -> 0.0001802\n",
      "RMSE fake image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 923.95, min: 0.00, mean: 58.98, std: 67.24\n",
      "RMSE real image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 1328.50, min: 0.00, mean: 59.07, std: 68.42\n",
      "(epoch: 109, iters: 500, time: 0.106, data: 2.077) G_GAN: 1.138 G_L1: 4.605 D_real: 0.527 D_fake: 0.468 RMSE: 29.966 \n",
      "RMSE fake image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 1814.31, min: 0.00, mean: 46.66, std: 59.38\n",
      "RMSE real image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 2146.95, min: 0.00, mean: 47.08, std: 59.73\n",
      "(epoch: 109, iters: 1000, time: 0.112, data: 0.013) G_GAN: 0.676 G_L1: 3.744 D_real: 1.206 D_fake: 0.239 RMSE: 27.624 \n",
      "End of epoch 109 / 200 \t Time Taken: 58 sec\n",
      "learning rate 0.0001802 -> 0.0001782\n",
      "RMSE fake image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 19542.34, min: 0.00, mean: 55.11, std: 77.65\n",
      "RMSE real image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 3325.74, min: 0.00, mean: 53.75, std: 66.56\n",
      "(epoch: 110, iters: 500, time: 0.131, data: 2.257) G_GAN: 1.478 G_L1: 4.295 D_real: 0.372 D_fake: 1.038 RMSE: 50.947 \n",
      "RMSE fake image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 828.16, min: 0.00, mean: 46.78, std: 60.35\n",
      "RMSE real image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 531.69, min: 0.00, mean: 48.07, std: 60.19\n",
      "(epoch: 110, iters: 1000, time: 0.116, data: 0.038) G_GAN: 0.757 G_L1: 3.942 D_real: 0.721 D_fake: 0.423 RMSE: 26.385 \n",
      "saving the latest model (epoch 110, total_iters 110000)\n",
      "End of epoch 110 / 200 \t Time Taken: 60 sec\n",
      "learning rate 0.0001782 -> 0.0001762\n",
      "RMSE fake image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 4365.84, min: 0.00, mean: 59.10, std: 67.60\n",
      "RMSE real image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 7339.64, min: 0.00, mean: 64.52, std: 72.94\n",
      "(epoch: 111, iters: 500, time: 0.124, data: 2.335) G_GAN: 1.212 G_L1: 4.492 D_real: 0.176 D_fake: 1.211 RMSE: 37.356 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE fake image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 805.21, min: 0.00, mean: 60.16, std: 67.01\n",
      "RMSE real image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 1454.35, min: 0.00, mean: 57.33, std: 65.95\n",
      "(epoch: 111, iters: 1000, time: 0.109, data: 0.012) G_GAN: 0.705 G_L1: 4.971 D_real: 0.909 D_fake: 0.338 RMSE: 32.821 \n",
      "End of epoch 111 / 200 \t Time Taken: 58 sec\n",
      "learning rate 0.0001762 -> 0.0001743\n",
      "RMSE fake image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 800.58, min: 0.00, mean: 52.01, std: 66.69\n",
      "RMSE real image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 1772.06, min: 0.00, mean: 50.54, std: 68.30\n",
      "(epoch: 112, iters: 500, time: 0.105, data: 2.362) G_GAN: 0.877 G_L1: 4.024 D_real: 0.646 D_fake: 0.386 RMSE: 29.442 \n",
      "RMSE fake image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 797.29, min: 0.00, mean: 56.19, std: 63.92\n",
      "RMSE real image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 2293.96, min: 0.00, mean: 52.51, std: 60.41\n",
      "(epoch: 112, iters: 1000, time: 0.115, data: 0.012) G_GAN: 0.470 G_L1: 4.324 D_real: 1.007 D_fake: 0.435 RMSE: 28.860 \n",
      "End of epoch 112 / 200 \t Time Taken: 55 sec\n",
      "learning rate 0.0001743 -> 0.0001723\n",
      "RMSE fake image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 2987.19, min: 0.00, mean: 62.72, std: 70.89\n",
      "RMSE real image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 3153.37, min: 0.00, mean: 65.25, std: 76.89\n",
      "(epoch: 113, iters: 500, time: 0.145, data: 2.188) G_GAN: 1.208 G_L1: 4.636 D_real: 0.331 D_fake: 0.741 RMSE: 34.646 \n",
      "RMSE fake image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 590.41, min: 0.00, mean: 60.82, std: 63.46\n",
      "RMSE real image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 661.43, min: 0.00, mean: 61.27, std: 64.55\n",
      "(epoch: 113, iters: 1000, time: 0.113, data: 0.038) G_GAN: 1.246 G_L1: 4.568 D_real: 0.512 D_fake: 0.499 RMSE: 28.239 \n",
      "End of epoch 113 / 200 \t Time Taken: 57 sec\n",
      "learning rate 0.0001723 -> 0.0001703\n",
      "RMSE fake image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 1403.45, min: 0.00, mean: 55.18, std: 64.39\n",
      "RMSE real image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 868.49, min: 0.00, mean: 54.49, std: 64.17\n",
      "(epoch: 114, iters: 500, time: 0.126, data: 1.859) G_GAN: 1.051 G_L1: 4.333 D_real: 0.451 D_fake: 0.645 RMSE: 29.524 \n",
      "RMSE fake image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 1027.11, min: 0.00, mean: 47.09, std: 64.11\n",
      "RMSE real image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 4773.41, min: 0.00, mean: 49.65, std: 67.88\n",
      "(epoch: 114, iters: 1000, time: 0.113, data: 0.055) G_GAN: 0.644 G_L1: 3.864 D_real: 0.790 D_fake: 0.391 RMSE: 31.737 \n",
      "End of epoch 114 / 200 \t Time Taken: 53 sec\n",
      "learning rate 0.0001703 -> 0.0001683\n",
      "RMSE fake image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 12991.84, min: 0.00, mean: 61.01, std: 66.26\n",
      "RMSE real image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 2834.73, min: 0.00, mean: 57.14, std: 60.73\n",
      "(epoch: 115, iters: 500, time: 0.144, data: 2.191) G_GAN: 0.990 G_L1: 4.825 D_real: 0.679 D_fake: 0.350 RMSE: 43.770 \n",
      "RMSE fake image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 1170.49, min: 0.00, mean: 60.96, std: 69.01\n",
      "RMSE real image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 2170.76, min: 0.00, mean: 58.37, std: 66.84\n",
      "(epoch: 115, iters: 1000, time: 0.109, data: 0.013) G_GAN: 1.185 G_L1: 4.430 D_real: 0.460 D_fake: 0.696 RMSE: 29.837 \n",
      "saving the latest model (epoch 115, total_iters 115000)\n",
      "End of epoch 115 / 200 \t Time Taken: 59 sec\n",
      "learning rate 0.0001683 -> 0.0001663\n",
      "RMSE fake image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 4176.57, min: 0.00, mean: 47.89, std: 59.21\n",
      "RMSE real image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 1233.59, min: 0.00, mean: 47.49, std: 55.89\n",
      "(epoch: 116, iters: 500, time: 0.131, data: 2.166) G_GAN: 0.964 G_L1: 3.998 D_real: 0.682 D_fake: 0.566 RMSE: 28.222 \n",
      "RMSE fake image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 1889.99, min: 0.00, mean: 45.19, std: 52.99\n",
      "RMSE real image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 436.47, min: 0.00, mean: 45.48, std: 52.01\n",
      "(epoch: 116, iters: 1000, time: 0.110, data: 0.052) G_GAN: 0.791 G_L1: 3.700 D_real: 0.856 D_fake: 0.379 RMSE: 24.524 \n",
      "End of epoch 116 / 200 \t Time Taken: 56 sec\n",
      "learning rate 0.0001663 -> 0.0001644\n",
      "RMSE fake image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 614.55, min: 0.00, mean: 55.43, std: 65.10\n",
      "RMSE real image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 1742.75, min: 0.00, mean: 55.38, std: 65.48\n",
      "(epoch: 117, iters: 500, time: 0.119, data: 2.245) G_GAN: 1.275 G_L1: 4.001 D_real: 0.409 D_fake: 0.629 RMSE: 27.072 \n",
      "RMSE fake image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 3434.98, min: 0.00, mean: 57.63, std: 62.83\n",
      "RMSE real image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 2599.55, min: 0.00, mean: 54.42, std: 59.17\n",
      "(epoch: 117, iters: 1000, time: 0.115, data: 0.014) G_GAN: 1.040 G_L1: 4.644 D_real: 0.557 D_fake: 0.623 RMSE: 32.529 \n",
      "End of epoch 117 / 200 \t Time Taken: 59 sec\n",
      "learning rate 0.0001644 -> 0.0001624\n",
      "RMSE fake image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 755.50, min: 0.00, mean: 61.39, std: 67.21\n",
      "RMSE real image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 946.32, min: 0.00, mean: 63.05, std: 65.57\n",
      "(epoch: 118, iters: 500, time: 0.155, data: 2.068) G_GAN: 0.982 G_L1: 4.904 D_real: 0.623 D_fake: 0.536 RMSE: 32.092 \n",
      "RMSE fake image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 978.77, min: 0.00, mean: 53.27, std: 59.40\n",
      "RMSE real image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 3377.76, min: 0.00, mean: 55.03, std: 63.40\n",
      "(epoch: 118, iters: 1000, time: 0.110, data: 0.013) G_GAN: 0.968 G_L1: 4.211 D_real: 0.367 D_fake: 0.629 RMSE: 31.019 \n",
      "End of epoch 118 / 200 \t Time Taken: 55 sec\n",
      "learning rate 0.0001624 -> 0.0001604\n",
      "RMSE fake image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 3652.40, min: 0.00, mean: 63.49, std: 67.15\n",
      "RMSE real image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 3233.36, min: 0.00, mean: 62.00, std: 65.26\n",
      "(epoch: 119, iters: 500, time: 0.150, data: 1.986) G_GAN: 0.634 G_L1: 4.636 D_real: 0.865 D_fake: 0.412 RMSE: 29.921 \n",
      "RMSE fake image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 2731.22, min: 0.00, mean: 55.00, std: 57.97\n",
      "RMSE real image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 5004.70, min: 0.00, mean: 52.86, std: 59.47\n",
      "(epoch: 119, iters: 1000, time: 0.087, data: 0.014) G_GAN: 0.992 G_L1: 4.194 D_real: 0.756 D_fake: 0.299 RMSE: 31.955 \n",
      "End of epoch 119 / 200 \t Time Taken: 56 sec\n",
      "learning rate 0.0001604 -> 0.0001584\n",
      "RMSE fake image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 3020.34, min: 0.00, mean: 58.96, std: 66.54\n",
      "RMSE real image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 1295.19, min: 0.00, mean: 62.36, std: 72.90\n",
      "(epoch: 120, iters: 500, time: 0.104, data: 2.040) G_GAN: 0.972 G_L1: 4.795 D_real: 0.485 D_fake: 0.453 RMSE: 32.801 \n",
      "RMSE fake image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 2682.62, min: 0.00, mean: 69.31, std: 86.56\n",
      "RMSE real image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 10450.77, min: 0.00, mean: 75.61, std: 95.41\n",
      "(epoch: 120, iters: 1000, time: 0.115, data: 0.024) G_GAN: 1.906 G_L1: 6.127 D_real: 0.194 D_fake: 1.121 RMSE: 49.969 \n",
      "saving the latest model (epoch 120, total_iters 120000)\n",
      "End of epoch 120 / 200 \t Time Taken: 58 sec\n",
      "learning rate 0.0001584 -> 0.0001564\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE fake image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 948.28, min: 0.00, mean: 52.68, std: 58.87\n",
      "RMSE real image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 810.61, min: 0.00, mean: 55.67, std: 61.40\n",
      "(epoch: 121, iters: 500, time: 0.134, data: 2.122) G_GAN: 0.979 G_L1: 4.156 D_real: 0.723 D_fake: 0.400 RMSE: 27.094 \n",
      "RMSE fake image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 2414.33, min: 0.00, mean: 54.09, std: 66.09\n",
      "RMSE real image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 1685.10, min: 0.00, mean: 53.64, std: 68.17\n",
      "(epoch: 121, iters: 1000, time: 0.116, data: 0.025) G_GAN: 0.683 G_L1: 4.063 D_real: 0.735 D_fake: 0.350 RMSE: 28.457 \n",
      "End of epoch 121 / 200 \t Time Taken: 56 sec\n",
      "learning rate 0.0001564 -> 0.0001545\n",
      "RMSE fake image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 1323.36, min: 0.00, mean: 65.09, std: 65.04\n",
      "RMSE real image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 1496.20, min: 0.00, mean: 66.28, std: 67.06\n",
      "(epoch: 122, iters: 500, time: 0.107, data: 1.982) G_GAN: 1.076 G_L1: 4.779 D_real: 0.672 D_fake: 0.314 RMSE: 30.461 \n",
      "RMSE fake image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 1122.60, min: 0.00, mean: 55.06, std: 65.51\n",
      "RMSE real image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 1591.30, min: 0.00, mean: 56.45, std: 65.68\n",
      "(epoch: 122, iters: 1000, time: 0.109, data: 0.014) G_GAN: 1.058 G_L1: 4.184 D_real: 0.626 D_fake: 0.482 RMSE: 28.290 \n",
      "End of epoch 122 / 200 \t Time Taken: 55 sec\n",
      "learning rate 0.0001545 -> 0.0001525\n",
      "RMSE fake image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 917.93, min: 0.00, mean: 57.95, std: 68.42\n",
      "RMSE real image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 1024.05, min: 0.00, mean: 56.23, std: 65.44\n",
      "(epoch: 123, iters: 500, time: 0.123, data: 2.123) G_GAN: 0.820 G_L1: 4.306 D_real: 0.816 D_fake: 0.447 RMSE: 29.165 \n",
      "RMSE fake image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 2071.99, min: 0.00, mean: 52.36, std: 62.24\n",
      "RMSE real image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 1389.95, min: 0.00, mean: 53.99, std: 64.98\n",
      "(epoch: 123, iters: 1000, time: 0.112, data: 0.012) G_GAN: 1.078 G_L1: 4.056 D_real: 0.513 D_fake: 0.598 RMSE: 27.748 \n",
      "End of epoch 123 / 200 \t Time Taken: 62 sec\n",
      "learning rate 0.0001525 -> 0.0001505\n",
      "RMSE fake image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 1906.71, min: 0.00, mean: 54.96, std: 57.03\n",
      "RMSE real image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 549.02, min: 0.00, mean: 56.86, std: 59.65\n",
      "(epoch: 124, iters: 500, time: 0.112, data: 2.128) G_GAN: 0.802 G_L1: 4.379 D_real: 0.761 D_fake: 0.398 RMSE: 27.243 \n",
      "RMSE fake image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 1803.70, min: 0.00, mean: 66.18, std: 69.95\n",
      "RMSE real image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 3195.57, min: 0.00, mean: 69.76, std: 75.28\n",
      "(epoch: 124, iters: 1000, time: 0.117, data: 0.015) G_GAN: 0.830 G_L1: 5.269 D_real: 0.795 D_fake: 0.350 RMSE: 35.182 \n",
      "End of epoch 124 / 200 \t Time Taken: 58 sec\n",
      "learning rate 0.0001505 -> 0.0001485\n",
      "RMSE fake image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 2418.67, min: 0.00, mean: 60.16, std: 65.40\n",
      "RMSE real image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 1813.82, min: 0.00, mean: 62.07, std: 67.99\n",
      "(epoch: 125, iters: 500, time: 0.120, data: 2.154) G_GAN: 0.779 G_L1: 4.514 D_real: 0.933 D_fake: 0.331 RMSE: 29.974 \n",
      "RMSE fake image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 3546.74, min: 0.00, mean: 54.98, std: 63.14\n",
      "RMSE real image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 7339.64, min: 0.00, mean: 58.89, std: 68.83\n",
      "(epoch: 125, iters: 1000, time: 0.115, data: 0.021) G_GAN: 1.333 G_L1: 4.530 D_real: 0.351 D_fake: 0.648 RMSE: 36.080 \n",
      "saving the latest model (epoch 125, total_iters 125000)\n",
      "End of epoch 125 / 200 \t Time Taken: 78 sec\n",
      "learning rate 0.0001485 -> 0.0001465\n",
      "RMSE fake image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 1268.12, min: 0.00, mean: 64.61, std: 72.68\n",
      "RMSE real image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 1597.18, min: 0.00, mean: 61.36, std: 71.15\n",
      "(epoch: 126, iters: 500, time: 0.096, data: 2.780) G_GAN: 1.725 G_L1: 4.539 D_real: 0.436 D_fake: 0.680 RMSE: 30.618 \n",
      "RMSE fake image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 603.73, min: 0.00, mean: 65.50, std: 64.10\n",
      "RMSE real image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 773.26, min: 0.00, mean: 63.67, std: 62.51\n",
      "(epoch: 126, iters: 1000, time: 0.126, data: 0.061) G_GAN: 1.105 G_L1: 4.608 D_real: 0.799 D_fake: 0.302 RMSE: 28.257 \n",
      "End of epoch 126 / 200 \t Time Taken: 109 sec\n",
      "learning rate 0.0001465 -> 0.0001446\n",
      "RMSE fake image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 3248.43, min: 0.00, mean: 59.27, std: 70.56\n",
      "RMSE real image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 2837.10, min: 0.00, mean: 60.41, std: 71.55\n",
      "(epoch: 127, iters: 500, time: 0.105, data: 1.830) G_GAN: 0.558 G_L1: 4.519 D_real: 0.991 D_fake: 0.341 RMSE: 32.546 \n",
      "RMSE fake image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 6657.49, min: 0.00, mean: 60.79, std: 72.62\n",
      "RMSE real image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 2493.77, min: 0.00, mean: 63.93, std: 74.91\n",
      "(epoch: 127, iters: 1000, time: 0.115, data: 0.095) G_GAN: 1.704 G_L1: 4.918 D_real: 0.247 D_fake: 0.847 RMSE: 40.259 \n",
      "End of epoch 127 / 200 \t Time Taken: 57 sec\n",
      "learning rate 0.0001446 -> 0.0001426\n",
      "RMSE fake image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 599.35, min: 0.00, mean: 63.42, std: 66.39\n",
      "RMSE real image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 1476.08, min: 0.00, mean: 59.89, std: 63.34\n",
      "(epoch: 128, iters: 500, time: 0.129, data: 2.044) G_GAN: 1.001 G_L1: 4.428 D_real: 1.317 D_fake: 0.164 RMSE: 28.294 \n",
      "RMSE fake image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 1029.95, min: 0.00, mean: 56.64, std: 63.04\n",
      "RMSE real image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 1257.58, min: 0.00, mean: 55.29, std: 59.36\n",
      "(epoch: 128, iters: 1000, time: 0.122, data: 0.013) G_GAN: 0.684 G_L1: 4.100 D_real: 1.066 D_fake: 0.226 RMSE: 26.920 \n",
      "End of epoch 128 / 200 \t Time Taken: 57 sec\n",
      "learning rate 0.0001426 -> 0.0001406\n",
      "RMSE fake image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 857.06, min: 0.00, mean: 65.72, std: 66.64\n",
      "RMSE real image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 1548.89, min: 0.00, mean: 69.48, std: 69.76\n",
      "(epoch: 129, iters: 500, time: 0.142, data: 2.143) G_GAN: 1.538 G_L1: 5.149 D_real: 0.262 D_fake: 0.834 RMSE: 32.096 \n",
      "RMSE fake image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 2652.05, min: 0.00, mean: 66.14, std: 67.22\n",
      "RMSE real image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 2599.55, min: 0.00, mean: 66.63, std: 66.38\n",
      "(epoch: 129, iters: 1000, time: 0.118, data: 0.024) G_GAN: 0.665 G_L1: 4.697 D_real: 0.979 D_fake: 0.338 RMSE: 30.032 \n",
      "End of epoch 129 / 200 \t Time Taken: 58 sec\n",
      "learning rate 0.0001406 -> 0.0001386\n",
      "RMSE fake image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 1974.23, min: 0.00, mean: 67.97, std: 70.42\n",
      "RMSE real image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 1126.49, min: 0.00, mean: 68.68, std: 74.63\n",
      "(epoch: 130, iters: 500, time: 0.129, data: 2.205) G_GAN: 1.097 G_L1: 4.686 D_real: 0.472 D_fake: 0.535 RMSE: 30.915 \n",
      "RMSE fake image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 1443.74, min: 0.00, mean: 72.45, std: 74.48\n",
      "RMSE real image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 967.02, min: 0.00, mean: 77.81, std: 76.70\n",
      "(epoch: 130, iters: 1000, time: 0.128, data: 0.013) G_GAN: 1.189 G_L1: 5.562 D_real: 0.216 D_fake: 0.904 RMSE: 34.452 \n",
      "saving the latest model (epoch 130, total_iters 130000)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End of epoch 130 / 200 \t Time Taken: 67 sec\n",
      "learning rate 0.0001386 -> 0.0001366\n",
      "RMSE fake image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 1137.53, min: 0.00, mean: 49.34, std: 58.84\n",
      "RMSE real image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 2256.45, min: 0.00, mean: 47.49, std: 57.32\n",
      "(epoch: 131, iters: 500, time: 0.114, data: 2.038) G_GAN: 0.723 G_L1: 3.924 D_real: 1.008 D_fake: 0.410 RMSE: 26.472 \n",
      "RMSE fake image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 3127.75, min: 0.00, mean: 53.82, std: 65.39\n",
      "RMSE real image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 1857.64, min: 0.00, mean: 56.84, std: 69.18\n",
      "(epoch: 131, iters: 1000, time: 0.118, data: 0.039) G_GAN: 1.064 G_L1: 4.434 D_real: 0.505 D_fake: 0.524 RMSE: 31.805 \n",
      "End of epoch 131 / 200 \t Time Taken: 62 sec\n",
      "learning rate 0.0001366 -> 0.0001347\n",
      "RMSE fake image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 1356.22, min: 0.00, mean: 62.29, std: 72.49\n",
      "RMSE real image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 2170.76, min: 0.00, mean: 63.06, std: 76.86\n",
      "(epoch: 132, iters: 500, time: 0.130, data: 2.193) G_GAN: 1.382 G_L1: 4.764 D_real: 0.221 D_fake: 0.809 RMSE: 33.355 \n",
      "RMSE fake image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 1249.32, min: 0.00, mean: 46.11, std: 58.39\n",
      "RMSE real image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 6212.39, min: 0.00, mean: 44.83, std: 59.34\n",
      "(epoch: 132, iters: 1000, time: 0.118, data: 0.013) G_GAN: 0.922 G_L1: 3.816 D_real: 0.622 D_fake: 0.493 RMSE: 28.943 \n",
      "End of epoch 132 / 200 \t Time Taken: 57 sec\n",
      "learning rate 0.0001347 -> 0.0001327\n",
      "RMSE fake image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 1648.46, min: 0.00, mean: 63.15, std: 64.07\n",
      "RMSE real image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 814.07, min: 0.00, mean: 64.45, std: 64.64\n",
      "(epoch: 133, iters: 500, time: 0.120, data: 2.047) G_GAN: 1.145 G_L1: 4.619 D_real: 0.435 D_fake: 0.541 RMSE: 28.663 \n",
      "RMSE fake image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 1278.14, min: 0.00, mean: 62.10, std: 61.38\n",
      "RMSE real image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 1383.39, min: 0.00, mean: 56.98, std: 58.12\n",
      "(epoch: 133, iters: 1000, time: 0.119, data: 0.025) G_GAN: 0.748 G_L1: 4.343 D_real: 0.772 D_fake: 0.311 RMSE: 26.785 \n",
      "End of epoch 133 / 200 \t Time Taken: 56 sec\n",
      "learning rate 0.0001327 -> 0.0001307\n",
      "RMSE fake image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 9242.52, min: 0.00, mean: 55.47, std: 72.34\n",
      "RMSE real image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 2172.72, min: 0.00, mean: 56.27, std: 69.30\n",
      "(epoch: 134, iters: 500, time: 0.128, data: 2.062) G_GAN: 1.296 G_L1: 4.493 D_real: 0.298 D_fake: 1.050 RMSE: 40.604 \n",
      "RMSE fake image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 2379.46, min: 0.00, mean: 66.97, std: 73.26\n",
      "RMSE real image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 4718.91, min: 0.00, mean: 70.05, std: 78.83\n",
      "(epoch: 134, iters: 1000, time: 0.118, data: 0.060) G_GAN: 1.287 G_L1: 5.417 D_real: 0.110 D_fake: 1.605 RMSE: 38.489 \n",
      "End of epoch 134 / 200 \t Time Taken: 56 sec\n",
      "learning rate 0.0001307 -> 0.0001287\n",
      "RMSE fake image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 1441.47, min: 0.00, mean: 48.47, std: 66.79\n",
      "RMSE real image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 3201.03, min: 0.00, mean: 49.11, std: 68.71\n",
      "(epoch: 135, iters: 500, time: 0.145, data: 2.079) G_GAN: 1.221 G_L1: 3.841 D_real: 0.737 D_fake: 0.398 RMSE: 29.615 \n",
      "RMSE fake image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 3054.71, min: 0.00, mean: 64.27, std: 69.26\n",
      "RMSE real image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 7339.64, min: 0.00, mean: 63.58, std: 72.34\n",
      "(epoch: 135, iters: 1000, time: 0.119, data: 0.014) G_GAN: 1.222 G_L1: 5.024 D_real: 0.683 D_fake: 0.391 RMSE: 40.252 \n",
      "saving the latest model (epoch 135, total_iters 135000)\n",
      "End of epoch 135 / 200 \t Time Taken: 59 sec\n",
      "learning rate 0.0001287 -> 0.0001267\n",
      "RMSE fake image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 1878.75, min: 0.00, mean: 66.49, std: 67.37\n",
      "RMSE real image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 593.06, min: 0.00, mean: 62.80, std: 65.13\n",
      "(epoch: 136, iters: 500, time: 0.154, data: 2.163) G_GAN: 1.075 G_L1: 4.769 D_real: 0.405 D_fake: 0.754 RMSE: 30.294 \n",
      "RMSE fake image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 769.46, min: 0.00, mean: 66.24, std: 62.62\n",
      "RMSE real image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 796.62, min: 0.00, mean: 64.43, std: 61.12\n",
      "(epoch: 136, iters: 1000, time: 0.120, data: 0.036) G_GAN: 1.094 G_L1: 4.696 D_real: 0.445 D_fake: 0.562 RMSE: 28.615 \n",
      "End of epoch 136 / 200 \t Time Taken: 58 sec\n",
      "learning rate 0.0001267 -> 0.0001248\n",
      "RMSE fake image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 1449.37, min: 0.00, mean: 60.64, std: 66.44\n",
      "RMSE real image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 709.00, min: 0.00, mean: 65.39, std: 66.93\n",
      "(epoch: 137, iters: 500, time: 0.143, data: 2.164) G_GAN: 1.532 G_L1: 4.718 D_real: 0.542 D_fake: 0.518 RMSE: 29.567 \n",
      "RMSE fake image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 682.67, min: 0.00, mean: 71.26, std: 66.19\n",
      "RMSE real image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 2296.38, min: 0.00, mean: 71.29, std: 66.23\n",
      "(epoch: 137, iters: 1000, time: 0.131, data: 0.013) G_GAN: 1.084 G_L1: 5.350 D_real: 0.601 D_fake: 0.426 RMSE: 32.791 \n",
      "End of epoch 137 / 200 \t Time Taken: 56 sec\n",
      "learning rate 0.0001248 -> 0.0001228\n",
      "RMSE fake image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 3541.73, min: 0.00, mean: 63.61, std: 78.58\n",
      "RMSE real image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 3623.46, min: 0.00, mean: 63.99, std: 77.04\n",
      "(epoch: 138, iters: 500, time: 0.120, data: 2.078) G_GAN: 0.444 G_L1: 4.702 D_real: 1.160 D_fake: 0.331 RMSE: 34.887 \n",
      "RMSE fake image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 1440.71, min: 0.00, mean: 55.78, std: 60.43\n",
      "RMSE real image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 1024.05, min: 0.00, mean: 56.56, std: 62.31\n",
      "(epoch: 138, iters: 1000, time: 0.120, data: 0.028) G_GAN: 0.607 G_L1: 3.971 D_real: 1.023 D_fake: 0.238 RMSE: 25.621 \n",
      "End of epoch 138 / 200 \t Time Taken: 53 sec\n",
      "learning rate 0.0001228 -> 0.0001208\n",
      "RMSE fake image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 2025.90, min: 0.00, mean: 69.47, std: 67.62\n",
      "RMSE real image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 1254.59, min: 0.00, mean: 71.67, std: 71.63\n",
      "(epoch: 139, iters: 500, time: 0.133, data: 2.031) G_GAN: 1.552 G_L1: 4.789 D_real: 0.275 D_fake: 0.763 RMSE: 30.280 \n",
      "RMSE fake image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 4039.84, min: 0.00, mean: 71.50, std: 76.54\n",
      "RMSE real image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 5151.87, min: 0.00, mean: 73.19, std: 78.62\n",
      "(epoch: 139, iters: 1000, time: 0.132, data: 0.097) G_GAN: 1.406 G_L1: 5.652 D_real: 0.391 D_fake: 0.574 RMSE: 46.015 \n",
      "End of epoch 139 / 200 \t Time Taken: 56 sec\n",
      "learning rate 0.0001208 -> 0.0001188\n",
      "RMSE fake image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 1352.40, min: 0.00, mean: 45.69, std: 63.22\n",
      "RMSE real image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 600.42, min: 0.00, mean: 45.33, std: 64.73\n",
      "(epoch: 140, iters: 500, time: 0.110, data: 2.195) G_GAN: 1.590 G_L1: 3.427 D_real: 0.275 D_fake: 1.134 RMSE: 25.680 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE fake image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 973.23, min: 0.00, mean: 61.30, std: 62.38\n",
      "RMSE real image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 6551.64, min: 0.00, mean: 66.50, std: 69.21\n",
      "(epoch: 140, iters: 1000, time: 0.122, data: 0.011) G_GAN: 1.459 G_L1: 4.864 D_real: 0.319 D_fake: 0.570 RMSE: 35.243 \n",
      "saving the latest model (epoch 140, total_iters 140000)\n",
      "End of epoch 140 / 200 \t Time Taken: 59 sec\n",
      "learning rate 0.0001188 -> 0.0001168\n",
      "RMSE fake image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 1335.24, min: 0.00, mean: 54.32, std: 62.80\n",
      "RMSE real image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 1606.04, min: 0.00, mean: 54.49, std: 59.87\n",
      "(epoch: 141, iters: 500, time: 0.135, data: 2.090) G_GAN: 1.052 G_L1: 4.157 D_real: 0.656 D_fake: 0.426 RMSE: 27.397 \n",
      "RMSE fake image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 4243.09, min: 0.00, mean: 70.57, std: 72.59\n",
      "RMSE real image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 10450.77, min: 0.00, mean: 71.05, std: 78.78\n",
      "(epoch: 141, iters: 1000, time: 0.122, data: 0.113) G_GAN: 1.561 G_L1: 5.070 D_real: 0.276 D_fake: 0.854 RMSE: 39.351 \n",
      "End of epoch 141 / 200 \t Time Taken: 60 sec\n",
      "learning rate 0.0001168 -> 0.0001149\n",
      "RMSE fake image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 3242.81, min: 0.00, mean: 47.61, std: 59.42\n",
      "RMSE real image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 525.53, min: 0.00, mean: 43.37, std: 52.22\n",
      "(epoch: 142, iters: 500, time: 0.141, data: 2.158) G_GAN: 0.818 G_L1: 4.053 D_real: 1.061 D_fake: 0.364 RMSE: 28.220 \n",
      "RMSE fake image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 8405.99, min: 0.00, mean: 47.11, std: 69.52\n",
      "RMSE real image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 2070.09, min: 0.00, mean: 47.13, std: 62.97\n",
      "(epoch: 142, iters: 1000, time: 0.131, data: 0.091) G_GAN: 0.799 G_L1: 3.994 D_real: 0.623 D_fake: 0.821 RMSE: 42.984 \n",
      "End of epoch 142 / 200 \t Time Taken: 54 sec\n",
      "learning rate 0.0001149 -> 0.0001129\n",
      "RMSE fake image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 912.14, min: 0.00, mean: 59.93, std: 63.47\n",
      "RMSE real image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 1765.93, min: 0.00, mean: 61.21, std: 65.49\n",
      "(epoch: 143, iters: 500, time: 0.133, data: 2.108) G_GAN: 1.150 G_L1: 4.194 D_real: 0.480 D_fake: 0.539 RMSE: 27.847 \n",
      "RMSE fake image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 713.33, min: 0.00, mean: 62.14, std: 62.01\n",
      "RMSE real image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 1813.82, min: 0.00, mean: 63.38, std: 64.20\n",
      "(epoch: 143, iters: 1000, time: 0.124, data: 0.009) G_GAN: 1.045 G_L1: 4.810 D_real: 0.342 D_fake: 0.731 RMSE: 29.528 \n",
      "End of epoch 143 / 200 \t Time Taken: 57 sec\n",
      "learning rate 0.0001129 -> 0.0001109\n",
      "RMSE fake image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 1610.68, min: 0.00, mean: 74.47, std: 72.43\n",
      "RMSE real image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 1330.72, min: 0.00, mean: 77.92, std: 75.48\n",
      "(epoch: 144, iters: 500, time: 0.149, data: 2.220) G_GAN: 1.172 G_L1: 5.450 D_real: 0.582 D_fake: 0.516 RMSE: 33.393 \n",
      "RMSE fake image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 1265.71, min: 0.00, mean: 45.42, std: 64.03\n",
      "RMSE real image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 938.40, min: 0.00, mean: 45.21, std: 64.87\n",
      "(epoch: 144, iters: 1000, time: 0.133, data: 0.012) G_GAN: 0.550 G_L1: 3.509 D_real: 1.005 D_fake: 0.311 RMSE: 26.297 \n",
      "End of epoch 144 / 200 \t Time Taken: 55 sec\n",
      "learning rate 0.0001109 -> 0.0001089\n",
      "RMSE fake image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 2468.94, min: 0.00, mean: 58.42, std: 70.59\n",
      "RMSE real image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 4718.91, min: 0.00, mean: 58.72, std: 73.70\n",
      "(epoch: 145, iters: 500, time: 0.147, data: 2.406) G_GAN: 0.952 G_L1: 4.346 D_real: 0.469 D_fake: 0.494 RMSE: 32.852 \n",
      "RMSE fake image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 1679.81, min: 0.00, mean: 53.14, std: 68.06\n",
      "RMSE real image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 2003.40, min: 0.00, mean: 53.81, std: 69.26\n",
      "(epoch: 145, iters: 1000, time: 0.125, data: 0.063) G_GAN: 0.980 G_L1: 4.251 D_real: 0.531 D_fake: 0.541 RMSE: 29.902 \n",
      "saving the latest model (epoch 145, total_iters 145000)\n",
      "End of epoch 145 / 200 \t Time Taken: 63 sec\n",
      "learning rate 0.0001089 -> 0.0001069\n",
      "RMSE fake image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 1404.87, min: 0.00, mean: 47.98, std: 59.98\n",
      "RMSE real image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 1328.50, min: 0.00, mean: 48.43, std: 60.25\n",
      "(epoch: 146, iters: 500, time: 0.155, data: 2.040) G_GAN: 0.787 G_L1: 3.586 D_real: 0.835 D_fake: 0.432 RMSE: 24.754 \n",
      "RMSE fake image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 1042.68, min: 0.00, mean: 56.96, std: 63.36\n",
      "RMSE real image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 1103.42, min: 0.00, mean: 53.87, std: 59.90\n",
      "(epoch: 146, iters: 1000, time: 0.108, data: 0.024) G_GAN: 0.914 G_L1: 4.329 D_real: 0.344 D_fake: 0.875 RMSE: 27.570 \n",
      "End of epoch 146 / 200 \t Time Taken: 57 sec\n",
      "learning rate 0.0001069 -> 0.0001050\n",
      "RMSE fake image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 2244.19, min: 0.00, mean: 54.43, std: 65.90\n",
      "RMSE real image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 517.81, min: 0.00, mean: 57.55, std: 67.89\n",
      "(epoch: 147, iters: 500, time: 0.120, data: 2.019) G_GAN: 0.922 G_L1: 4.044 D_real: 0.547 D_fake: 0.531 RMSE: 27.578 \n",
      "RMSE fake image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 1493.44, min: 0.00, mean: 64.39, std: 68.85\n",
      "RMSE real image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 1847.24, min: 0.00, mean: 67.12, std: 71.05\n",
      "(epoch: 147, iters: 1000, time: 0.134, data: 0.013) G_GAN: 1.197 G_L1: 4.556 D_real: 0.421 D_fake: 0.587 RMSE: 30.221 \n",
      "End of epoch 147 / 200 \t Time Taken: 57 sec\n",
      "learning rate 0.0001050 -> 0.0001030\n",
      "RMSE fake image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 2067.20, min: 0.00, mean: 65.20, std: 70.40\n",
      "RMSE real image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 974.91, min: 0.00, mean: 64.94, std: 73.09\n",
      "(epoch: 148, iters: 500, time: 0.141, data: 2.162) G_GAN: 1.260 G_L1: 4.387 D_real: 0.998 D_fake: 0.319 RMSE: 28.939 \n",
      "RMSE fake image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 4439.60, min: 0.00, mean: 63.89, std: 63.46\n",
      "RMSE real image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 3400.48, min: 0.00, mean: 62.27, std: 63.07\n",
      "(epoch: 148, iters: 1000, time: 0.125, data: 0.056) G_GAN: 0.975 G_L1: 4.206 D_real: 0.361 D_fake: 0.881 RMSE: 28.369 \n",
      "End of epoch 148 / 200 \t Time Taken: 58 sec\n",
      "learning rate 0.0001030 -> 0.0001010\n",
      "RMSE fake image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 5106.88, min: 0.00, mean: 61.69, std: 69.44\n",
      "RMSE real image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 6078.89, min: 0.00, mean: 63.79, std: 73.18\n",
      "(epoch: 149, iters: 500, time: 0.160, data: 1.968) G_GAN: 0.926 G_L1: 4.374 D_real: 0.635 D_fake: 0.425 RMSE: 28.846 \n",
      "RMSE fake image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 3027.27, min: 0.00, mean: 71.82, std: 69.69\n",
      "RMSE real image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 4753.29, min: 0.00, mean: 72.49, std: 74.91\n",
      "(epoch: 149, iters: 1000, time: 0.121, data: 0.012) G_GAN: 1.469 G_L1: 5.242 D_real: 0.244 D_fake: 0.786 RMSE: 35.905 \n",
      "End of epoch 149 / 200 \t Time Taken: 56 sec\n",
      "learning rate 0.0001010 -> 0.0000990\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE fake image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 1648.08, min: 0.00, mean: 61.95, std: 65.22\n",
      "RMSE real image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 1597.18, min: 0.00, mean: 63.03, std: 67.14\n",
      "(epoch: 150, iters: 500, time: 0.139, data: 1.992) G_GAN: 0.926 G_L1: 4.301 D_real: 0.483 D_fake: 0.594 RMSE: 28.252 \n",
      "RMSE fake image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 3642.22, min: 0.00, mean: 53.23, std: 59.97\n",
      "RMSE real image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 1091.48, min: 0.00, mean: 51.67, std: 58.19\n",
      "(epoch: 150, iters: 1000, time: 0.121, data: 0.010) G_GAN: 0.803 G_L1: 4.009 D_real: 0.644 D_fake: 0.420 RMSE: 26.961 \n",
      "saving the latest model (epoch 150, total_iters 150000)\n",
      "End of epoch 150 / 200 \t Time Taken: 58 sec\n",
      "learning rate 0.0000990 -> 0.0000970\n",
      "RMSE fake image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 3222.59, min: 0.00, mean: 68.11, std: 66.08\n",
      "RMSE real image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 1130.92, min: 0.00, mean: 69.21, std: 66.64\n",
      "(epoch: 151, iters: 500, time: 0.162, data: 2.195) G_GAN: 0.905 G_L1: 4.730 D_real: 0.501 D_fake: 0.548 RMSE: 29.311 \n",
      "RMSE fake image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 5302.08, min: 0.00, mean: 51.73, std: 74.10\n",
      "RMSE real image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 2577.69, min: 0.00, mean: 53.51, std: 72.76\n",
      "(epoch: 151, iters: 1000, time: 0.118, data: 0.052) G_GAN: 0.948 G_L1: 4.338 D_real: 0.632 D_fake: 0.684 RMSE: 39.625 \n",
      "End of epoch 151 / 200 \t Time Taken: 55 sec\n",
      "learning rate 0.0000970 -> 0.0000950\n",
      "RMSE fake image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 2773.41, min: 0.00, mean: 51.39, std: 58.52\n",
      "RMSE real image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 4207.71, min: 0.00, mean: 53.11, std: 59.33\n",
      "(epoch: 152, iters: 500, time: 0.152, data: 2.198) G_GAN: 1.007 G_L1: 3.729 D_real: 0.548 D_fake: 0.582 RMSE: 26.574 \n",
      "RMSE fake image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 4454.79, min: 0.00, mean: 43.14, std: 60.09\n",
      "RMSE real image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 1765.93, min: 0.00, mean: 38.30, std: 54.30\n",
      "(epoch: 152, iters: 1000, time: 0.132, data: 0.012) G_GAN: 0.708 G_L1: 3.878 D_real: 1.286 D_fake: 0.253 RMSE: 31.732 \n",
      "End of epoch 152 / 200 \t Time Taken: 56 sec\n",
      "learning rate 0.0000950 -> 0.0000931\n",
      "RMSE fake image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 3556.52, min: 0.00, mean: 72.75, std: 69.45\n",
      "RMSE real image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 1677.23, min: 0.00, mean: 74.81, std: 69.35\n",
      "(epoch: 153, iters: 500, time: 0.138, data: 2.209) G_GAN: 1.114 G_L1: 4.955 D_real: 0.428 D_fake: 0.635 RMSE: 30.826 \n",
      "RMSE fake image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 5228.24, min: 0.00, mean: 55.48, std: 60.33\n",
      "RMSE real image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 6078.89, min: 0.00, mean: 52.01, std: 57.90\n",
      "(epoch: 153, iters: 1000, time: 0.123, data: 0.012) G_GAN: 0.702 G_L1: 3.923 D_real: 0.834 D_fake: 0.336 RMSE: 25.634 \n",
      "End of epoch 153 / 200 \t Time Taken: 57 sec\n",
      "learning rate 0.0000931 -> 0.0000911\n",
      "RMSE fake image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 1138.64, min: 0.00, mean: 59.43, std: 59.92\n",
      "RMSE real image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 2178.84, min: 0.00, mean: 59.52, std: 58.05\n",
      "(epoch: 154, iters: 500, time: 0.142, data: 2.129) G_GAN: 1.104 G_L1: 4.333 D_real: 0.551 D_fake: 0.473 RMSE: 27.732 \n",
      "RMSE fake image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 4643.34, min: 0.00, mean: 61.31, std: 70.67\n",
      "RMSE real image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 846.87, min: 0.00, mean: 61.54, std: 69.86\n",
      "(epoch: 154, iters: 1000, time: 0.093, data: 0.013) G_GAN: 1.011 G_L1: 4.267 D_real: 0.568 D_fake: 0.591 RMSE: 30.351 \n",
      "End of epoch 154 / 200 \t Time Taken: 53 sec\n",
      "learning rate 0.0000911 -> 0.0000891\n",
      "RMSE fake image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 1026.40, min: 0.00, mean: 56.39, std: 65.09\n",
      "RMSE real image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 966.59, min: 0.00, mean: 57.51, std: 64.09\n",
      "(epoch: 155, iters: 500, time: 0.146, data: 2.165) G_GAN: 1.235 G_L1: 4.091 D_real: 0.354 D_fake: 0.634 RMSE: 26.503 \n",
      "RMSE fake image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 953.51, min: 0.00, mean: 56.54, std: 67.59\n",
      "RMSE real image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 1328.50, min: 0.00, mean: 55.91, std: 67.41\n",
      "(epoch: 155, iters: 1000, time: 0.135, data: 0.017) G_GAN: 0.849 G_L1: 3.927 D_real: 0.522 D_fake: 0.602 RMSE: 26.285 \n",
      "saving the latest model (epoch 155, total_iters 155000)\n",
      "End of epoch 155 / 200 \t Time Taken: 57 sec\n",
      "learning rate 0.0000891 -> 0.0000871\n",
      "RMSE fake image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 2957.01, min: 0.00, mean: 59.37, std: 64.34\n",
      "RMSE real image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 1428.65, min: 0.00, mean: 57.29, std: 63.33\n",
      "(epoch: 156, iters: 500, time: 0.144, data: 2.178) G_GAN: 1.093 G_L1: 4.343 D_real: 0.732 D_fake: 0.361 RMSE: 28.189 \n",
      "RMSE fake image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 1998.59, min: 0.00, mean: 60.65, std: 62.99\n",
      "RMSE real image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 2003.40, min: 0.00, mean: 60.88, std: 63.34\n",
      "(epoch: 156, iters: 1000, time: 0.129, data: 0.025) G_GAN: 0.951 G_L1: 4.357 D_real: 0.593 D_fake: 0.550 RMSE: 28.830 \n",
      "End of epoch 156 / 200 \t Time Taken: 55 sec\n",
      "learning rate 0.0000871 -> 0.0000851\n",
      "RMSE fake image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 1008.29, min: 0.00, mean: 52.97, std: 60.50\n",
      "RMSE real image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 1476.08, min: 0.00, mean: 51.72, std: 58.24\n",
      "(epoch: 157, iters: 500, time: 0.164, data: 2.096) G_GAN: 0.730 G_L1: 3.724 D_real: 1.028 D_fake: 0.318 RMSE: 25.202 \n",
      "RMSE fake image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 2497.40, min: 0.00, mean: 71.65, std: 66.55\n",
      "RMSE real image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 1154.85, min: 0.00, mean: 71.80, std: 65.03\n",
      "(epoch: 157, iters: 1000, time: 0.130, data: 0.012) G_GAN: 1.039 G_L1: 4.858 D_real: 0.633 D_fake: 0.501 RMSE: 29.422 \n",
      "End of epoch 157 / 200 \t Time Taken: 56 sec\n",
      "learning rate 0.0000851 -> 0.0000832\n",
      "RMSE fake image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 1640.12, min: 0.00, mean: 68.35, std: 67.07\n",
      "RMSE real image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 812.34, min: 0.00, mean: 67.98, std: 66.47\n",
      "(epoch: 158, iters: 500, time: 0.139, data: 2.251) G_GAN: 1.016 G_L1: 4.646 D_real: 0.505 D_fake: 0.655 RMSE: 29.176 \n",
      "RMSE fake image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 5767.04, min: 0.00, mean: 68.43, std: 75.05\n",
      "RMSE real image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 2172.72, min: 0.00, mean: 72.32, std: 79.22\n",
      "(epoch: 158, iters: 1000, time: 0.138, data: 0.013) G_GAN: 1.376 G_L1: 5.658 D_real: 0.465 D_fake: 0.452 RMSE: 40.538 \n",
      "End of epoch 158 / 200 \t Time Taken: 57 sec\n",
      "learning rate 0.0000832 -> 0.0000812\n",
      "RMSE fake image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 835.66, min: 0.00, mean: 40.63, std: 59.35\n",
      "RMSE real image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 1240.27, min: 0.00, mean: 40.70, std: 58.15\n",
      "(epoch: 159, iters: 500, time: 0.153, data: 2.226) G_GAN: 0.467 G_L1: 3.061 D_real: 0.903 D_fake: 0.620 RMSE: 23.970 \n",
      "RMSE fake image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 2673.62, min: 0.00, mean: 59.63, std: 64.32\n",
      "RMSE real image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 1296.42, min: 0.00, mean: 58.18, std: 63.67\n",
      "(epoch: 159, iters: 1000, time: 0.130, data: 0.022) G_GAN: 0.924 G_L1: 4.195 D_real: 0.755 D_fake: 0.417 RMSE: 27.848 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End of epoch 159 / 200 \t Time Taken: 56 sec\n",
      "learning rate 0.0000812 -> 0.0000792\n",
      "RMSE fake image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 1128.43, min: 0.00, mean: 63.81, std: 68.63\n",
      "RMSE real image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 1247.29, min: 0.00, mean: 67.74, std: 73.00\n",
      "(epoch: 160, iters: 500, time: 0.157, data: 2.060) G_GAN: 0.775 G_L1: 4.616 D_real: 1.004 D_fake: 0.314 RMSE: 29.700 \n",
      "RMSE fake image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 1161.55, min: 0.00, mean: 59.12, std: 70.50\n",
      "RMSE real image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 1848.90, min: 0.00, mean: 61.89, std: 72.49\n",
      "(epoch: 160, iters: 1000, time: 0.130, data: 0.012) G_GAN: 1.291 G_L1: 3.923 D_real: 0.362 D_fake: 0.719 RMSE: 27.858 \n",
      "saving the latest model (epoch 160, total_iters 160000)\n",
      "End of epoch 160 / 200 \t Time Taken: 59 sec\n",
      "learning rate 0.0000792 -> 0.0000772\n",
      "RMSE fake image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 3892.77, min: 0.00, mean: 65.39, std: 78.88\n",
      "RMSE real image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 2577.69, min: 0.00, mean: 65.95, std: 77.47\n",
      "(epoch: 161, iters: 500, time: 0.140, data: 1.960) G_GAN: 0.902 G_L1: 4.882 D_real: 0.632 D_fake: 0.533 RMSE: 37.865 \n",
      "RMSE fake image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 736.14, min: 0.00, mean: 70.50, std: 74.69\n",
      "RMSE real image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 610.49, min: 0.00, mean: 70.91, std: 75.34\n",
      "(epoch: 161, iters: 1000, time: 0.137, data: 0.012) G_GAN: 1.037 G_L1: 4.690 D_real: 0.386 D_fake: 0.727 RMSE: 30.644 \n",
      "End of epoch 161 / 200 \t Time Taken: 62 sec\n",
      "learning rate 0.0000772 -> 0.0000752\n",
      "RMSE fake image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 1574.05, min: 0.00, mean: 64.36, std: 70.75\n",
      "RMSE real image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 1780.63, min: 0.00, mean: 65.83, std: 71.89\n",
      "(epoch: 162, iters: 500, time: 0.151, data: 2.911) G_GAN: 1.095 G_L1: 4.321 D_real: 0.451 D_fake: 0.763 RMSE: 28.563 \n",
      "RMSE fake image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 7878.10, min: 0.00, mean: 62.10, std: 70.14\n",
      "RMSE real image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 4858.87, min: 0.00, mean: 63.15, std: 70.72\n",
      "(epoch: 162, iters: 1000, time: 0.128, data: 0.011) G_GAN: 0.992 G_L1: 4.354 D_real: 0.636 D_fake: 0.442 RMSE: 39.940 \n",
      "End of epoch 162 / 200 \t Time Taken: 57 sec\n",
      "learning rate 0.0000752 -> 0.0000733\n",
      "RMSE fake image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 4380.77, min: 0.00, mean: 60.40, std: 73.02\n",
      "RMSE real image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 1591.30, min: 0.00, mean: 60.01, std: 70.90\n",
      "(epoch: 163, iters: 500, time: 0.160, data: 1.938) G_GAN: 0.781 G_L1: 3.988 D_real: 0.875 D_fake: 0.413 RMSE: 28.639 \n",
      "RMSE fake image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 1417.59, min: 0.00, mean: 62.34, std: 65.23\n",
      "RMSE real image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 2293.96, min: 0.00, mean: 63.02, std: 66.48\n",
      "(epoch: 163, iters: 1000, time: 0.128, data: 0.013) G_GAN: 0.915 G_L1: 4.241 D_real: 0.679 D_fake: 0.443 RMSE: 27.762 \n",
      "End of epoch 163 / 200 \t Time Taken: 55 sec\n",
      "learning rate 0.0000733 -> 0.0000713\n",
      "RMSE fake image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 2266.69, min: 0.00, mean: 56.49, std: 67.11\n",
      "RMSE real image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 1650.92, min: 0.00, mean: 54.26, std: 65.42\n",
      "(epoch: 164, iters: 500, time: 0.143, data: 2.130) G_GAN: 0.754 G_L1: 3.952 D_real: 0.508 D_fake: 0.570 RMSE: 27.435 \n",
      "RMSE fake image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 2573.18, min: 0.00, mean: 66.47, std: 74.37\n",
      "RMSE real image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 1654.40, min: 0.00, mean: 68.00, std: 77.68\n",
      "(epoch: 164, iters: 1000, time: 0.111, data: 0.013) G_GAN: 1.033 G_L1: 4.640 D_real: 0.571 D_fake: 0.602 RMSE: 31.894 \n",
      "End of epoch 164 / 200 \t Time Taken: 54 sec\n",
      "learning rate 0.0000713 -> 0.0000693\n",
      "RMSE fake image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 780.21, min: 0.00, mean: 58.61, std: 61.44\n",
      "RMSE real image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 3623.46, min: 0.00, mean: 58.55, std: 62.70\n",
      "(epoch: 165, iters: 500, time: 0.159, data: 2.098) G_GAN: 1.103 G_L1: 4.196 D_real: 0.480 D_fake: 0.493 RMSE: 27.593 \n",
      "RMSE fake image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 2947.81, min: 0.00, mean: 50.39, std: 63.49\n",
      "RMSE real image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 548.22, min: 0.00, mean: 49.41, std: 64.42\n",
      "(epoch: 165, iters: 1000, time: 0.128, data: 0.012) G_GAN: 0.865 G_L1: 3.775 D_real: 0.876 D_fake: 0.326 RMSE: 25.910 \n",
      "saving the latest model (epoch 165, total_iters 165000)\n",
      "End of epoch 165 / 200 \t Time Taken: 57 sec\n",
      "learning rate 0.0000693 -> 0.0000673\n",
      "RMSE fake image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 1798.61, min: 0.00, mean: 54.47, std: 64.87\n",
      "RMSE real image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 868.49, min: 0.00, mean: 56.57, std: 67.38\n",
      "(epoch: 166, iters: 500, time: 0.168, data: 2.227) G_GAN: 1.026 G_L1: 3.902 D_real: 0.451 D_fake: 0.697 RMSE: 27.100 \n",
      "RMSE fake image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 1975.94, min: 0.00, mean: 61.84, std: 61.50\n",
      "RMSE real image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 1857.64, min: 0.00, mean: 60.35, std: 58.99\n",
      "(epoch: 166, iters: 1000, time: 0.130, data: 0.013) G_GAN: 0.974 G_L1: 4.604 D_real: 0.632 D_fake: 0.376 RMSE: 29.068 \n",
      "End of epoch 166 / 200 \t Time Taken: 57 sec\n",
      "learning rate 0.0000673 -> 0.0000653\n",
      "RMSE fake image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 2934.26, min: 0.00, mean: 57.75, std: 64.49\n",
      "RMSE real image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 1677.23, min: 0.00, mean: 58.15, std: 64.47\n",
      "(epoch: 167, iters: 500, time: 0.148, data: 1.941) G_GAN: 0.724 G_L1: 4.215 D_real: 0.526 D_fake: 0.631 RMSE: 28.382 \n",
      "RMSE fake image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 1649.60, min: 0.00, mean: 54.49, std: 61.53\n",
      "RMSE real image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 3623.46, min: 0.00, mean: 53.42, std: 60.57\n",
      "(epoch: 167, iters: 1000, time: 0.139, data: 0.036) G_GAN: 0.755 G_L1: 3.846 D_real: 0.767 D_fake: 0.454 RMSE: 27.578 \n",
      "End of epoch 167 / 200 \t Time Taken: 54 sec\n",
      "learning rate 0.0000653 -> 0.0000634\n",
      "RMSE fake image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 1400.57, min: 0.00, mean: 71.23, std: 70.65\n",
      "RMSE real image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 738.57, min: 0.00, mean: 69.42, std: 67.82\n",
      "(epoch: 168, iters: 500, time: 0.139, data: 2.100) G_GAN: 0.825 G_L1: 4.517 D_real: 0.651 D_fake: 0.455 RMSE: 28.625 \n",
      "RMSE fake image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 1192.45, min: 0.00, mean: 57.77, std: 67.32\n",
      "RMSE real image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 2293.96, min: 0.00, mean: 58.44, std: 68.24\n",
      "(epoch: 168, iters: 1000, time: 0.129, data: 0.013) G_GAN: 0.599 G_L1: 3.962 D_real: 1.153 D_fake: 0.247 RMSE: 26.943 \n",
      "End of epoch 168 / 200 \t Time Taken: 54 sec\n",
      "learning rate 0.0000634 -> 0.0000614\n",
      "RMSE fake image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 2701.62, min: 0.00, mean: 67.63, std: 66.15\n",
      "RMSE real image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 2146.95, min: 0.00, mean: 67.27, std: 65.70\n",
      "(epoch: 169, iters: 500, time: 0.150, data: 2.188) G_GAN: 1.018 G_L1: 4.480 D_real: 0.378 D_fake: 0.698 RMSE: 28.714 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE fake image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 5244.09, min: 0.00, mean: 53.40, std: 66.46\n",
      "RMSE real image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 6078.89, min: 0.00, mean: 54.16, std: 70.64\n",
      "(epoch: 169, iters: 1000, time: 0.132, data: 0.013) G_GAN: 1.346 G_L1: 3.847 D_real: 0.507 D_fake: 0.522 RMSE: 32.404 \n",
      "End of epoch 169 / 200 \t Time Taken: 56 sec\n",
      "learning rate 0.0000614 -> 0.0000594\n",
      "RMSE fake image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 1303.55, min: 0.00, mean: 53.46, std: 66.16\n",
      "RMSE real image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 1871.07, min: 0.00, mean: 52.17, std: 63.77\n",
      "(epoch: 170, iters: 500, time: 0.151, data: 2.117) G_GAN: 0.860 G_L1: 3.852 D_real: 0.414 D_fake: 0.777 RMSE: 26.524 \n",
      "RMSE fake image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 8421.65, min: 0.00, mean: 65.75, std: 72.37\n",
      "RMSE real image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 5311.07, min: 0.00, mean: 62.06, std: 71.03\n",
      "(epoch: 170, iters: 1000, time: 0.131, data: 0.013) G_GAN: 0.867 G_L1: 4.636 D_real: 0.517 D_fake: 0.528 RMSE: 40.935 \n",
      "saving the latest model (epoch 170, total_iters 170000)\n",
      "End of epoch 170 / 200 \t Time Taken: 55 sec\n",
      "learning rate 0.0000594 -> 0.0000574\n",
      "RMSE fake image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 1404.31, min: 0.00, mean: 45.04, std: 60.74\n",
      "RMSE real image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 2170.76, min: 0.00, mean: 45.63, std: 60.47\n",
      "(epoch: 171, iters: 500, time: 0.131, data: 1.954) G_GAN: 0.981 G_L1: 3.436 D_real: 0.610 D_fake: 0.516 RMSE: 25.136 \n",
      "RMSE fake image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 3921.93, min: 0.00, mean: 73.94, std: 71.44\n",
      "RMSE real image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 4753.29, min: 0.00, mean: 75.44, std: 75.69\n",
      "(epoch: 171, iters: 1000, time: 0.144, data: 0.011) G_GAN: 1.238 G_L1: 5.056 D_real: 0.384 D_fake: 0.677 RMSE: 32.769 \n",
      "End of epoch 171 / 200 \t Time Taken: 56 sec\n",
      "learning rate 0.0000574 -> 0.0000554\n",
      "RMSE fake image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 945.38, min: 0.00, mean: 63.14, std: 62.80\n",
      "RMSE real image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 1742.75, min: 0.00, mean: 62.57, std: 62.46\n",
      "(epoch: 172, iters: 500, time: 0.157, data: 2.223) G_GAN: 1.097 G_L1: 4.313 D_real: 0.728 D_fake: 0.364 RMSE: 27.045 \n",
      "RMSE fake image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 2913.92, min: 0.00, mean: 61.65, std: 68.23\n",
      "RMSE real image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 1567.69, min: 0.00, mean: 59.98, std: 67.67\n",
      "(epoch: 172, iters: 1000, time: 0.131, data: 0.043) G_GAN: 0.949 G_L1: 4.175 D_real: 0.678 D_fake: 0.507 RMSE: 27.828 \n",
      "End of epoch 172 / 200 \t Time Taken: 56 sec\n",
      "learning rate 0.0000554 -> 0.0000535\n",
      "RMSE fake image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 1209.51, min: 0.00, mean: 48.29, std: 62.76\n",
      "RMSE real image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 2170.76, min: 0.00, mean: 49.51, std: 65.42\n",
      "(epoch: 173, iters: 500, time: 0.184, data: 2.085) G_GAN: 0.836 G_L1: 3.561 D_real: 0.579 D_fake: 0.574 RMSE: 26.630 \n",
      "RMSE fake image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 801.41, min: 0.00, mean: 51.70, std: 67.40\n",
      "RMSE real image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 3225.43, min: 0.00, mean: 53.06, std: 69.75\n",
      "(epoch: 173, iters: 1000, time: 0.133, data: 0.012) G_GAN: 0.945 G_L1: 3.968 D_real: 0.496 D_fake: 0.654 RMSE: 28.899 \n",
      "End of epoch 173 / 200 \t Time Taken: 56 sec\n",
      "learning rate 0.0000535 -> 0.0000515\n",
      "RMSE fake image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 3637.19, min: 0.00, mean: 46.75, std: 59.70\n",
      "RMSE real image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 3233.36, min: 0.00, mean: 44.68, std: 58.22\n",
      "(epoch: 174, iters: 500, time: 0.155, data: 2.169) G_GAN: 0.772 G_L1: 3.701 D_real: 0.756 D_fake: 0.413 RMSE: 27.663 \n",
      "RMSE fake image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 2024.91, min: 0.00, mean: 55.30, std: 63.73\n",
      "RMSE real image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 3201.03, min: 0.00, mean: 56.17, std: 65.47\n",
      "(epoch: 174, iters: 1000, time: 0.143, data: 0.013) G_GAN: 0.940 G_L1: 4.278 D_real: 0.785 D_fake: 0.324 RMSE: 29.828 \n",
      "End of epoch 174 / 200 \t Time Taken: 56 sec\n",
      "learning rate 0.0000515 -> 0.0000495\n",
      "RMSE fake image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 4590.12, min: 0.00, mean: 57.11, std: 74.45\n",
      "RMSE real image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 5151.87, min: 0.00, mean: 57.87, std: 77.05\n",
      "(epoch: 175, iters: 500, time: 0.156, data: 2.122) G_GAN: 0.894 G_L1: 4.271 D_real: 0.394 D_fake: 0.783 RMSE: 42.120 \n",
      "RMSE fake image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 6630.04, min: 0.00, mean: 66.21, std: 80.97\n",
      "RMSE real image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 2070.09, min: 0.00, mean: 67.16, std: 78.45\n",
      "(epoch: 175, iters: 1000, time: 0.133, data: 0.051) G_GAN: 0.723 G_L1: 4.667 D_real: 0.840 D_fake: 0.398 RMSE: 40.577 \n",
      "saving the latest model (epoch 175, total_iters 175000)\n",
      "End of epoch 175 / 200 \t Time Taken: 57 sec\n",
      "learning rate 0.0000495 -> 0.0000475\n",
      "RMSE fake image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 1810.06, min: 0.00, mean: 59.44, std: 68.34\n",
      "RMSE real image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 3153.37, min: 0.00, mean: 60.32, std: 70.21\n",
      "(epoch: 176, iters: 500, time: 0.146, data: 2.343) G_GAN: 1.046 G_L1: 4.225 D_real: 0.371 D_fake: 0.743 RMSE: 30.815 \n",
      "RMSE fake image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 4403.65, min: 0.00, mean: 50.58, std: 62.85\n",
      "RMSE real image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 612.18, min: 0.00, mean: 52.16, std: 64.56\n",
      "(epoch: 176, iters: 1000, time: 0.129, data: 0.083) G_GAN: 0.994 G_L1: 3.733 D_real: 0.476 D_fake: 0.623 RMSE: 26.901 \n",
      "End of epoch 176 / 200 \t Time Taken: 55 sec\n",
      "learning rate 0.0000475 -> 0.0000455\n",
      "RMSE fake image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 5359.22, min: 0.00, mean: 60.49, std: 84.44\n",
      "RMSE real image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 2253.89, min: 0.00, mean: 56.38, std: 74.42\n",
      "(epoch: 177, iters: 500, time: 0.151, data: 2.123) G_GAN: 0.843 G_L1: 4.917 D_real: 0.579 D_fake: 0.790 RMSE: 42.339 \n",
      "RMSE fake image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 1056.62, min: 0.00, mean: 73.24, std: 63.43\n",
      "RMSE real image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 1709.82, min: 0.00, mean: 72.42, std: 64.04\n",
      "(epoch: 177, iters: 1000, time: 0.137, data: 0.092) G_GAN: 1.144 G_L1: 4.859 D_real: 0.450 D_fake: 0.421 RMSE: 30.095 \n",
      "End of epoch 177 / 200 \t Time Taken: 54 sec\n",
      "learning rate 0.0000455 -> 0.0000436\n",
      "RMSE fake image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 2298.15, min: 0.00, mean: 61.49, std: 64.46\n",
      "RMSE real image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 5004.70, min: 0.00, mean: 62.80, std: 68.46\n",
      "(epoch: 178, iters: 500, time: 0.153, data: 2.198) G_GAN: 1.009 G_L1: 4.161 D_real: 0.630 D_fake: 0.437 RMSE: 32.999 \n",
      "RMSE fake image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 1495.32, min: 0.00, mean: 62.37, std: 66.92\n",
      "RMSE real image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 661.43, min: 0.00, mean: 62.71, std: 66.45\n",
      "(epoch: 178, iters: 1000, time: 0.145, data: 0.013) G_GAN: 1.333 G_L1: 4.340 D_real: 0.301 D_fake: 0.671 RMSE: 28.435 \n",
      "End of epoch 178 / 200 \t Time Taken: 55 sec\n",
      "learning rate 0.0000436 -> 0.0000416\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE fake image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 544.06, min: 0.00, mean: 56.20, std: 54.54\n",
      "RMSE real image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 537.40, min: 0.00, mean: 55.64, std: 52.94\n",
      "(epoch: 179, iters: 500, time: 0.156, data: 2.105) G_GAN: 1.092 G_L1: 3.944 D_real: 0.591 D_fake: 0.392 RMSE: 24.038 \n",
      "RMSE fake image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 1928.56, min: 0.00, mean: 73.71, std: 68.85\n",
      "RMSE real image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 974.91, min: 0.00, mean: 73.03, std: 68.71\n",
      "(epoch: 179, iters: 1000, time: 0.131, data: 0.016) G_GAN: 0.921 G_L1: 4.794 D_real: 0.405 D_fake: 0.590 RMSE: 30.278 \n",
      "End of epoch 179 / 200 \t Time Taken: 53 sec\n",
      "learning rate 0.0000416 -> 0.0000396\n",
      "RMSE fake image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 2819.04, min: 0.00, mean: 52.19, std: 54.65\n",
      "RMSE real image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 6551.64, min: 0.00, mean: 50.82, std: 56.20\n",
      "(epoch: 180, iters: 500, time: 0.173, data: 1.988) G_GAN: 1.140 G_L1: 4.065 D_real: 0.408 D_fake: 0.562 RMSE: 31.101 \n",
      "RMSE fake image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 855.25, min: 0.00, mean: 71.17, std: 64.88\n",
      "RMSE real image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 623.07, min: 0.00, mean: 76.99, std: 66.00\n",
      "(epoch: 180, iters: 1000, time: 0.135, data: 0.012) G_GAN: 1.045 G_L1: 5.277 D_real: 0.238 D_fake: 0.742 RMSE: 30.995 \n",
      "saving the latest model (epoch 180, total_iters 180000)\n",
      "End of epoch 180 / 200 \t Time Taken: 57 sec\n",
      "learning rate 0.0000396 -> 0.0000376\n",
      "RMSE fake image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 605.15, min: 0.00, mean: 46.24, std: 57.90\n",
      "RMSE real image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 919.63, min: 0.00, mean: 47.07, std: 57.30\n",
      "(epoch: 181, iters: 500, time: 0.151, data: 2.147) G_GAN: 1.224 G_L1: 3.437 D_real: 0.440 D_fake: 0.589 RMSE: 23.000 \n",
      "RMSE fake image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 2006.03, min: 0.00, mean: 61.45, std: 72.81\n",
      "RMSE real image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 3221.46, min: 0.00, mean: 63.74, std: 73.92\n",
      "(epoch: 181, iters: 1000, time: 0.134, data: 0.009) G_GAN: 1.091 G_L1: 3.997 D_real: 0.351 D_fake: 0.802 RMSE: 28.259 \n",
      "End of epoch 181 / 200 \t Time Taken: 56 sec\n",
      "learning rate 0.0000376 -> 0.0000356\n",
      "RMSE fake image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 1243.75, min: 0.00, mean: 59.90, std: 69.17\n",
      "RMSE real image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 1813.82, min: 0.00, mean: 60.33, std: 69.56\n",
      "(epoch: 182, iters: 500, time: 0.162, data: 2.154) G_GAN: 0.826 G_L1: 4.068 D_real: 0.615 D_fake: 0.498 RMSE: 27.636 \n",
      "RMSE fake image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 5242.71, min: 0.00, mean: 58.79, std: 60.88\n",
      "RMSE real image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 487.73, min: 0.00, mean: 58.96, std: 58.20\n",
      "(epoch: 182, iters: 1000, time: 0.143, data: 0.024) G_GAN: 0.850 G_L1: 4.099 D_real: 0.391 D_fake: 0.583 RMSE: 27.259 \n",
      "End of epoch 182 / 200 \t Time Taken: 56 sec\n",
      "learning rate 0.0000356 -> 0.0000337\n",
      "RMSE fake image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 1610.54, min: 0.00, mean: 52.01, std: 60.10\n",
      "RMSE real image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 1088.04, min: 0.00, mean: 53.58, std: 62.91\n",
      "(epoch: 183, iters: 500, time: 0.159, data: 2.125) G_GAN: 1.070 G_L1: 3.759 D_real: 0.520 D_fake: 0.582 RMSE: 24.963 \n",
      "RMSE fake image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 4657.75, min: 0.00, mean: 51.87, std: 65.87\n",
      "RMSE real image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 1689.28, min: 0.00, mean: 51.65, std: 65.45\n",
      "(epoch: 183, iters: 1000, time: 0.132, data: 0.012) G_GAN: 0.749 G_L1: 3.942 D_real: 0.534 D_fake: 0.585 RMSE: 29.836 \n",
      "End of epoch 183 / 200 \t Time Taken: 60 sec\n",
      "learning rate 0.0000337 -> 0.0000317\n",
      "RMSE fake image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 1048.92, min: 0.00, mean: 59.78, std: 63.16\n",
      "RMSE real image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 1204.25, min: 0.00, mean: 58.21, std: 60.41\n",
      "(epoch: 184, iters: 500, time: 0.176, data: 2.192) G_GAN: 0.886 G_L1: 4.161 D_real: 0.759 D_fake: 0.450 RMSE: 26.339 \n",
      "RMSE fake image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 895.96, min: 0.00, mean: 50.87, std: 60.59\n",
      "RMSE real image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 2178.84, min: 0.00, mean: 52.40, std: 61.65\n",
      "(epoch: 184, iters: 1000, time: 0.135, data: 0.013) G_GAN: 1.028 G_L1: 3.755 D_real: 0.382 D_fake: 0.567 RMSE: 25.197 \n",
      "End of epoch 184 / 200 \t Time Taken: 65 sec\n",
      "learning rate 0.0000317 -> 0.0000297\n",
      "RMSE fake image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 1058.18, min: 0.00, mean: 49.87, std: 62.80\n",
      "RMSE real image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 2592.55, min: 0.00, mean: 50.57, std: 63.93\n",
      "(epoch: 185, iters: 500, time: 0.165, data: 2.175) G_GAN: 0.990 G_L1: 3.507 D_real: 0.361 D_fake: 0.700 RMSE: 25.322 \n",
      "RMSE fake image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 1554.94, min: 0.00, mean: 50.01, std: 62.30\n",
      "RMSE real image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 768.74, min: 0.00, mean: 50.75, std: 62.48\n",
      "(epoch: 185, iters: 1000, time: 0.135, data: 0.014) G_GAN: 0.986 G_L1: 3.494 D_real: 0.797 D_fake: 0.397 RMSE: 25.022 \n",
      "saving the latest model (epoch 185, total_iters 185000)\n",
      "End of epoch 185 / 200 \t Time Taken: 58 sec\n",
      "learning rate 0.0000297 -> 0.0000277\n",
      "RMSE fake image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 2105.00, min: 0.00, mean: 69.54, std: 66.49\n",
      "RMSE real image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 1071.09, min: 0.00, mean: 66.80, std: 64.20\n",
      "(epoch: 186, iters: 500, time: 0.139, data: 2.258) G_GAN: 0.972 G_L1: 4.837 D_real: 0.550 D_fake: 0.390 RMSE: 30.335 \n",
      "RMSE fake image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 2537.48, min: 0.00, mean: 64.42, std: 61.18\n",
      "RMSE real image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 1307.76, min: 0.00, mean: 64.04, std: 60.37\n",
      "(epoch: 186, iters: 1000, time: 0.145, data: 0.030) G_GAN: 1.009 G_L1: 4.456 D_real: 0.561 D_fake: 0.497 RMSE: 27.747 \n",
      "End of epoch 186 / 200 \t Time Taken: 56 sec\n",
      "learning rate 0.0000277 -> 0.0000257\n",
      "RMSE fake image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 1272.20, min: 0.00, mean: 57.92, std: 58.94\n",
      "RMSE real image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 1677.23, min: 0.00, mean: 55.94, std: 56.93\n",
      "(epoch: 187, iters: 500, time: 0.137, data: 2.262) G_GAN: 0.980 G_L1: 3.878 D_real: 0.794 D_fake: 0.377 RMSE: 24.732 \n",
      "RMSE fake image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 5294.92, min: 0.00, mean: 62.09, std: 76.38\n",
      "RMSE real image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 2070.09, min: 0.00, mean: 64.99, std: 77.15\n",
      "(epoch: 187, iters: 1000, time: 0.141, data: 0.015) G_GAN: 0.895 G_L1: 4.741 D_real: 0.469 D_fake: 0.686 RMSE: 39.712 \n",
      "End of epoch 187 / 200 \t Time Taken: 62 sec\n",
      "learning rate 0.0000257 -> 0.0000238\n",
      "RMSE fake image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 3383.72, min: 0.00, mean: 72.14, std: 73.20\n",
      "RMSE real image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 2407.02, min: 0.00, mean: 75.08, std: 73.96\n",
      "(epoch: 188, iters: 500, time: 0.141, data: 2.029) G_GAN: 0.814 G_L1: 5.097 D_real: 0.334 D_fake: 0.850 RMSE: 33.485 \n",
      "RMSE fake image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 1871.18, min: 0.00, mean: 71.63, std: 69.65\n",
      "RMSE real image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 6212.39, min: 0.00, mean: 71.94, std: 69.69\n",
      "(epoch: 188, iters: 1000, time: 0.134, data: 0.032) G_GAN: 1.029 G_L1: 4.772 D_real: 0.661 D_fake: 0.453 RMSE: 31.414 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End of epoch 188 / 200 \t Time Taken: 56 sec\n",
      "learning rate 0.0000238 -> 0.0000218\n",
      "RMSE fake image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 943.65, min: 0.00, mean: 60.59, std: 62.08\n",
      "RMSE real image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 1580.31, min: 0.00, mean: 60.85, std: 61.44\n",
      "(epoch: 189, iters: 500, time: 0.161, data: 2.052) G_GAN: 0.958 G_L1: 4.244 D_real: 0.595 D_fake: 0.454 RMSE: 27.552 \n",
      "RMSE fake image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 849.59, min: 0.00, mean: 51.32, std: 60.08\n",
      "RMSE real image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 1324.13, min: 0.00, mean: 51.45, std: 60.16\n",
      "(epoch: 189, iters: 1000, time: 0.136, data: 0.034) G_GAN: 1.053 G_L1: 3.724 D_real: 0.717 D_fake: 0.323 RMSE: 25.230 \n",
      "End of epoch 189 / 200 \t Time Taken: 56 sec\n",
      "learning rate 0.0000218 -> 0.0000198\n",
      "RMSE fake image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 2039.25, min: 0.00, mean: 56.09, std: 59.37\n",
      "RMSE real image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 1296.42, min: 0.00, mean: 56.16, std: 58.81\n",
      "(epoch: 190, iters: 500, time: 0.149, data: 2.298) G_GAN: 1.130 G_L1: 3.971 D_real: 0.666 D_fake: 0.371 RMSE: 25.604 \n",
      "RMSE fake image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 4906.01, min: 0.00, mean: 63.81, std: 72.40\n",
      "RMSE real image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 549.02, min: 0.00, mean: 62.12, std: 71.35\n",
      "(epoch: 190, iters: 1000, time: 0.134, data: 0.013) G_GAN: 0.817 G_L1: 4.210 D_real: 0.501 D_fake: 0.624 RMSE: 29.560 \n",
      "saving the latest model (epoch 190, total_iters 190000)\n",
      "End of epoch 190 / 200 \t Time Taken: 57 sec\n",
      "learning rate 0.0000198 -> 0.0000178\n",
      "RMSE fake image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 943.21, min: 0.00, mean: 55.91, std: 59.61\n",
      "RMSE real image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 1606.04, min: 0.00, mean: 55.00, std: 58.93\n",
      "(epoch: 191, iters: 500, time: 0.160, data: 2.173) G_GAN: 1.053 G_L1: 3.862 D_real: 0.812 D_fake: 0.378 RMSE: 25.423 \n",
      "RMSE fake image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 1164.98, min: 0.00, mean: 53.39, std: 57.65\n",
      "RMSE real image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 3623.46, min: 0.00, mean: 53.52, std: 57.52\n",
      "(epoch: 191, iters: 1000, time: 0.147, data: 0.013) G_GAN: 1.058 G_L1: 3.837 D_real: 0.729 D_fake: 0.408 RMSE: 25.671 \n",
      "End of epoch 191 / 200 \t Time Taken: 57 sec\n",
      "learning rate 0.0000178 -> 0.0000158\n",
      "RMSE fake image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 2784.76, min: 0.00, mean: 64.11, std: 69.31\n",
      "RMSE real image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 1654.40, min: 0.00, mean: 65.66, std: 72.28\n",
      "(epoch: 192, iters: 500, time: 0.141, data: 2.180) G_GAN: 0.859 G_L1: 4.573 D_real: 0.355 D_fake: 0.726 RMSE: 32.271 \n",
      "RMSE fake image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 1834.56, min: 0.00, mean: 56.38, std: 65.56\n",
      "RMSE real image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 1597.18, min: 0.00, mean: 56.58, std: 67.33\n",
      "(epoch: 192, iters: 1000, time: 0.138, data: 0.013) G_GAN: 1.041 G_L1: 4.108 D_real: 0.622 D_fake: 0.444 RMSE: 27.547 \n",
      "End of epoch 192 / 200 \t Time Taken: 54 sec\n",
      "learning rate 0.0000158 -> 0.0000139\n",
      "RMSE fake image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 959.34, min: 0.00, mean: 53.33, std: 58.49\n",
      "RMSE real image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 1871.07, min: 0.00, mean: 52.20, std: 57.18\n",
      "(epoch: 193, iters: 500, time: 0.158, data: 2.272) G_GAN: 1.191 G_L1: 3.716 D_real: 0.724 D_fake: 0.336 RMSE: 25.119 \n",
      "RMSE fake image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 1653.60, min: 0.00, mean: 47.31, std: 55.83\n",
      "RMSE real image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 1126.49, min: 0.00, mean: 46.14, std: 53.97\n",
      "(epoch: 193, iters: 1000, time: 0.134, data: 0.059) G_GAN: 1.017 G_L1: 3.443 D_real: 0.397 D_fake: 0.637 RMSE: 23.072 \n",
      "End of epoch 193 / 200 \t Time Taken: 56 sec\n",
      "learning rate 0.0000139 -> 0.0000119\n",
      "RMSE fake image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 1172.20, min: 0.00, mean: 48.38, std: 55.02\n",
      "RMSE real image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 1307.76, min: 0.00, mean: 48.08, std: 55.90\n",
      "(epoch: 194, iters: 500, time: 0.170, data: 2.140) G_GAN: 1.043 G_L1: 3.540 D_real: 0.615 D_fake: 0.426 RMSE: 23.824 \n",
      "RMSE fake image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 674.97, min: 0.00, mean: 50.65, std: 59.03\n",
      "RMSE real image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 538.14, min: 0.00, mean: 52.57, std: 60.47\n",
      "(epoch: 194, iters: 1000, time: 0.137, data: 0.013) G_GAN: 1.044 G_L1: 3.620 D_real: 0.515 D_fake: 0.474 RMSE: 24.170 \n",
      "End of epoch 194 / 200 \t Time Taken: 56 sec\n",
      "learning rate 0.0000119 -> 0.0000099\n",
      "RMSE fake image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 1692.54, min: 0.00, mean: 58.78, std: 62.83\n",
      "RMSE real image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 1765.93, min: 0.00, mean: 56.21, std: 59.81\n",
      "(epoch: 195, iters: 500, time: 0.172, data: 2.200) G_GAN: 1.027 G_L1: 4.076 D_real: 0.859 D_fake: 0.411 RMSE: 27.370 \n",
      "RMSE fake image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 3448.91, min: 0.00, mean: 60.01, std: 68.23\n",
      "RMSE real image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 3233.36, min: 0.00, mean: 59.90, std: 68.20\n",
      "(epoch: 195, iters: 1000, time: 0.137, data: 0.055) G_GAN: 0.945 G_L1: 4.280 D_real: 0.536 D_fake: 0.538 RMSE: 29.868 \n",
      "saving the latest model (epoch 195, total_iters 195000)\n",
      "End of epoch 195 / 200 \t Time Taken: 57 sec\n",
      "learning rate 0.0000099 -> 0.0000079\n",
      "RMSE fake image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 2319.43, min: 0.00, mean: 48.02, std: 57.64\n",
      "RMSE real image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 2146.95, min: 0.00, mean: 46.78, std: 56.27\n",
      "(epoch: 196, iters: 500, time: 0.147, data: 1.999) G_GAN: 0.942 G_L1: 3.502 D_real: 0.647 D_fake: 0.461 RMSE: 23.738 \n",
      "RMSE fake image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 3544.15, min: 0.00, mean: 49.44, std: 62.62\n",
      "RMSE real image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 3221.46, min: 0.00, mean: 49.93, std: 62.34\n",
      "(epoch: 196, iters: 1000, time: 0.148, data: 0.019) G_GAN: 0.947 G_L1: 3.861 D_real: 0.500 D_fake: 0.561 RMSE: 29.067 \n",
      "End of epoch 196 / 200 \t Time Taken: 55 sec\n",
      "learning rate 0.0000079 -> 0.0000059\n",
      "RMSE fake image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 3362.30, min: 0.00, mean: 58.83, std: 57.35\n",
      "RMSE real image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 521.30, min: 0.00, mean: 61.10, std: 59.80\n",
      "(epoch: 197, iters: 500, time: 0.165, data: 2.102) G_GAN: 1.123 G_L1: 4.088 D_real: 0.500 D_fake: 0.421 RMSE: 25.651 \n",
      "RMSE fake image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 1034.18, min: 0.00, mean: 49.88, std: 57.53\n",
      "RMSE real image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 475.63, min: 0.00, mean: 50.61, std: 57.62\n",
      "(epoch: 197, iters: 1000, time: 0.148, data: 0.010) G_GAN: 1.061 G_L1: 3.538 D_real: 0.520 D_fake: 0.466 RMSE: 23.063 \n",
      "End of epoch 197 / 200 \t Time Taken: 57 sec\n",
      "learning rate 0.0000059 -> 0.0000040\n",
      "RMSE fake image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 1914.04, min: 0.00, mean: 53.58, std: 64.94\n",
      "RMSE real image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 2430.66, min: 0.00, mean: 54.52, std: 66.45\n",
      "(epoch: 198, iters: 500, time: 0.163, data: 2.236) G_GAN: 0.911 G_L1: 4.056 D_real: 0.536 D_fake: 0.565 RMSE: 27.799 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE fake image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 4132.93, min: 0.00, mean: 60.55, std: 71.14\n",
      "RMSE real image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 5151.87, min: 0.00, mean: 60.80, std: 72.84\n",
      "(epoch: 198, iters: 1000, time: 0.139, data: 0.062) G_GAN: 1.002 G_L1: 4.481 D_real: 0.512 D_fake: 0.504 RMSE: 40.749 \n",
      "End of epoch 198 / 200 \t Time Taken: 55 sec\n",
      "learning rate 0.0000040 -> 0.0000020\n",
      "RMSE fake image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 1960.45, min: 0.00, mean: 53.33, std: 68.51\n",
      "RMSE real image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 10450.77, min: 0.00, mean: 51.53, std: 70.33\n",
      "(epoch: 199, iters: 500, time: 0.176, data: 2.256) G_GAN: 0.948 G_L1: 3.851 D_real: 0.590 D_fake: 0.538 RMSE: 34.425 \n",
      "RMSE fake image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 1620.81, min: 0.00, mean: 59.74, std: 63.43\n",
      "RMSE real image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 1088.04, min: 0.00, mean: 61.24, std: 65.67\n",
      "(epoch: 199, iters: 1000, time: 0.139, data: 0.015) G_GAN: 0.985 G_L1: 3.988 D_real: 0.424 D_fake: 0.517 RMSE: 26.478 \n",
      "End of epoch 199 / 200 \t Time Taken: 55 sec\n",
      "learning rate 0.0000020 -> 0.0000000\n",
      "RMSE fake image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 532.73, min: 0.00, mean: 54.53, std: 52.58\n",
      "RMSE real image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 466.29, min: 0.00, mean: 55.11, std: 51.93\n",
      "(epoch: 200, iters: 500, time: 0.175, data: 2.452) G_GAN: 1.142 G_L1: 3.900 D_real: 0.496 D_fake: 0.419 RMSE: 23.390 \n",
      "RMSE fake image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 1933.15, min: 0.00, mean: 58.54, std: 66.57\n",
      "RMSE real image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 2156.00, min: 0.00, mean: 58.49, std: 66.39\n",
      "(epoch: 200, iters: 1000, time: 0.140, data: 0.012) G_GAN: 1.020 G_L1: 4.050 D_real: 0.678 D_fake: 0.490 RMSE: 28.847 \n",
      "saving the latest model (epoch 200, total_iters 200000)\n",
      "End of epoch 200 / 200 \t Time Taken: 57 sec\n"
     ]
    }
   ],
   "source": [
    "%cd ~/projects/dd-biomassters\n",
    "!python ./pix2pix/train.py \\\n",
    "    --dataroot ./data --name biomassters_20221203_02 --model pix2pix_bio --phase train --gpu_ids 0 \\\n",
    "    --direction AtoB --input_nc 16 --output_nc 1 --dataset_mode biomassters --preprocess \"\" --no_flip  \\\n",
    "    --g_activation Softplus \\\n",
    "    --batch_size 10 --max_dataset_size 1000 \\\n",
    "    --n_epochs 100 --n_epochs_decay 100 --lr 0.0002 \\\n",
    "    --display_id 1 --display_freq 500 --print_freq 500 --update_html_freq 1000 --save_epoch_freq 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/projects/dd-biomassters\n",
      "----------------- Options ---------------\n",
      "             aspect_ratio: 1.0                           \n",
      "               batch_size: 1                             \n",
      "          checkpoints_dir: ./checkpoints                 \n",
      "                crop_size: 256                           \n",
      "                 dataroot: ./data                        \t[default: data]\n",
      "             dataset_mode: biomassters                   \t[default: aligned]\n",
      "                direction: AtoB                          \n",
      "          display_winsize: 256                           \n",
      "                    epoch: latest                        \n",
      "                     eval: True                          \t[default: False]\n",
      "             g_activation: Softplus                      \t[default: Tanh]\n",
      "                  gpu_ids: 0                             \n",
      "                init_gain: 0.02                          \n",
      "                init_type: normal                        \n",
      "                 input_nc: 16                            \t[default: 3]\n",
      "                  isTrain: False                         \t[default: None]\n",
      "                load_iter: 0                             \t[default: 0]\n",
      "                load_size: 256                           \n",
      "         max_dataset_size: 10                            \t[default: inf]\n",
      "                    model: pix2pix_bio                   \t[default: test]\n",
      "               n_layers_D: 3                             \n",
      "                     name: biomassters_20221203_02       \t[default: experiment_name]\n",
      "                      ndf: 64                            \n",
      "                     netD: basic                         \n",
      "                     netG: unet_256                      \n",
      "                      ngf: 64                            \n",
      "               no_dropout: True                          \t[default: False]\n",
      "                  no_flip: False                         \n",
      "                     norm: batch                         \n",
      "                 num_test: 50                            \n",
      "              num_threads: 4                             \n",
      "                output_nc: 1                             \t[default: 3]\n",
      "                    phase: validation                    \t[default: test]\n",
      "               preprocess:                               \t[default: resize_and_crop]\n",
      "              results_dir: ./results/                    \n",
      "           serial_batches: False                         \n",
      "                   suffix:                               \n",
      "                use_wandb: False                         \n",
      "                  verbose: False                         \n",
      "       wandb_project_name: CycleGAN-and-pix2pix          \n",
      "----------------- End -------------------\n",
      "dataset [BioMasstersDataset] was created\n",
      "initialize network with normal\n",
      "model [Pix2PixBioModel] was created\n",
      "loading the model from ./checkpoints/biomassters_20221203_02/latest_net_G.pth\n",
      "---------- Networks initialized -------------\n",
      "[Network G] Total number of parameters : 54.423 M\n",
      "-----------------------------------------------\n",
      "creating web directory ./results/biomassters_20221203_02/validation_latest\n",
      "processing (0000)-th image... ['A_194f6b2f']\n",
      "RMSE fake image; type: <class 'torch.Tensor'>, shape: torch.Size([1, 1, 256, 256]), max: 409.77, min: 0.00, mean: 27.44, std: 51.81\n",
      "RMSE real image; type: <class 'torch.Tensor'>, shape: torch.Size([1, 1, 256, 256]), max: 743.73, min: 0.00, mean: 24.02, std: 51.46\n",
      "0 ['A_194f6b2f'] RMSE: 28.500797\n",
      "RMSE fake image; type: <class 'torch.Tensor'>, shape: torch.Size([1, 1, 256, 256]), max: 385.02, min: 0.00, mean: 37.77, std: 55.93\n",
      "RMSE real image; type: <class 'torch.Tensor'>, shape: torch.Size([1, 1, 256, 256]), max: 332.70, min: 0.00, mean: 36.90, std: 56.16\n",
      "1 ['A_f3fb0390'] RMSE: 30.445198\n",
      "RMSE fake image; type: <class 'torch.Tensor'>, shape: torch.Size([1, 1, 256, 256]), max: 393.45, min: 0.00, mean: 49.38, std: 40.90\n",
      "RMSE real image; type: <class 'torch.Tensor'>, shape: torch.Size([1, 1, 256, 256]), max: 365.83, min: 0.00, mean: 55.48, std: 48.89\n",
      "2 ['A_aac55cc2'] RMSE: 29.94939\n",
      "RMSE fake image; type: <class 'torch.Tensor'>, shape: torch.Size([1, 1, 256, 256]), max: 326.04, min: 0.00, mean: 40.33, std: 55.57\n",
      "RMSE real image; type: <class 'torch.Tensor'>, shape: torch.Size([1, 1, 256, 256]), max: 288.19, min: 0.00, mean: 50.45, std: 70.22\n",
      "3 ['A_e1d8bd56'] RMSE: 38.722645\n",
      "RMSE fake image; type: <class 'torch.Tensor'>, shape: torch.Size([1, 1, 256, 256]), max: 428.69, min: 0.00, mean: 44.56, std: 52.10\n",
      "RMSE real image; type: <class 'torch.Tensor'>, shape: torch.Size([1, 1, 256, 256]), max: 1119.50, min: 0.00, mean: 40.13, std: 48.76\n",
      "4 ['A_fc5fdc7d'] RMSE: 26.588377\n",
      "processing (0005)-th image... ['A_3f94776d']\n",
      "RMSE fake image; type: <class 'torch.Tensor'>, shape: torch.Size([1, 1, 256, 256]), max: 374.90, min: 0.00, mean: 44.79, std: 34.69\n",
      "RMSE real image; type: <class 'torch.Tensor'>, shape: torch.Size([1, 1, 256, 256]), max: 402.88, min: 0.00, mean: 42.70, std: 39.49\n",
      "5 ['A_3f94776d'] RMSE: 28.824993\n",
      "RMSE fake image; type: <class 'torch.Tensor'>, shape: torch.Size([1, 1, 256, 256]), max: 251.78, min: 0.00, mean: 45.17, std: 27.50\n",
      "RMSE real image; type: <class 'torch.Tensor'>, shape: torch.Size([1, 1, 256, 256]), max: 202.36, min: 0.00, mean: 47.77, std: 29.45\n",
      "6 ['A_532a13ca'] RMSE: 22.369135\n",
      "RMSE fake image; type: <class 'torch.Tensor'>, shape: torch.Size([1, 1, 256, 256]), max: 463.22, min: 0.00, mean: 86.81, std: 63.52\n",
      "RMSE real image; type: <class 'torch.Tensor'>, shape: torch.Size([1, 1, 256, 256]), max: 450.25, min: 0.00, mean: 87.43, std: 68.64\n",
      "7 ['A_5cd803cc'] RMSE: 53.540985\n",
      "RMSE fake image; type: <class 'torch.Tensor'>, shape: torch.Size([1, 1, 256, 256]), max: 378.89, min: 0.00, mean: 68.35, std: 48.87\n",
      "RMSE real image; type: <class 'torch.Tensor'>, shape: torch.Size([1, 1, 256, 256]), max: 437.76, min: 0.00, mean: 64.42, std: 52.84\n",
      "8 ['A_cdf1770b'] RMSE: 34.29599\n",
      "RMSE fake image; type: <class 'torch.Tensor'>, shape: torch.Size([1, 1, 256, 256]), max: 245.68, min: 0.00, mean: 3.08, std: 8.73\n",
      "RMSE real image; type: <class 'torch.Tensor'>, shape: torch.Size([1, 1, 256, 256]), max: 104.08, min: 0.00, mean: 2.65, std: 8.03\n",
      "9 ['A_dcd628b3'] RMSE: 9.251624\n"
     ]
    }
   ],
   "source": [
    "%cd ~/projects/dd-biomassters\n",
    "!python ./pix2pix/test.py \\\n",
    "    --dataroot ./data --name biomassters_20221203_02 --model pix2pix_bio --phase validation --gpu_ids 0 \\\n",
    "    --direction AtoB --input_nc 16 --output_nc 1 --dataset_mode biomassters --preprocess \"\" \\\n",
    "    --g_activation Softplus \\\n",
    "    --max_dataset_size 10 \\\n",
    "    --eval --no_dropout \\\n",
    "    --results_dir ./results/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Move Artiafcts to S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "upload: checkpoints/biomassters_20221203_02/validation_opt.txt to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/validation_opt.txt\n",
      "upload: checkpoints/biomassters_20221203_02/loss_log.txt to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/loss_log.txt\n",
      "upload: checkpoints/biomassters_20221203_02/train_opt.txt to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/train_opt.txt\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch001_fake_B_clip.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch001_fake_B_clip.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch001_real_A.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch001_real_A.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch001_fake_B.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch001_fake_B.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch001_real_B.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch001_real_B.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch001_real_B_clip.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch001_real_B_clip.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch002_fake_B_clip.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch002_fake_B_clip.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch002_real_B_clip.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch002_real_B_clip.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch003_fake_B.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch003_fake_B.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch002_real_A.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch002_real_A.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch002_fake_B.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch002_fake_B.png\n",
      "upload: checkpoints/biomassters_20221203_02/latest_net_D.pth to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/latest_net_D.pth\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch002_real_B.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch002_real_B.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch003_real_A.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch003_real_A.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch003_fake_B_clip.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch003_fake_B_clip.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch003_real_B_clip.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch003_real_B_clip.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch003_real_B.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch003_real_B.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch004_fake_B_clip.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch004_fake_B_clip.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch004_fake_B.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch004_fake_B.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch004_real_A.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch004_real_A.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch004_real_B_clip.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch004_real_B_clip.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch004_real_B.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch004_real_B.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch005_fake_B_clip.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch005_fake_B_clip.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch005_fake_B.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch005_fake_B.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch005_real_A.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch005_real_A.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch005_real_B.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch005_real_B.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch006_real_B.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch006_real_B.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch006_real_B_clip.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch006_real_B_clip.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch007_fake_B.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch007_fake_B.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch006_fake_B.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch006_fake_B.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch006_fake_B_clip.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch006_fake_B_clip.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch006_real_A.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch006_real_A.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch007_fake_B_clip.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch007_fake_B_clip.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch005_real_B_clip.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch005_real_B_clip.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch007_real_A.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch007_real_A.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch007_real_B_clip.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch007_real_B_clip.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch007_real_B.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch007_real_B.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch008_real_B.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch008_real_B.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch008_real_B_clip.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch008_real_B_clip.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch008_fake_B.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch008_fake_B.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch009_real_A.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch009_real_A.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch009_fake_B.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch009_fake_B.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch009_real_B_clip.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch009_real_B_clip.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch010_fake_B.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch010_fake_B.png\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch008_real_A.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch008_real_A.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch009_fake_B_clip.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch009_fake_B_clip.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch010_real_A.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch010_real_A.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch009_real_B.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch009_real_B.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch008_fake_B_clip.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch008_fake_B_clip.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch011_fake_B.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch011_fake_B.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch010_real_B.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch010_real_B.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch011_fake_B_clip.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch011_fake_B_clip.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch011_real_A.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch011_real_A.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch011_real_B.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch011_real_B.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch010_fake_B_clip.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch010_fake_B_clip.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch010_real_B_clip.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch010_real_B_clip.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch012_real_A.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch012_real_A.png\n",
      "upload: checkpoints/biomassters_20221203_02/latest_net_G.pth to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/latest_net_G.pth\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch011_real_B_clip.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch011_real_B_clip.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch013_fake_B.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch013_fake_B.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch013_real_A.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch013_real_A.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch013_real_B.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch013_real_B.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch013_fake_B_clip.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch013_fake_B_clip.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch012_fake_B_clip.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch012_fake_B_clip.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch012_real_B.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch012_real_B.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch014_fake_B.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch014_fake_B.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch012_real_B_clip.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch012_real_B_clip.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch014_fake_B_clip.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch014_fake_B_clip.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch014_real_B_clip.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch014_real_B_clip.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch014_real_A.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch014_real_A.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch014_real_B.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch014_real_B.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch012_fake_B.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch012_fake_B.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch015_fake_B.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch015_fake_B.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch015_fake_B_clip.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch015_fake_B_clip.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch015_real_A.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch015_real_A.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch016_fake_B_clip.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch016_fake_B_clip.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch016_fake_B.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch016_fake_B.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch015_real_B_clip.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch015_real_B_clip.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch016_real_B.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch016_real_B.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch016_real_B_clip.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch016_real_B_clip.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch013_real_B_clip.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch013_real_B_clip.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch017_fake_B.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch017_fake_B.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch017_fake_B_clip.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch017_fake_B_clip.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch015_real_B.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch015_real_B.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch018_fake_B.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch018_fake_B.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch017_real_B_clip.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch017_real_B_clip.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch017_real_B.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch017_real_B.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch017_real_A.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch017_real_A.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch018_fake_B_clip.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch018_fake_B_clip.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch018_real_B.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch018_real_B.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch016_real_A.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch016_real_A.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch019_fake_B.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch019_fake_B.png\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch019_real_B.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch019_real_B.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch019_real_B_clip.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch019_real_B_clip.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch019_real_A.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch019_real_A.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch020_fake_B.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch020_fake_B.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch018_real_A.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch018_real_A.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch020_real_A.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch020_real_A.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch020_real_B.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch020_real_B.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch019_fake_B_clip.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch019_fake_B_clip.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch021_fake_B.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch021_fake_B.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch021_real_B.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch021_real_B.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch018_real_B_clip.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch018_real_B_clip.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch020_fake_B_clip.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch020_fake_B_clip.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch021_fake_B_clip.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch021_fake_B_clip.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch022_real_B.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch022_real_B.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch021_real_B_clip.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch021_real_B_clip.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch022_fake_B.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch022_fake_B.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch020_real_B_clip.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch020_real_B_clip.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch023_fake_B.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch023_fake_B.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch023_fake_B_clip.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch023_fake_B_clip.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch023_real_A.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch023_real_A.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch021_real_A.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch021_real_A.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch024_fake_B.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch024_fake_B.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch023_real_B_clip.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch023_real_B_clip.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch022_real_A.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch022_real_A.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch022_real_B_clip.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch022_real_B_clip.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch024_real_A.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch024_real_A.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch025_fake_B_clip.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch025_fake_B_clip.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch025_fake_B.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch025_fake_B.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch024_fake_B_clip.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch024_fake_B_clip.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch023_real_B.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch023_real_B.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch022_fake_B_clip.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch022_fake_B_clip.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch025_real_B_clip.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch025_real_B_clip.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch024_real_B_clip.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch024_real_B_clip.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch024_real_B.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch024_real_B.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch026_real_A.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch026_real_A.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch026_fake_B_clip.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch026_fake_B_clip.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch026_real_B.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch026_real_B.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch025_real_B.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch025_real_B.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch027_fake_B.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch027_fake_B.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch026_fake_B.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch026_fake_B.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch026_real_B_clip.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch026_real_B_clip.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch025_real_A.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch025_real_A.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch027_real_B.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch027_real_B.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch027_real_A.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch027_real_A.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch028_fake_B.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch028_fake_B.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch027_fake_B_clip.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch027_fake_B_clip.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch028_fake_B_clip.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch028_fake_B_clip.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch028_real_B.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch028_real_B.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch028_real_B_clip.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch028_real_B_clip.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch027_real_B_clip.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch027_real_B_clip.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch029_real_B_clip.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch029_real_B_clip.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch029_real_A.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch029_real_A.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch029_real_B.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch029_real_B.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch028_real_A.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch028_real_A.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch029_fake_B.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch029_fake_B.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch030_fake_B_clip.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch030_fake_B_clip.png\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch030_real_B.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch030_real_B.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch029_fake_B_clip.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch029_fake_B_clip.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch030_fake_B.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch030_fake_B.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch031_real_B.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch031_real_B.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch031_real_B_clip.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch031_real_B_clip.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch032_fake_B.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch032_fake_B.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch030_real_A.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch030_real_A.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch030_real_B_clip.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch030_real_B_clip.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch032_fake_B_clip.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch032_fake_B_clip.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch032_real_A.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch032_real_A.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch031_real_A.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch031_real_A.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch032_real_B.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch032_real_B.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch031_fake_B.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch031_fake_B.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch032_real_B_clip.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch032_real_B_clip.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch033_real_B_clip.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch033_real_B_clip.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch031_fake_B_clip.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch031_fake_B_clip.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch034_real_B.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch034_real_B.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch033_fake_B_clip.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch033_fake_B_clip.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch033_real_A.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch033_real_A.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch033_fake_B.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch033_fake_B.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch035_real_A.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch035_real_A.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch034_fake_B.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch034_fake_B.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch033_real_B.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch033_real_B.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch034_real_A.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch034_real_A.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch035_real_B.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch035_real_B.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch034_real_B_clip.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch034_real_B_clip.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch035_real_B_clip.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch035_real_B_clip.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch036_real_B.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch036_real_B.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch035_fake_B_clip.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch035_fake_B_clip.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch036_fake_B.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch036_fake_B.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch035_fake_B.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch035_fake_B.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch036_real_B_clip.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch036_real_B_clip.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch037_fake_B_clip.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch037_fake_B_clip.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch037_real_B_clip.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch037_real_B_clip.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch038_fake_B.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch038_fake_B.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch037_real_B.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch037_real_B.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch038_fake_B_clip.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch038_fake_B_clip.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch038_real_B.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch038_real_B.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch036_fake_B_clip.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch036_fake_B_clip.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch036_real_A.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch036_real_A.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch034_fake_B_clip.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch034_fake_B_clip.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch038_real_B_clip.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch038_real_B_clip.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch039_fake_B.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch039_fake_B.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch037_fake_B.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch037_fake_B.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch039_fake_B_clip.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch039_fake_B_clip.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch037_real_A.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch037_real_A.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch039_real_A.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch039_real_A.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch040_fake_B_clip.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch040_fake_B_clip.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch038_real_A.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch038_real_A.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch040_real_B.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch040_real_B.png\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch041_fake_B_clip.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch041_fake_B_clip.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch041_real_A.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch041_real_A.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch039_real_B.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch039_real_B.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch041_real_B.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch041_real_B.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch040_real_B_clip.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch040_real_B_clip.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch041_real_B_clip.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch041_real_B_clip.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch041_fake_B.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch041_fake_B.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch042_fake_B.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch042_fake_B.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch039_real_B_clip.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch039_real_B_clip.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch040_real_A.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch040_real_A.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch042_real_A.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch042_real_A.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch040_fake_B.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch040_fake_B.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch042_real_B_clip.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch042_real_B_clip.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch042_fake_B_clip.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch042_fake_B_clip.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch043_fake_B.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch043_fake_B.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch043_fake_B_clip.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch043_fake_B_clip.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch043_real_B.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch043_real_B.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch044_real_A.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch044_real_A.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch042_real_B.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch042_real_B.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch044_real_B.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch044_real_B.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch044_real_B_clip.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch044_real_B_clip.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch043_real_B_clip.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch043_real_B_clip.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch044_fake_B.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch044_fake_B.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch045_real_A.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch045_real_A.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch045_real_B.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch045_real_B.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch043_real_A.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch043_real_A.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch046_real_A.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch046_real_A.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch046_fake_B.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch046_fake_B.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch045_fake_B.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch045_fake_B.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch045_fake_B_clip.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch045_fake_B_clip.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch044_fake_B_clip.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch044_fake_B_clip.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch046_fake_B_clip.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch046_fake_B_clip.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch047_real_B.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch047_real_B.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch047_real_A.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch047_real_A.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch047_real_B_clip.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch047_real_B_clip.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch045_real_B_clip.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch045_real_B_clip.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch046_real_B.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch046_real_B.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch047_fake_B_clip.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch047_fake_B_clip.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch047_fake_B.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch047_fake_B.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch046_real_B_clip.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch046_real_B_clip.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch048_fake_B_clip.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch048_fake_B_clip.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch049_fake_B_clip.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch049_fake_B_clip.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch049_fake_B.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch049_fake_B.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch048_fake_B.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch048_fake_B.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch048_real_B.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch048_real_B.png\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch049_real_B_clip.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch049_real_B_clip.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch050_fake_B.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch050_fake_B.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch050_fake_B_clip.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch050_fake_B_clip.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch050_real_A.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch050_real_A.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch048_real_A.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch048_real_A.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch048_real_B_clip.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch048_real_B_clip.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch049_real_A.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch049_real_A.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch049_real_B.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch049_real_B.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch050_real_B_clip.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch050_real_B_clip.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch051_real_A.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch051_real_A.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch051_fake_B_clip.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch051_fake_B_clip.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch051_real_B.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch051_real_B.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch051_fake_B.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch051_fake_B.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch051_real_B_clip.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch051_real_B_clip.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch052_real_A.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch052_real_A.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch052_real_B.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch052_real_B.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch050_real_B.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch050_real_B.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch053_fake_B_clip.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch053_fake_B_clip.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch052_real_B_clip.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch052_real_B_clip.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch052_fake_B_clip.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch052_fake_B_clip.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch053_real_A.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch053_real_A.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch054_fake_B.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch054_fake_B.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch052_fake_B.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch052_fake_B.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch053_real_B.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch053_real_B.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch053_real_B_clip.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch053_real_B_clip.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch054_real_A.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch054_real_A.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch054_real_B_clip.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch054_real_B_clip.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch055_fake_B_clip.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch055_fake_B_clip.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch053_fake_B.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch053_fake_B.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch054_fake_B_clip.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch054_fake_B_clip.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch055_real_A.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch055_real_A.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch055_real_B.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch055_real_B.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch056_real_B.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch056_real_B.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch056_real_A.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch056_real_A.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch057_fake_B_clip.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch057_fake_B_clip.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch055_fake_B.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch055_fake_B.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch056_fake_B.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch056_fake_B.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch054_real_B.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch054_real_B.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch057_fake_B.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch057_fake_B.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch056_fake_B_clip.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch056_fake_B_clip.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch057_real_A.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch057_real_A.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch055_real_B_clip.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch055_real_B_clip.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch057_real_B.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch057_real_B.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch057_real_B_clip.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch057_real_B_clip.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch056_real_B_clip.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch056_real_B_clip.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch058_fake_B.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch058_fake_B.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch058_real_B.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch058_real_B.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch058_real_B_clip.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch058_real_B_clip.png\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch058_real_A.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch058_real_A.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch059_fake_B_clip.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch059_fake_B_clip.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch059_real_A.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch059_real_A.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch059_real_B_clip.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch059_real_B_clip.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch060_fake_B_clip.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch060_fake_B_clip.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch059_real_B.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch059_real_B.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch060_real_A.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch060_real_A.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch059_fake_B.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch059_fake_B.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch060_real_B.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch060_real_B.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch061_fake_B.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch061_fake_B.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch058_fake_B_clip.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch058_fake_B_clip.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch060_real_B_clip.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch060_real_B_clip.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch061_fake_B_clip.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch061_fake_B_clip.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch061_real_A.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch061_real_A.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch062_fake_B.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch062_fake_B.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch061_real_B.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch061_real_B.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch062_fake_B_clip.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch062_fake_B_clip.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch061_real_B_clip.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch061_real_B_clip.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch062_real_A.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch062_real_A.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch062_real_B_clip.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch062_real_B_clip.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch060_fake_B.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch060_fake_B.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch063_fake_B_clip.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch063_fake_B_clip.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch063_fake_B.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch063_fake_B.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch063_real_A.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch063_real_A.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch062_real_B.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch062_real_B.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch064_fake_B_clip.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch064_fake_B_clip.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch064_real_B.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch064_real_B.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch064_real_B_clip.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch064_real_B_clip.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch065_real_A.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch065_real_A.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch063_real_B_clip.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch063_real_B_clip.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch065_real_B.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch065_real_B.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch064_fake_B.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch064_fake_B.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch065_real_B_clip.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch065_real_B_clip.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch066_fake_B.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch066_fake_B.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch063_real_B.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch063_real_B.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch066_real_A.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch066_real_A.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch065_fake_B_clip.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch065_fake_B_clip.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch066_real_B.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch066_real_B.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch065_fake_B.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch065_fake_B.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch064_real_A.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch064_real_A.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch067_fake_B.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch067_fake_B.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch067_real_A.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch067_real_A.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch066_fake_B_clip.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch066_fake_B_clip.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch067_fake_B_clip.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch067_fake_B_clip.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch068_fake_B.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch068_fake_B.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch067_real_B_clip.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch067_real_B_clip.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch066_real_B_clip.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch066_real_B_clip.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch068_real_A.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch068_real_A.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch068_fake_B_clip.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch068_fake_B_clip.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch067_real_B.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch067_real_B.png\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch069_fake_B.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch069_fake_B.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch069_fake_B_clip.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch069_fake_B_clip.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch068_real_B.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch068_real_B.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch068_real_B_clip.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch068_real_B_clip.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch069_real_A.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch069_real_A.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch070_fake_B_clip.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch070_fake_B_clip.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch070_real_A.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch070_real_A.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch069_real_B.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch069_real_B.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch069_real_B_clip.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch069_real_B_clip.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch071_fake_B_clip.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch071_fake_B_clip.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch071_real_A.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch071_real_A.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch071_fake_B.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch071_fake_B.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch071_real_B_clip.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch071_real_B_clip.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch072_fake_B.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch072_fake_B.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch070_real_B.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch070_real_B.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch070_real_B_clip.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch070_real_B_clip.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch072_real_A.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch072_real_A.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch070_fake_B.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch070_fake_B.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch072_real_B.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch072_real_B.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch073_real_A.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch073_real_A.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch073_fake_B.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch073_fake_B.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch071_real_B.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch071_real_B.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch072_real_B_clip.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch072_real_B_clip.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch072_fake_B_clip.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch072_fake_B_clip.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch073_fake_B_clip.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch073_fake_B_clip.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch073_real_B.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch073_real_B.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch074_fake_B.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch074_fake_B.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch074_fake_B_clip.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch074_fake_B_clip.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch073_real_B_clip.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch073_real_B_clip.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch074_real_B.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch074_real_B.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch075_fake_B.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch075_fake_B.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch075_fake_B_clip.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch075_fake_B_clip.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch075_real_B_clip.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch075_real_B_clip.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch076_fake_B_clip.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch076_fake_B_clip.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch076_real_A.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch076_real_A.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch076_real_B.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch076_real_B.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch074_real_A.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch074_real_A.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch076_fake_B.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch076_fake_B.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch074_real_B_clip.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch074_real_B_clip.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch077_fake_B.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch077_fake_B.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch075_real_B.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch075_real_B.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch075_real_A.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch075_real_A.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch077_real_A.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch077_real_A.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch077_fake_B_clip.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch077_fake_B_clip.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch076_real_B_clip.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch076_real_B_clip.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch078_fake_B_clip.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch078_fake_B_clip.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch078_fake_B.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch078_fake_B.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch078_real_A.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch078_real_A.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch077_real_B_clip.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch077_real_B_clip.png\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch079_real_A.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch079_real_A.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch078_real_B_clip.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch078_real_B_clip.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch079_fake_B_clip.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch079_fake_B_clip.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch079_fake_B.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch079_fake_B.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch079_real_B_clip.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch079_real_B_clip.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch077_real_B.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch077_real_B.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch080_fake_B.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch080_fake_B.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch079_real_B.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch079_real_B.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch080_real_B_clip.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch080_real_B_clip.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch081_fake_B_clip.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch081_fake_B_clip.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch081_real_A.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch081_real_A.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch080_fake_B_clip.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch080_fake_B_clip.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch081_real_B_clip.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch081_real_B_clip.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch080_real_A.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch080_real_A.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch080_real_B.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch080_real_B.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch082_fake_B.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch082_fake_B.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch081_real_B.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch081_real_B.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch078_real_B.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch078_real_B.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch082_real_A.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch082_real_A.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch083_real_B.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch083_real_B.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch082_real_B.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch082_real_B.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch083_fake_B_clip.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch083_fake_B_clip.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch083_fake_B.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch083_fake_B.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch081_fake_B.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch081_fake_B.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch082_real_B_clip.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch082_real_B_clip.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch084_fake_B_clip.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch084_fake_B_clip.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch084_real_B_clip.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch084_real_B_clip.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch084_real_A.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch084_real_A.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch082_fake_B_clip.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch082_fake_B_clip.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch083_real_B_clip.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch083_real_B_clip.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch085_fake_B.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch085_fake_B.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch084_fake_B.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch084_fake_B.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch083_real_A.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch083_real_A.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch085_real_B.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch085_real_B.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch085_real_B_clip.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch085_real_B_clip.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch085_real_A.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch085_real_A.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch085_fake_B_clip.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch085_fake_B_clip.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch086_fake_B_clip.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch086_fake_B_clip.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch084_real_B.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch084_real_B.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch086_fake_B.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch086_fake_B.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch086_real_B_clip.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch086_real_B_clip.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch087_fake_B.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch087_fake_B.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch086_real_A.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch086_real_A.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch086_real_B.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch086_real_B.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch087_real_A.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch087_real_A.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch087_real_B_clip.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch087_real_B_clip.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch088_real_B.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch088_real_B.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch088_real_B_clip.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch088_real_B_clip.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch089_fake_B.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch089_fake_B.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch087_real_B.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch087_real_B.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch089_fake_B_clip.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch089_fake_B_clip.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch089_real_A.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch089_real_A.png\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch088_fake_B.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch088_fake_B.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch090_real_A.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch090_real_A.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch090_real_B.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch090_real_B.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch089_real_B.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch089_real_B.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch088_real_A.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch088_real_A.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch090_fake_B_clip.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch090_fake_B_clip.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch089_real_B_clip.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch089_real_B_clip.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch091_real_B.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch091_real_B.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch091_fake_B_clip.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch091_fake_B_clip.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch091_fake_B.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch091_fake_B.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch090_fake_B.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch090_fake_B.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch092_fake_B.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch092_fake_B.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch088_fake_B_clip.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch088_fake_B_clip.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch092_fake_B_clip.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch092_fake_B_clip.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch090_real_B_clip.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch090_real_B_clip.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch087_fake_B_clip.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch087_fake_B_clip.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch092_real_A.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch092_real_A.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch091_real_A.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch091_real_A.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch093_fake_B.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch093_fake_B.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch093_real_B.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch093_real_B.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch093_fake_B_clip.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch093_fake_B_clip.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch093_real_B_clip.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch093_real_B_clip.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch092_real_B.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch092_real_B.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch091_real_B_clip.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch091_real_B_clip.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch093_real_A.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch093_real_A.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch094_fake_B_clip.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch094_fake_B_clip.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch094_real_B_clip.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch094_real_B_clip.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch095_fake_B.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch095_fake_B.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch092_real_B_clip.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch092_real_B_clip.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch094_real_B.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch094_real_B.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch095_fake_B_clip.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch095_fake_B_clip.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch095_real_A.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch095_real_A.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch094_real_A.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch094_real_A.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch095_real_B.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch095_real_B.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch094_fake_B.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch094_fake_B.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch095_real_B_clip.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch095_real_B_clip.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch096_fake_B_clip.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch096_fake_B_clip.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch096_real_B.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch096_real_B.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch097_real_B_clip.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch097_real_B_clip.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch096_fake_B.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch096_fake_B.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch098_fake_B_clip.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch098_fake_B_clip.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch097_fake_B_clip.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch097_fake_B_clip.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch098_fake_B.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch098_fake_B.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch097_real_A.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch097_real_A.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch096_real_A.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch096_real_A.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch097_fake_B.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch097_fake_B.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch097_real_B.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch097_real_B.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch098_real_A.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch098_real_A.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch098_real_B.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch098_real_B.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch099_real_A.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch099_real_A.png\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch099_fake_B.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch099_fake_B.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch096_real_B_clip.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch096_real_B_clip.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch099_fake_B_clip.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch099_fake_B_clip.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch099_real_B.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch099_real_B.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch098_real_B_clip.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch098_real_B_clip.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch099_real_B_clip.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch099_real_B_clip.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch100_fake_B_clip.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch100_fake_B_clip.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch101_fake_B.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch101_fake_B.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch100_real_B.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch100_real_B.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch100_fake_B.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch100_fake_B.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch101_real_B.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch101_real_B.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch101_real_A.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch101_real_A.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch101_real_B_clip.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch101_real_B_clip.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch102_fake_B.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch102_fake_B.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch100_real_B_clip.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch100_real_B_clip.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch101_fake_B_clip.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch101_fake_B_clip.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch100_real_A.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch100_real_A.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch102_fake_B_clip.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch102_fake_B_clip.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch102_real_A.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch102_real_A.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch102_real_B.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch102_real_B.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch103_fake_B.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch103_fake_B.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch103_real_B.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch103_real_B.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch103_real_B_clip.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch103_real_B_clip.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch103_fake_B_clip.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch103_fake_B_clip.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch104_fake_B.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch104_fake_B.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch104_fake_B_clip.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch104_fake_B_clip.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch103_real_A.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch103_real_A.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch104_real_B.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch104_real_B.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch104_real_B_clip.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch104_real_B_clip.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch102_real_B_clip.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch102_real_B_clip.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch105_fake_B.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch105_fake_B.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch105_real_A.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch105_real_A.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch106_fake_B.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch106_fake_B.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch106_real_A.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch106_real_A.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch104_real_A.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch104_real_A.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch105_real_B.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch105_real_B.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch105_real_B_clip.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch105_real_B_clip.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch106_real_B_clip.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch106_real_B_clip.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch106_real_B.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch106_real_B.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch107_fake_B_clip.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch107_fake_B_clip.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch107_fake_B.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch107_fake_B.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch105_fake_B_clip.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch105_fake_B_clip.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch107_real_B_clip.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch107_real_B_clip.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch108_fake_B_clip.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch108_fake_B_clip.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch108_real_A.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch108_real_A.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch108_real_B.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch108_real_B.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch108_real_B_clip.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch108_real_B_clip.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch106_fake_B_clip.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch106_fake_B_clip.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch107_real_B.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch107_real_B.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch109_real_A.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch109_real_A.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch109_fake_B_clip.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch109_fake_B_clip.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch108_fake_B.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch108_fake_B.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch107_real_A.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch107_real_A.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch109_real_B.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch109_real_B.png\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch109_real_B_clip.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch109_real_B_clip.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch110_fake_B.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch110_fake_B.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch110_fake_B_clip.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch110_fake_B_clip.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch110_real_A.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch110_real_A.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch111_fake_B.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch111_fake_B.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch110_real_B_clip.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch110_real_B_clip.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch110_real_B.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch110_real_B.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch109_fake_B.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch109_fake_B.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch111_fake_B_clip.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch111_fake_B_clip.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch111_real_A.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch111_real_A.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch111_real_B_clip.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch111_real_B_clip.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch112_fake_B.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch112_fake_B.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch111_real_B.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch111_real_B.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch113_real_A.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch113_real_A.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch113_fake_B_clip.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch113_fake_B_clip.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch112_fake_B_clip.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch112_fake_B_clip.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch113_real_B.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch113_real_B.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch113_real_B_clip.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch113_real_B_clip.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch114_fake_B.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch114_fake_B.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch112_real_B.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch112_real_B.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch114_fake_B_clip.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch114_fake_B_clip.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch114_real_B.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch114_real_B.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch114_real_B_clip.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch114_real_B_clip.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch112_real_A.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch112_real_A.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch115_fake_B.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch115_fake_B.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch112_real_B_clip.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch112_real_B_clip.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch113_fake_B.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch113_fake_B.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch115_real_B.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch115_real_B.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch115_real_A.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch115_real_A.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch116_fake_B_clip.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch116_fake_B_clip.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch114_real_A.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch114_real_A.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch116_real_B.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch116_real_B.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch117_fake_B.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch117_fake_B.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch116_fake_B.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch116_fake_B.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch115_real_B_clip.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch115_real_B_clip.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch116_real_B_clip.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch116_real_B_clip.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch117_real_B_clip.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch117_real_B_clip.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch115_fake_B_clip.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch115_fake_B_clip.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch117_real_A.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch117_real_A.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch118_fake_B.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch118_fake_B.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch118_fake_B_clip.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch118_fake_B_clip.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch118_real_A.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch118_real_A.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch118_real_B.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch118_real_B.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch119_fake_B_clip.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch119_fake_B_clip.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch116_real_A.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch116_real_A.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch119_real_B.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch119_real_B.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch117_fake_B_clip.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch117_fake_B_clip.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch117_real_B.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch117_real_B.png\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch120_fake_B.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch120_fake_B.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch119_real_A.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch119_real_A.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch118_real_B_clip.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch118_real_B_clip.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch120_real_B_clip.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch120_real_B_clip.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch121_fake_B.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch121_fake_B.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch119_real_B_clip.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch119_real_B_clip.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch120_real_B.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch120_real_B.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch119_fake_B.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch119_fake_B.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch122_fake_B.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch122_fake_B.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch121_real_B_clip.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch121_real_B_clip.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch120_real_A.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch120_real_A.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch122_real_A.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch122_real_A.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch121_fake_B_clip.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch121_fake_B_clip.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch122_real_B.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch122_real_B.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch120_fake_B_clip.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch120_fake_B_clip.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch121_real_A.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch121_real_A.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch121_real_B.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch121_real_B.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch123_real_B.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch123_real_B.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch123_fake_B_clip.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch123_fake_B_clip.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch124_fake_B.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch124_fake_B.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch122_real_B_clip.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch122_real_B_clip.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch124_fake_B_clip.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch124_fake_B_clip.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch124_real_A.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch124_real_A.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch123_real_A.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch123_real_A.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch124_real_B.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch124_real_B.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch122_fake_B_clip.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch122_fake_B_clip.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch124_real_B_clip.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch124_real_B_clip.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch123_fake_B.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch123_fake_B.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch125_fake_B_clip.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch125_fake_B_clip.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch125_real_A.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch125_real_A.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch125_real_B.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch125_real_B.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch125_fake_B.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch125_fake_B.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch126_fake_B.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch126_fake_B.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch126_fake_B_clip.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch126_fake_B_clip.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch126_real_A.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch126_real_A.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch126_real_B.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch126_real_B.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch123_real_B_clip.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch123_real_B_clip.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch128_fake_B.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch128_fake_B.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch127_fake_B_clip.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch127_fake_B_clip.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch125_real_B_clip.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch125_real_B_clip.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch127_real_B_clip.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch127_real_B_clip.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch127_real_A.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch127_real_A.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch127_real_B.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch127_real_B.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch127_fake_B.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch127_fake_B.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch128_fake_B_clip.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch128_fake_B_clip.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch128_real_A.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch128_real_A.png\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch129_real_A.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch129_real_A.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch129_fake_B_clip.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch129_fake_B_clip.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch126_real_B_clip.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch126_real_B_clip.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch129_real_B.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch129_real_B.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch129_fake_B.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch129_fake_B.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch130_fake_B_clip.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch130_fake_B_clip.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch128_real_B.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch128_real_B.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch128_real_B_clip.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch128_real_B_clip.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch130_real_A.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch130_real_A.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch131_fake_B.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch131_fake_B.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch131_fake_B_clip.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch131_fake_B_clip.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch130_fake_B.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch130_fake_B.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch131_real_B.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch131_real_B.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch130_real_B_clip.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch130_real_B_clip.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch131_real_B_clip.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch131_real_B_clip.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch131_real_A.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch131_real_A.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch129_real_B_clip.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch129_real_B_clip.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch132_fake_B_clip.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch132_fake_B_clip.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch132_fake_B.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch132_fake_B.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch132_real_B.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch132_real_B.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch132_real_A.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch132_real_A.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch132_real_B_clip.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch132_real_B_clip.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch133_fake_B.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch133_fake_B.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch130_real_B.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch130_real_B.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch133_real_A.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch133_real_A.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch133_fake_B_clip.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch133_fake_B_clip.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch133_real_B.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch133_real_B.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch134_fake_B.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch134_fake_B.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch133_real_B_clip.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch133_real_B_clip.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch134_real_A.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch134_real_A.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch134_real_B.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch134_real_B.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch135_fake_B.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch135_fake_B.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch134_real_B_clip.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch134_real_B_clip.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch135_real_B.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch135_real_B.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch135_fake_B_clip.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch135_fake_B_clip.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch134_fake_B_clip.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch134_fake_B_clip.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch136_fake_B_clip.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch136_fake_B_clip.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch136_real_A.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch136_real_A.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch137_fake_B_clip.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch137_fake_B_clip.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch136_fake_B.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch136_fake_B.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch135_real_A.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch135_real_A.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch138_fake_B_clip.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch138_fake_B_clip.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch138_fake_B.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch138_fake_B.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch135_real_B_clip.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch135_real_B_clip.png\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch137_real_B_clip.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch137_real_B_clip.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch137_real_B.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch137_real_B.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch137_real_A.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch137_real_A.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch136_real_B.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch136_real_B.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch138_real_A.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch138_real_A.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch138_real_B.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch138_real_B.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch137_fake_B.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch137_fake_B.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch138_real_B_clip.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch138_real_B_clip.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch139_fake_B.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch139_fake_B.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch136_real_B_clip.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch136_real_B_clip.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch139_real_B_clip.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch139_real_B_clip.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch139_real_B.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch139_real_B.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch140_fake_B.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch140_fake_B.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch140_real_B_clip.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch140_real_B_clip.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch140_real_B.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch140_real_B.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch139_fake_B_clip.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch139_fake_B_clip.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch139_real_A.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch139_real_A.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch141_fake_B_clip.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch141_fake_B_clip.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch141_real_B_clip.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch141_real_B_clip.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch141_fake_B.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch141_fake_B.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch140_real_A.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch140_real_A.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch141_real_A.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch141_real_A.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch142_fake_B.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch142_fake_B.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch142_fake_B_clip.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch142_fake_B_clip.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch142_real_B.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch142_real_B.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch143_fake_B.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch143_fake_B.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch143_real_B.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch143_real_B.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch143_real_A.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch143_real_A.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch143_fake_B_clip.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch143_fake_B_clip.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch142_real_A.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch142_real_A.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch143_real_B_clip.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch143_real_B_clip.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch140_fake_B_clip.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch140_fake_B_clip.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch144_real_A.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch144_real_A.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch141_real_B.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch141_real_B.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch144_real_B.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch144_real_B.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch144_real_B_clip.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch144_real_B_clip.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch145_fake_B.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch145_fake_B.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch142_real_B_clip.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch142_real_B_clip.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch145_real_A.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch145_real_A.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch145_fake_B_clip.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch145_fake_B_clip.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch146_fake_B.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch146_fake_B.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch145_real_B_clip.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch145_real_B_clip.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch144_fake_B.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch144_fake_B.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch146_fake_B_clip.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch146_fake_B_clip.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch146_real_B_clip.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch146_real_B_clip.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch146_real_B.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch146_real_B.png\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch147_real_A.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch147_real_A.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch145_real_B.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch145_real_B.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch147_real_B_clip.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch147_real_B_clip.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch144_fake_B_clip.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch144_fake_B_clip.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch147_fake_B.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch147_fake_B.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch148_real_A.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch148_real_A.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch148_fake_B.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch148_fake_B.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch148_real_B.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch148_real_B.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch147_real_B.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch147_real_B.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch148_real_B_clip.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch148_real_B_clip.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch147_fake_B_clip.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch147_fake_B_clip.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch149_fake_B.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch149_fake_B.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch148_fake_B_clip.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch148_fake_B_clip.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch149_fake_B_clip.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch149_fake_B_clip.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch149_real_A.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch149_real_A.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch150_fake_B.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch150_fake_B.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch150_fake_B_clip.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch150_fake_B_clip.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch150_real_A.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch150_real_A.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch151_fake_B.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch151_fake_B.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch149_real_B.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch149_real_B.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch146_real_A.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch146_real_A.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch151_fake_B_clip.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch151_fake_B_clip.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch150_real_B.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch150_real_B.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch151_real_A.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch151_real_A.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch151_real_B.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch151_real_B.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch149_real_B_clip.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch149_real_B_clip.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch150_real_B_clip.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch150_real_B_clip.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch152_fake_B.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch152_fake_B.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch152_real_B.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch152_real_B.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch152_real_A.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch152_real_A.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch152_fake_B_clip.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch152_fake_B_clip.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch152_real_B_clip.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch152_real_B_clip.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch153_real_A.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch153_real_A.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch153_real_B_clip.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch153_real_B_clip.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch151_real_B_clip.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch151_real_B_clip.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch153_real_B.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch153_real_B.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch154_fake_B.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch154_fake_B.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch154_fake_B_clip.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch154_fake_B_clip.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch154_real_A.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch154_real_A.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch154_real_B.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch154_real_B.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch153_fake_B_clip.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch153_fake_B_clip.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch155_real_B.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch155_real_B.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch155_real_B_clip.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch155_real_B_clip.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch156_fake_B_clip.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch156_fake_B_clip.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch156_real_A.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch156_real_A.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch155_fake_B.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch155_fake_B.png\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch156_fake_B.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch156_fake_B.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch153_fake_B.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch153_fake_B.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch156_real_B_clip.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch156_real_B_clip.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch154_real_B_clip.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch154_real_B_clip.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch157_fake_B_clip.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch157_fake_B_clip.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch155_real_A.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch155_real_A.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch157_real_A.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch157_real_A.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch155_fake_B_clip.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch155_fake_B_clip.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch157_real_B.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch157_real_B.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch157_fake_B.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch157_fake_B.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch158_fake_B_clip.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch158_fake_B_clip.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch156_real_B.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch156_real_B.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch158_real_A.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch158_real_A.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch158_fake_B.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch158_fake_B.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch159_real_A.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch159_real_A.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch159_real_B_clip.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch159_real_B_clip.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch159_fake_B.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch159_fake_B.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch160_fake_B_clip.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch160_fake_B_clip.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch157_real_B_clip.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch157_real_B_clip.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch160_fake_B.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch160_fake_B.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch160_real_B.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch160_real_B.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch159_real_B.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch159_real_B.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch158_real_B.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch158_real_B.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch158_real_B_clip.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch158_real_B_clip.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch160_real_A.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch160_real_A.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch161_fake_B_clip.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch161_fake_B_clip.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch161_fake_B.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch161_fake_B.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch161_real_B_clip.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch161_real_B_clip.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch161_real_B.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch161_real_B.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch162_fake_B.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch162_fake_B.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch162_fake_B_clip.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch162_fake_B_clip.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch162_real_A.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch162_real_A.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch163_fake_B.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch163_fake_B.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch160_real_B_clip.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch160_real_B_clip.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch163_real_A.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch163_real_A.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch163_fake_B_clip.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch163_fake_B_clip.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch161_real_A.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch161_real_A.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch159_fake_B_clip.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch159_fake_B_clip.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch163_real_B_clip.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch163_real_B_clip.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch162_real_B_clip.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch162_real_B_clip.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch164_fake_B.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch164_fake_B.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch164_real_A.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch164_real_A.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch164_fake_B_clip.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch164_fake_B_clip.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch164_real_B_clip.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch164_real_B_clip.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch163_real_B.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch163_real_B.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch164_real_B.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch164_real_B.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch165_fake_B.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch165_fake_B.png\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch162_real_B.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch162_real_B.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch165_real_B_clip.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch165_real_B_clip.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch165_real_A.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch165_real_A.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch166_fake_B.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch166_fake_B.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch165_real_B.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch165_real_B.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch166_real_B.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch166_real_B.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch165_fake_B_clip.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch165_fake_B_clip.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch166_real_A.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch166_real_A.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch166_real_B_clip.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch166_real_B_clip.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch167_fake_B_clip.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch167_fake_B_clip.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch167_real_B_clip.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch167_real_B_clip.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch167_fake_B.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch167_fake_B.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch167_real_B.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch167_real_B.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch166_fake_B_clip.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch166_fake_B_clip.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch168_real_B_clip.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch168_real_B_clip.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch169_fake_B_clip.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch169_fake_B_clip.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch167_real_A.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch167_real_A.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch168_fake_B.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch168_fake_B.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch168_fake_B_clip.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch168_fake_B_clip.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch168_real_B.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch168_real_B.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch169_real_B_clip.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch169_real_B_clip.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch168_real_A.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch168_real_A.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch170_fake_B_clip.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch170_fake_B_clip.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch169_fake_B.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch169_fake_B.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch170_real_A.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch170_real_A.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch169_real_A.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch169_real_A.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch170_real_B.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch170_real_B.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch169_real_B.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch169_real_B.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch170_real_B_clip.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch170_real_B_clip.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch171_real_A.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch171_real_A.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch171_real_B.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch171_real_B.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch172_fake_B_clip.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch172_fake_B_clip.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch172_fake_B.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch172_fake_B.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch172_real_A.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch172_real_A.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch171_real_B_clip.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch171_real_B_clip.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch173_fake_B.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch173_fake_B.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch171_fake_B.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch171_fake_B.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch170_fake_B.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch170_fake_B.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch173_fake_B_clip.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch173_fake_B_clip.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch173_real_A.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch173_real_A.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch172_real_B_clip.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch172_real_B_clip.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch171_fake_B_clip.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch171_fake_B_clip.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch172_real_B.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch172_real_B.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch173_real_B_clip.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch173_real_B_clip.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch174_fake_B_clip.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch174_fake_B_clip.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch174_real_A.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch174_real_A.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch173_real_B.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch173_real_B.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch175_real_A.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch175_real_A.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch175_fake_B.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch175_fake_B.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch174_real_B.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch174_real_B.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch174_real_B_clip.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch174_real_B_clip.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch175_real_B_clip.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch175_real_B_clip.png\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch175_real_B.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch175_real_B.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch174_fake_B.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch174_fake_B.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch176_real_B_clip.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch176_real_B_clip.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch177_fake_B.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch177_fake_B.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch177_fake_B_clip.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch177_fake_B_clip.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch177_real_A.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch177_real_A.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch176_fake_B_clip.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch176_fake_B_clip.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch176_real_A.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch176_real_A.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch176_real_B.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch176_real_B.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch178_fake_B.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch178_fake_B.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch178_fake_B_clip.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch178_fake_B_clip.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch177_real_B.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch177_real_B.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch178_real_A.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch178_real_A.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch176_fake_B.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch176_fake_B.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch178_real_B_clip.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch178_real_B_clip.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch177_real_B_clip.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch177_real_B_clip.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch179_real_B.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch179_real_B.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch175_fake_B_clip.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch175_fake_B_clip.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch179_fake_B_clip.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch179_fake_B_clip.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch180_fake_B.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch180_fake_B.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch180_fake_B_clip.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch180_fake_B_clip.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch179_real_B_clip.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch179_real_B_clip.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch179_fake_B.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch179_fake_B.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch180_real_A.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch180_real_A.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch181_fake_B.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch181_fake_B.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch181_real_B.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch181_real_B.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch181_fake_B_clip.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch181_fake_B_clip.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch180_real_B.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch180_real_B.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch181_real_B_clip.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch181_real_B_clip.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch180_real_B_clip.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch180_real_B_clip.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch179_real_A.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch179_real_A.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch182_real_A.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch182_real_A.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch182_real_B.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch182_real_B.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch178_real_B.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch178_real_B.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch183_fake_B.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch183_fake_B.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch183_fake_B_clip.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch183_fake_B_clip.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch182_real_B_clip.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch182_real_B_clip.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch183_real_B_clip.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch183_real_B_clip.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch183_real_B.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch183_real_B.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch183_real_A.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch183_real_A.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch182_fake_B_clip.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch182_fake_B_clip.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch182_fake_B.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch182_fake_B.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch181_real_A.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch181_real_A.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch184_real_B.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch184_real_B.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch185_fake_B.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch185_fake_B.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch184_real_B_clip.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch184_real_B_clip.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch184_fake_B.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch184_fake_B.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch185_real_B_clip.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch185_real_B_clip.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch186_real_A.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch186_real_A.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch185_fake_B_clip.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch185_fake_B_clip.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch186_real_B.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch186_real_B.png\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch185_real_A.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch185_real_A.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch186_fake_B_clip.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch186_fake_B_clip.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch185_real_B.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch185_real_B.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch184_real_A.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch184_real_A.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch187_real_A.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch187_real_A.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch186_fake_B.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch186_fake_B.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch187_fake_B.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch187_fake_B.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch186_real_B_clip.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch186_real_B_clip.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch188_fake_B_clip.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch188_fake_B_clip.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch187_real_B_clip.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch187_real_B_clip.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch188_real_B_clip.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch188_real_B_clip.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch189_fake_B.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch189_fake_B.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch188_real_B.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch188_real_B.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch187_fake_B_clip.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch187_fake_B_clip.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch188_real_A.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch188_real_A.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch189_real_B.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch189_real_B.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch187_real_B.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch187_real_B.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch189_real_A.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch189_real_A.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch189_real_B_clip.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch189_real_B_clip.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch188_fake_B.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch188_fake_B.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch184_fake_B_clip.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch184_fake_B_clip.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch190_real_B_clip.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch190_real_B_clip.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch190_real_A.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch190_real_A.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch191_real_A.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch191_real_A.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch191_fake_B.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch191_fake_B.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch190_fake_B.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch190_fake_B.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch190_real_B.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch190_real_B.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch191_real_B_clip.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch191_real_B_clip.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch189_fake_B_clip.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch189_fake_B_clip.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch192_fake_B.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch192_fake_B.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch192_real_B.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch192_real_B.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch192_fake_B_clip.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch192_fake_B_clip.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch192_real_B_clip.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch192_real_B_clip.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch193_fake_B.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch193_fake_B.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch193_fake_B_clip.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch193_fake_B_clip.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch192_real_A.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch192_real_A.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch191_real_B.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch191_real_B.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch193_real_B.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch193_real_B.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch191_fake_B_clip.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch191_fake_B_clip.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch194_real_A.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch194_real_A.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch194_fake_B.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch194_fake_B.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch195_fake_B_clip.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch195_fake_B_clip.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch195_fake_B.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch195_fake_B.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch193_real_B_clip.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch193_real_B_clip.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch193_real_A.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch193_real_A.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch195_real_B.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch195_real_B.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch194_fake_B_clip.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch194_fake_B_clip.png\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch195_real_A.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch195_real_A.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch195_real_B_clip.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch195_real_B_clip.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch196_fake_B.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch196_fake_B.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch196_fake_B_clip.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch196_fake_B_clip.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch197_fake_B_clip.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch197_fake_B_clip.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch194_real_B_clip.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch194_real_B_clip.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch196_real_A.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch196_real_A.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch190_fake_B_clip.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch190_fake_B_clip.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch194_real_B.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch194_real_B.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch197_real_B_clip.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch197_real_B_clip.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch196_real_B.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch196_real_B.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch197_real_A.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch197_real_A.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch197_real_B.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch197_real_B.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch196_real_B_clip.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch196_real_B_clip.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch197_fake_B.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch197_fake_B.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch198_real_B.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch198_real_B.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch198_fake_B_clip.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch198_fake_B_clip.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch199_fake_B.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch199_fake_B.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch198_real_B_clip.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch198_real_B_clip.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch198_fake_B.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch198_fake_B.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch199_real_B.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch199_real_B.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch198_real_A.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch198_real_A.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch199_real_A.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch199_real_A.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch199_real_B_clip.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch199_real_B_clip.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch199_fake_B_clip.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch199_fake_B_clip.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch200_fake_B.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch200_fake_B.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch200_real_A.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch200_real_A.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch200_real_B_clip.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch200_real_B_clip.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch200_fake_B_clip.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch200_fake_B_clip.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/images/epoch200_real_B.png to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/images/epoch200_real_B.png\n",
      "upload: checkpoints/biomassters_20221203_02/web/index.html to s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/web/index.html\n"
     ]
    }
   ],
   "source": [
    "! aws s3 cp --recursive \\\n",
    "    ~/projects/dd-biomassters/checkpoints/biomassters_20221203_02/ \\\n",
    "    s3://rockson-s3-bucket/dd-biomassters/checkpoints/biomassters_20221203_02/\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
