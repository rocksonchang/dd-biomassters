{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run Training and Testing Scripts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train\n",
    "Start visdom server: `python -m visdom.server` \n",
    "\n",
    "Otherwise set display id to -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/loaner/projects/dd-biomassters\n",
      "----------------- Options ---------------\n",
      "               batch_size: 10                            \t[default: 1]\n",
      "                    beta1: 0.5                           \n",
      "          checkpoints_dir: ./checkpoints                 \n",
      "           continue_train: False                         \n",
      "                crop_size: 256                           \n",
      "                 dataroot: ./data                        \t[default: data]\n",
      "             dataset_mode: biomassters                   \t[default: aligned]\n",
      "                direction: AtoB                          \n",
      "              display_env: main                          \n",
      "             display_freq: 10                            \t[default: 400]\n",
      "               display_id: 1                             \n",
      "            display_ncols: 4                             \n",
      "             display_port: 8097                          \n",
      "           display_server: http://localhost              \n",
      "          display_winsize: 256                           \n",
      "                    epoch: latest                        \n",
      "              epoch_count: 1                             \n",
      "             g_activation: Softplus                      \t[default: Tanh]\n",
      "                 gan_mode: vanilla                       \n",
      "                  gpu_ids: -1                            \t[default: 0]\n",
      "                init_gain: 0.02                          \n",
      "                init_type: normal                        \n",
      "                 input_nc: 16                            \t[default: 3]\n",
      "                  isTrain: True                          \t[default: None]\n",
      "                lambda_L1: 100.0                         \n",
      "                load_iter: 0                             \t[default: 0]\n",
      "                load_size: 286                           \n",
      "                       lr: 0.0002                        \n",
      "           lr_decay_iters: 50                            \n",
      "                lr_policy: linear                        \n",
      "         max_dataset_size: 10                            \t[default: inf]\n",
      "                    model: pix2pix_bio                   \t[default: cycle_gan]\n",
      "                 n_epochs: 4                             \t[default: 100]\n",
      "           n_epochs_decay: 1                             \t[default: 100]\n",
      "               n_layers_D: 3                             \n",
      "                     name: biomassters_20221202          \t[default: experiment_name]\n",
      "                      ndf: 64                            \n",
      "                     netD: basic                         \n",
      "                     netG: unet_256                      \n",
      "                      ngf: 64                            \n",
      "               no_dropout: False                         \n",
      "                  no_flip: True                          \t[default: False]\n",
      "                  no_html: False                         \n",
      "                     norm: batch                         \n",
      "              num_threads: 4                             \n",
      "                output_nc: 1                             \t[default: 3]\n",
      "                    phase: train                         \n",
      "                pool_size: 0                             \n",
      "               preprocess:                               \t[default: resize_and_crop]\n",
      "               print_freq: 10                            \t[default: 100]\n",
      "             save_by_iter: False                         \n",
      "          save_epoch_freq: 10                            \t[default: 5]\n",
      "         save_latest_freq: 5000                          \n",
      "           serial_batches: False                         \n",
      "                   suffix:                               \n",
      "         update_html_freq: 50                            \t[default: 1000]\n",
      "                use_wandb: False                         \n",
      "                  verbose: False                         \n",
      "       wandb_project_name: CycleGAN-and-pix2pix          \n",
      "----------------- End -------------------\n",
      "dataset [BioMasstersDataset] was created\n",
      "The number of training images = 10\n",
      "initialize network with normal\n",
      "initialize network with normal\n",
      "model [Pix2PixBioModel] was created\n",
      "---------- Networks initialized -------------\n",
      "[Network G] Total number of parameters : 54.423 M\n",
      "[Network D] Total number of parameters : 2.780 M\n",
      "-----------------------------------------------\n",
      "Setting up a new session...\n",
      "create web directory ./checkpoints/biomassters_20221202/web...\n",
      "/Users/loaner/.pyenv/versions/3.8.15/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:138: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  warnings.warn(\"Detected call of `lr_scheduler.step()` before `optimizer.step()`. \"\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "RMSE fake image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 887.91, min: 88.94, mean: 274.07, std: 38.16\n",
      "RMSE real image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 2146.95, min: 0.00, mean: 55.25, std: 66.54\n",
      "(epoch: 1, iters: 10, time: 1.603, data: 9.997) G_GAN: 1.865 G_L1: 57.216 D_real: 0.885 D_fake: 0.770 RMSE: 232.089 \n",
      "End of epoch 1 / 5 \t Time Taken: 31 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "RMSE fake image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 734.34, min: 103.67, mean: 262.47, std: 31.81\n",
      "RMSE real image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 2146.95, min: 0.00, mean: 55.25, std: 66.54\n",
      "(epoch: 2, iters: 10, time: 1.539, data: 12.928) G_GAN: 1.072 G_L1: 54.264 D_real: 1.863 D_fake: 1.940 RMSE: 220.498 \n",
      "End of epoch 2 / 5 \t Time Taken: 33 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "RMSE fake image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 542.65, min: 104.44, mean: 251.38, std: 27.79\n",
      "RMSE real image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 2146.95, min: 0.00, mean: 55.25, std: 66.54\n",
      "(epoch: 3, iters: 10, time: 1.550, data: 13.630) G_GAN: 1.009 G_L1: 51.464 D_real: 1.080 D_fake: 0.969 RMSE: 209.732 \n",
      "End of epoch 3 / 5 \t Time Taken: 34 sec\n",
      "learning rate 0.0002000 -> 0.0001000\n",
      "RMSE fake image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 527.77, min: 114.97, mean: 240.85, std: 25.06\n",
      "RMSE real image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 2146.95, min: 0.00, mean: 55.25, std: 66.54\n",
      "(epoch: 4, iters: 10, time: 1.365, data: 9.568) G_GAN: 0.873 G_L1: 48.834 D_real: 1.003 D_fake: 0.805 RMSE: 199.765 \n",
      "End of epoch 4 / 5 \t Time Taken: 28 sec\n",
      "learning rate 0.0001000 -> 0.0000000\n",
      "RMSE fake image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 472.46, min: 115.95, mean: 235.80, std: 24.02\n",
      "RMSE real image; type: <class 'torch.Tensor'>, shape: torch.Size([10, 1, 256, 256]), max: 2146.95, min: 0.00, mean: 55.25, std: 66.54\n",
      "(epoch: 5, iters: 10, time: 1.359, data: 9.257) G_GAN: 0.873 G_L1: 47.576 D_real: 0.867 D_fake: 0.684 RMSE: 194.962 \n",
      "End of epoch 5 / 5 \t Time Taken: 27 sec\n"
     ]
    }
   ],
   "source": [
    "%cd /Users/loaner/projects/dd-biomassters\n",
    "!python ./pix2pix/train.py \\\n",
    "    --dataroot ./data --name biomassters_20221202 --model pix2pix_bio --phase train --gpu_ids -1 \\\n",
    "    --direction AtoB --input_nc 16 --output_nc 1 --dataset_mode biomassters --preprocess \"\" --no_flip  \\\n",
    "    --g_activation Softplus \\\n",
    "    --batch_size 10 --max_dataset_size 10 \\\n",
    "    --n_epochs 4 --n_epochs_decay 1 --lr 0.0002 \\\n",
    "    --display_id 1 --display_freq 10 --print_freq 10 --update_html_freq 50 --save_epoch_freq 10 \\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".dd-biomassters",
   "language": "python",
   "name": ".dd-biomassters"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
